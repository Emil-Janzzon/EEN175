{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58a75cb0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "40e594185c2d06f7dff5d08df6281c78",
     "grade": false,
     "grade_id": "Introduction",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Reinforcement learning and deep-learning\n",
    "\n",
    "## General outline for this assingment \n",
    "\n",
    "* Q-learning, openai taxi problem \n",
    "* Deep Q-learning, control inverted pendelum\n",
    "* Image classification with pytorch for MNIST dataset\n",
    "\n",
    "This assignment combines the elements of comprehension and implementation. You will be responsible for coding in some sections, while in others, we will provide you with code to study.\n",
    "\n",
    "### Q-Learning\n",
    "\n",
    "In this task, you will employ Q-learning to tackle decision-making in a grid world game. This will provide you with a foundational grasp of Q-learning and the principles of reinforcement learning.\n",
    "\n",
    "To set up the environment for the first two tasks, you'll need to install the required software. https://pypi.org/project/gymnasium/\n",
    "\n",
    "pip install gymnasium==0.29.1\n",
    "\n",
    "\n",
    "### Deep Q-Learning\n",
    "\n",
    "Deep Q-learning combines neural networks with Q-learning. In this task, you're embarking on a rather ambitious journey. Your goal is to construct a neural network from the ground up and we will show how to apply it to a reinforcement learning problem. This endeavor aims to lay a solid foundation for your comprehension of neural networks and the inherent challenges they pose. This may well be one of the very few opportunities you'll have to create such a network from scratch, granting you insight into what transpires behind the scenes. Following this, you'll likely rely on libraries like PyTorch or TensorFlow, which abstract much of the mathematics. \n",
    "\n",
    "The core concept behind deep Q-learning involves approximating the Q-table with a neural network. However, as you'll soon discover, this endeavor is far from straightforward.\n",
    "\n",
    "\n",
    "### CNN + dense with pytorch\n",
    "\n",
    "To wrap up, you will employ PyTorch to tackle an image classification problem, specifically the classification of handwritten numbers. In this segment, we will demonstrate how PyTorch can be used to construct neural networks. Your objective is to enhance the accuracy of this model to reach a minimum of 98%.\n",
    "\n",
    "You can easily install pytorch through (it is enough with just cpu support, if you have an nvidia graphics card you can try the cuda installation), https://pytorch.org/\n",
    "\n",
    "I'm running pytorch version 2.0.1, newer versions should hopefully also work.\n",
    "\n",
    "I have also only tested this assignment with numpy version 1.xx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31d1c61",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "31aeb295b3527a6c938eba211934afed",
     "grade": false,
     "grade_id": "Intro_q_learning",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Q-Learning\n",
    "\n",
    "In reinforcement learning, the primary aim is to maximize future rewards. While this may not seem significantly different from supervised learning, the implications are profound. Consider the scenario where you want an AI to navigate a maze: at each time step, the AI can make a move in any valid direction. If you were to approach this as a regression problem, akin to supervised learning, you would need to know the precise solution for every step, which becomes infeasible for complex problems. Reinforcement learning simplifies the human side of the problem by using rewards. For instance, you can reward the AI only when it successfully solves the maze and allow the AI to explore freely. You don't instruct it on how to solve the maze directly but instead provide a reward for completing the task. The AI will then determine the most effective way to maximize the reward over the entire episode. \n",
    "\n",
    "If you want a robot to learn how to walk, you would provide rewards for moving in the correct direction and penalties if it falls, but you wouldn't explicitly instruct it on how to walk. This is the advantage of reinforcement learning. \n",
    "\n",
    "Q-learning represents one of the simplest versions of reinforcement learning.   \n",
    "\n",
    "In this task, we will employ Q-learning to tackle the taxi problem, which is further described in https://gymnasium.farama.org/environments/toy_text/taxi/ and visualization is provided a few cells down. Short summary: \n",
    "\n",
    "\n",
    ">There are four designated pick-up and drop-off locations (Red, Green, Yellow and Blue) in the 5x5 grid world. The taxi starts off at a random square and the passenger at one of the designated locations.\n",
    "The goal is move the taxi to the passenger’s location, pick up the passenger, move to the passenger’s desired destination, and drop off the passenger. Once the passenger is dropped off, the episode ends.\n",
    "The player receives positive rewards for successfully dropping-off the passenger at the correct location. Negative rewards for incorrect attempts to pick-up/drop-off passenger and for each step where another reward is not received.\n",
    "\n",
    "Let's start by importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b30caa51",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c755f1cc11c29a05288c56443b7c6b32",
     "grade": false,
     "grade_id": "import_np_and_gym",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67400a04",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6c955111bc44a1c1b71b639aa1512210",
     "grade": false,
     "grade_id": "into_viz_env",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The code below visulizes the environment with random actions, the goal will be to create a policy that chooses actions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3bdd054d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "536981e95a9d74d3c9fa5eca9b86dc8c",
     "grade": false,
     "grade_id": "viz_taxi",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "env_render = gym.make(\"Taxi-v3\", render_mode='human') # create environment with rendering \n",
    "state, _ = env_render.reset() # initiate the environment\n",
    "done = False\n",
    "i = 0\n",
    "while not done:\n",
    "    action = env_render.action_space.sample()  # Samples random actions from our environment. \n",
    "    new_state, reward, terminated, truncated, _ = env_render.step(action) # takes as step in our environment\n",
    "    done = terminated or truncated # checks if we have reached our goal or timed out\n",
    "    state = new_state # updates the current state.\n",
    "    if i > 20: # End after 20 steps\n",
    "        done = True\n",
    "    i+=1\n",
    "env_render.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61cd03c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8ea50bf67faa3a737f798a0fc60ac14c",
     "grade": false,
     "grade_id": "intro2_q_learning",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## The Q-learning algorithm\n",
    "\n",
    "In Q-learning we want to learn a look-up table that for every state and action has the future discounted reward. It is initialized with zeros. \n",
    "\n",
    "| State  | a1  | a2  | a3  | a4 |\n",
    "|---|---|---|---|---|\n",
    "| 1  | 0  | 0  | 0 | 0  |\n",
    "| 2  | 0  | 0  | 0 | 0  |\n",
    "| ...  | ...  | ...  | ... | ... |\n",
    "| N  | 0  | 0  | 0 | 0  |\n",
    "\n",
    "The training then updates this table to the correct values. It might look something like:\n",
    "\n",
    "| State  | a1  | a2  | a3  | a4 |\n",
    "|---|---|---|---|---|\n",
    "| 1  | 0.1  | -5  | 1 | 0.4  |\n",
    "| 2  | -1  | -2  | 0 | 4  |\n",
    "| ...  | ...  | ...  | ... | ... |\n",
    "| N  | 1  | 2  | -2 | 1  |\n",
    "\n",
    "List of some terms in the feild of Q-learning:\n",
    "* State - A state in our environment is a representation of all the information available to make a decision. At time step \"t,\" we have the state \"s_t.\" In the case of the taxi problem, there are 500 different states. Each state is an integer within the range of 0 to 500, and it represents: \n",
    "    * 25 different taxi locations\n",
    "    * 5 passenger locations\n",
    "    * 4 possible destinations\n",
    "* Markov decision process (MDP) - Q-learning is an algorithm designed to solve problems involving finite discrete Markov decision processes (MDPs) https://en.wikipedia.org/wiki/Markov_decision_process. \n",
    "* Action - The actions is how we transition between states, at time step $t$ the action $a_t$ takes us to $s_{t+1}$. In this case we have 6 possible actions:\n",
    "    * 0: Move south (down)\n",
    "    * 1: Move north (up)\n",
    "    * 2: Move east (right)\n",
    "    * 3: Move west (left)\n",
    "    * 4: Pickup passenger\n",
    "    * 5: Drop off passenger\n",
    "* Reward - In reinforcement learning, the system provides rewards and penalties to guide the learning process. When the actor successfully completes a task or makes a correct move, a reward $r$ is given. Conversely, penalties can be imposed for suboptimal or incorrect actions. These rewards and penalties serve as the means to influence and shape what the algorithm attempts to learn and optimize. The algorithm aims to maximize the cumulative rewards over time by making decisions that lead to higher overall rewards and fewer penalties.\n",
    "* Q-table - The q table contains for every state (s) and action (a) the expected future discounted reward. Often written as Q(s, a), see above.\n",
    "* Policy - How do we choose our action, Q(s, a) outputs how good a action is but not directly which action to choose. \n",
    "* Greedy policy - For a state choose the action that has the highest expected reward.\n",
    "* Epsilon greedy policy - During training allow for exploration by having a probability of choosing a random action instead of greedy. Exploration is necessary for learning, without it the learning can get stuck in the same solution. \n",
    "* Episode - One espisode is the agient interacting with the environment from start to finish or termination i.e. a timeseries of states and actions.  \n",
    "\n",
    "The q-table can be initated with zeros. It can be updated as:\n",
    "\n",
    "$Q(s_t, a_t) = (1- \\alpha)Q(s_t, a_t) + \\alpha(r_t + \\gamma \\underbrace{\\max}_{a} Q(s_{t+1}, a))$\n",
    "\n",
    "where $\\alpha$ is the learning rate and $\\gamma$ is the dicount factor. For training, we want a policy that both explores new paths while at the same time exploits the current best solution. The solution is an epsilon greedy policy. There is more information at https://en.wikipedia.org/wiki/Q-learning. Also notice that we never update the Q values for the goal state, as the episode will terminate upon reaching the goal. The epsilon greedy policy:\n",
    "\n",
    "$a \\begin{cases} random & \\textrm{With probability } \\epsilon \\\\\n",
    "                greedy &  \\textrm{With probability } 1 - \\epsilon \\end{cases}$\n",
    "                \n",
    "Where $\\epsilon$ is ussually decresing with traning, here is exponential decay. \n",
    "\n",
    "$ \\epsilon = \\epsilon_{\\textrm{min}} + (\\epsilon_{\\textrm{max}} -\\epsilon_{\\textrm{min}}) e^{- \\lambda i_e}$\n",
    "\n",
    "where $\\epsilon_{\\textrm{min}}$ is the minimum value of $\\epsilon$, i.e. we allways want some exploration, otherwise we wont learn anything new. $\\epsilon_{\\textrm{max}}$ usually set to $1$, how much exploration to start of with. $\\lambda$ is the decay rate, how fast should we decreese the amount of exploration. $i_e$ is how many episodes we have trained on.\n",
    "\n",
    "Next we can check how many state and actions our environment has. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "97796a3b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd3889eb32f96a65d7c4bfad86a85b75",
     "grade": true,
     "grade_id": "check_action_states",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of states 500 and number of actions 6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "env = gym.make(\"Taxi-v3\")\n",
    "num_states = env.observation_space.n\n",
    "num_actions = env.action_space.n\n",
    "print('Number of states', num_states, 'and number of actions', num_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bceba74",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0340ba367da67b9b3010c5861815e210",
     "grade": false,
     "grade_id": "inro_hyp_q",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We define our hyper parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "19044479",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8b62a4ae2ee04105502c6d27b261b287",
     "grade": true,
     "grade_id": "hyper_parame_q_lr",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.1 # aplha in our q-learning update\n",
    "discount_factor = 0.99 # gamma\n",
    "epsilon = 1.0 # epsilon\n",
    "epsilon_max = 1.0 # epsilon max\n",
    "epsilon_min = 0.01 # epsilon min\n",
    "epsilon_lambda = 0.01 # lambda\n",
    "num_episodes = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f27928",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "85d19353fc769c3d25cd0047363a45db",
     "grade": false,
     "grade_id": "intro_ex_1_1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exersice 1.1: Q-learning \n",
    "\n",
    "Here the task is to implement the Q-learning algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f55f8373",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6c9c27f4ca9a0e2cfff4b11d71d6d84a",
     "grade": false,
     "grade_id": "q_learning",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Total Reward: -740\n",
      "Episode: 2, Total Reward: -767\n",
      "Episode: 3, Total Reward: -785\n",
      "Episode: 4, Total Reward: -641\n",
      "Episode: 5, Total Reward: -704\n",
      "Episode: 6, Total Reward: -686\n",
      "Episode: 7, Total Reward: -776\n",
      "Episode: 8, Total Reward: -641\n",
      "Episode: 9, Total Reward: -695\n",
      "Episode: 10, Total Reward: -695\n",
      "Episode: 11, Total Reward: -749\n",
      "Episode: 12, Total Reward: -740\n",
      "Episode: 13, Total Reward: -713\n",
      "Episode: 14, Total Reward: -758\n",
      "Episode: 15, Total Reward: -758\n",
      "Episode: 16, Total Reward: -731\n",
      "Episode: 17, Total Reward: -758\n",
      "Episode: 18, Total Reward: -286\n",
      "Episode: 19, Total Reward: -650\n",
      "Episode: 20, Total Reward: -713\n",
      "Episode: 21, Total Reward: -650\n",
      "Episode: 22, Total Reward: -650\n",
      "Episode: 23, Total Reward: -677\n",
      "Episode: 24, Total Reward: -650\n",
      "Episode: 25, Total Reward: -459\n",
      "Episode: 26, Total Reward: -704\n",
      "Episode: 27, Total Reward: -668\n",
      "Episode: 28, Total Reward: -659\n",
      "Episode: 29, Total Reward: -713\n",
      "Episode: 30, Total Reward: -686\n",
      "Episode: 31, Total Reward: -677\n",
      "Episode: 32, Total Reward: -659\n",
      "Episode: 33, Total Reward: -632\n",
      "Episode: 34, Total Reward: -623\n",
      "Episode: 35, Total Reward: -569\n",
      "Episode: 36, Total Reward: -722\n",
      "Episode: 37, Total Reward: -740\n",
      "Episode: 38, Total Reward: -560\n",
      "Episode: 39, Total Reward: -614\n",
      "Episode: 40, Total Reward: -587\n",
      "Episode: 41, Total Reward: -551\n",
      "Episode: 42, Total Reward: -623\n",
      "Episode: 43, Total Reward: -641\n",
      "Episode: 44, Total Reward: -551\n",
      "Episode: 45, Total Reward: -551\n",
      "Episode: 46, Total Reward: -587\n",
      "Episode: 47, Total Reward: -659\n",
      "Episode: 48, Total Reward: -468\n",
      "Episode: 49, Total Reward: -524\n",
      "Episode: 50, Total Reward: -330\n",
      "Episode: 51, Total Reward: -578\n",
      "Episode: 52, Total Reward: -587\n",
      "Episode: 53, Total Reward: -578\n",
      "Episode: 54, Total Reward: -587\n",
      "Episode: 55, Total Reward: -614\n",
      "Episode: 56, Total Reward: -533\n",
      "Episode: 57, Total Reward: -533\n",
      "Episode: 58, Total Reward: -488\n",
      "Episode: 59, Total Reward: -569\n",
      "Episode: 60, Total Reward: -623\n",
      "Episode: 61, Total Reward: -524\n",
      "Episode: 62, Total Reward: -515\n",
      "Episode: 63, Total Reward: -578\n",
      "Episode: 64, Total Reward: -601\n",
      "Episode: 65, Total Reward: -202\n",
      "Episode: 66, Total Reward: -393\n",
      "Episode: 67, Total Reward: -533\n",
      "Episode: 68, Total Reward: -479\n",
      "Episode: 69, Total Reward: -587\n",
      "Episode: 70, Total Reward: -479\n",
      "Episode: 71, Total Reward: -470\n",
      "Episode: 72, Total Reward: -470\n",
      "Episode: 73, Total Reward: -578\n",
      "Episode: 74, Total Reward: -506\n",
      "Episode: 75, Total Reward: -551\n",
      "Episode: 76, Total Reward: -524\n",
      "Episode: 77, Total Reward: -542\n",
      "Episode: 78, Total Reward: -533\n",
      "Episode: 79, Total Reward: -524\n",
      "Episode: 80, Total Reward: -257\n",
      "Episode: 81, Total Reward: -425\n",
      "Episode: 82, Total Reward: -238\n",
      "Episode: 83, Total Reward: -452\n",
      "Episode: 84, Total Reward: -300\n",
      "Episode: 85, Total Reward: -515\n",
      "Episode: 86, Total Reward: -425\n",
      "Episode: 87, Total Reward: -434\n",
      "Episode: 88, Total Reward: -470\n",
      "Episode: 89, Total Reward: -452\n",
      "Episode: 90, Total Reward: -461\n",
      "Episode: 91, Total Reward: -443\n",
      "Episode: 92, Total Reward: -304\n",
      "Episode: 93, Total Reward: -452\n",
      "Episode: 94, Total Reward: -371\n",
      "Episode: 95, Total Reward: -259\n",
      "Episode: 96, Total Reward: -425\n",
      "Episode: 97, Total Reward: -235\n",
      "Episode: 98, Total Reward: -197\n",
      "Episode: 99, Total Reward: -389\n",
      "Episode: 100, Total Reward: -443\n",
      "Episode: 101, Total Reward: -434\n",
      "Episode: 102, Total Reward: -470\n",
      "Episode: 103, Total Reward: -515\n",
      "Episode: 104, Total Reward: -380\n",
      "Episode: 105, Total Reward: -443\n",
      "Episode: 106, Total Reward: -54\n",
      "Episode: 107, Total Reward: -362\n",
      "Episode: 108, Total Reward: -300\n",
      "Episode: 109, Total Reward: -398\n",
      "Episode: 110, Total Reward: -470\n",
      "Episode: 111, Total Reward: -246\n",
      "Episode: 112, Total Reward: -344\n",
      "Episode: 113, Total Reward: -416\n",
      "Episode: 114, Total Reward: -389\n",
      "Episode: 115, Total Reward: -380\n",
      "Episode: 116, Total Reward: -317\n",
      "Episode: 117, Total Reward: -98\n",
      "Episode: 118, Total Reward: -284\n",
      "Episode: 119, Total Reward: -198\n",
      "Episode: 120, Total Reward: -328\n",
      "Episode: 121, Total Reward: -371\n",
      "Episode: 122, Total Reward: -335\n",
      "Episode: 123, Total Reward: -156\n",
      "Episode: 124, Total Reward: -317\n",
      "Episode: 125, Total Reward: -389\n",
      "Episode: 126, Total Reward: -362\n",
      "Episode: 127, Total Reward: -228\n",
      "Episode: 128, Total Reward: -389\n",
      "Episode: 129, Total Reward: -416\n",
      "Episode: 130, Total Reward: -36\n",
      "Episode: 131, Total Reward: -371\n",
      "Episode: 132, Total Reward: -315\n",
      "Episode: 133, Total Reward: -371\n",
      "Episode: 134, Total Reward: -362\n",
      "Episode: 135, Total Reward: -398\n",
      "Episode: 136, Total Reward: -344\n",
      "Episode: 137, Total Reward: -344\n",
      "Episode: 138, Total Reward: -317\n",
      "Episode: 139, Total Reward: -23\n",
      "Episode: 140, Total Reward: -344\n",
      "Episode: 141, Total Reward: -178\n",
      "Episode: 142, Total Reward: -362\n",
      "Episode: 143, Total Reward: -326\n",
      "Episode: 144, Total Reward: -326\n",
      "Episode: 145, Total Reward: -299\n",
      "Episode: 146, Total Reward: -260\n",
      "Episode: 147, Total Reward: -299\n",
      "Episode: 148, Total Reward: -353\n",
      "Episode: 149, Total Reward: -30\n",
      "Episode: 150, Total Reward: -308\n",
      "Episode: 151, Total Reward: -317\n",
      "Episode: 152, Total Reward: -326\n",
      "Episode: 153, Total Reward: -326\n",
      "Episode: 154, Total Reward: -353\n",
      "Episode: 155, Total Reward: -75\n",
      "Episode: 156, Total Reward: -326\n",
      "Episode: 157, Total Reward: -326\n",
      "Episode: 158, Total Reward: -226\n",
      "Episode: 159, Total Reward: -32\n",
      "Episode: 160, Total Reward: -140\n",
      "Episode: 161, Total Reward: -276\n",
      "Episode: 162, Total Reward: -33\n",
      "Episode: 163, Total Reward: -299\n",
      "Episode: 164, Total Reward: -306\n",
      "Episode: 165, Total Reward: -335\n",
      "Episode: 166, Total Reward: -317\n",
      "Episode: 167, Total Reward: -308\n",
      "Episode: 168, Total Reward: -317\n",
      "Episode: 169, Total Reward: -299\n",
      "Episode: 170, Total Reward: -21\n",
      "Episode: 171, Total Reward: -221\n",
      "Episode: 172, Total Reward: -200\n",
      "Episode: 173, Total Reward: -308\n",
      "Episode: 174, Total Reward: -290\n",
      "Episode: 175, Total Reward: -263\n",
      "Episode: 176, Total Reward: -199\n",
      "Episode: 177, Total Reward: -317\n",
      "Episode: 178, Total Reward: -272\n",
      "Episode: 179, Total Reward: -216\n",
      "Episode: 180, Total Reward: -344\n",
      "Episode: 181, Total Reward: -286\n",
      "Episode: 182, Total Reward: -326\n",
      "Episode: 183, Total Reward: -61\n",
      "Episode: 184, Total Reward: -317\n",
      "Episode: 185, Total Reward: -326\n",
      "Episode: 186, Total Reward: -203\n",
      "Episode: 187, Total Reward: -281\n",
      "Episode: 188, Total Reward: -155\n",
      "Episode: 189, Total Reward: -214\n",
      "Episode: 190, Total Reward: -308\n",
      "Episode: 191, Total Reward: -149\n",
      "Episode: 192, Total Reward: -254\n",
      "Episode: 193, Total Reward: -23\n",
      "Episode: 194, Total Reward: -162\n",
      "Episode: 195, Total Reward: -245\n",
      "Episode: 196, Total Reward: -272\n",
      "Episode: 197, Total Reward: -149\n",
      "Episode: 198, Total Reward: -299\n",
      "Episode: 199, Total Reward: -281\n",
      "Episode: 200, Total Reward: -263\n",
      "Episode: 201, Total Reward: -32\n",
      "Episode: 202, Total Reward: -189\n",
      "Episode: 203, Total Reward: -272\n",
      "Episode: 204, Total Reward: -281\n",
      "Episode: 205, Total Reward: -299\n",
      "Episode: 206, Total Reward: -57\n",
      "Episode: 207, Total Reward: 6\n",
      "Episode: 208, Total Reward: -250\n",
      "Episode: 209, Total Reward: -27\n",
      "Episode: 210, Total Reward: -222\n",
      "Episode: 211, Total Reward: -281\n",
      "Episode: 212, Total Reward: -83\n",
      "Episode: 213, Total Reward: -281\n",
      "Episode: 214, Total Reward: -272\n",
      "Episode: 215, Total Reward: -290\n",
      "Episode: 216, Total Reward: -118\n",
      "Episode: 217, Total Reward: -223\n",
      "Episode: 218, Total Reward: -206\n",
      "Episode: 219, Total Reward: -299\n",
      "Episode: 220, Total Reward: -233\n",
      "Episode: 221, Total Reward: -115\n",
      "Episode: 222, Total Reward: -181\n",
      "Episode: 223, Total Reward: -272\n",
      "Episode: 224, Total Reward: -93\n",
      "Episode: 225, Total Reward: -225\n",
      "Episode: 226, Total Reward: -41\n",
      "Episode: 227, Total Reward: -98\n",
      "Episode: 228, Total Reward: -146\n",
      "Episode: 229, Total Reward: 11\n",
      "Episode: 230, Total Reward: -308\n",
      "Episode: 231, Total Reward: -290\n",
      "Episode: 232, Total Reward: -195\n",
      "Episode: 233, Total Reward: -152\n",
      "Episode: 234, Total Reward: -155\n",
      "Episode: 235, Total Reward: -299\n",
      "Episode: 236, Total Reward: -281\n",
      "Episode: 237, Total Reward: -193\n",
      "Episode: 238, Total Reward: -36\n",
      "Episode: 239, Total Reward: -94\n",
      "Episode: 240, Total Reward: -157\n",
      "Episode: 241, Total Reward: -203\n",
      "Episode: 242, Total Reward: -8\n",
      "Episode: 243, Total Reward: -153\n",
      "Episode: 244, Total Reward: -82\n",
      "Episode: 245, Total Reward: -254\n",
      "Episode: 246, Total Reward: -121\n",
      "Episode: 247, Total Reward: -281\n",
      "Episode: 248, Total Reward: -222\n",
      "Episode: 249, Total Reward: -63\n",
      "Episode: 250, Total Reward: -113\n",
      "Episode: 251, Total Reward: -124\n",
      "Episode: 252, Total Reward: -272\n",
      "Episode: 253, Total Reward: -189\n",
      "Episode: 254, Total Reward: -78\n",
      "Episode: 255, Total Reward: -263\n",
      "Episode: 256, Total Reward: -242\n",
      "Episode: 257, Total Reward: -123\n",
      "Episode: 258, Total Reward: -100\n",
      "Episode: 259, Total Reward: -162\n",
      "Episode: 260, Total Reward: -161\n",
      "Episode: 261, Total Reward: -191\n",
      "Episode: 262, Total Reward: -272\n",
      "Episode: 263, Total Reward: -172\n",
      "Episode: 264, Total Reward: -121\n",
      "Episode: 265, Total Reward: -254\n",
      "Episode: 266, Total Reward: -146\n",
      "Episode: 267, Total Reward: -175\n",
      "Episode: 268, Total Reward: -204\n",
      "Episode: 269, Total Reward: 0\n",
      "Episode: 270, Total Reward: -7\n",
      "Episode: 271, Total Reward: -167\n",
      "Episode: 272, Total Reward: -96\n",
      "Episode: 273, Total Reward: -220\n",
      "Episode: 274, Total Reward: -162\n",
      "Episode: 275, Total Reward: -98\n",
      "Episode: 276, Total Reward: -236\n",
      "Episode: 277, Total Reward: -54\n",
      "Episode: 278, Total Reward: -263\n",
      "Episode: 279, Total Reward: -54\n",
      "Episode: 280, Total Reward: -215\n",
      "Episode: 281, Total Reward: -254\n",
      "Episode: 282, Total Reward: -187\n",
      "Episode: 283, Total Reward: -66\n",
      "Episode: 284, Total Reward: -227\n",
      "Episode: 285, Total Reward: -236\n",
      "Episode: 286, Total Reward: -236\n",
      "Episode: 287, Total Reward: -14\n",
      "Episode: 288, Total Reward: -102\n",
      "Episode: 289, Total Reward: -117\n",
      "Episode: 290, Total Reward: -103\n",
      "Episode: 291, Total Reward: -263\n",
      "Episode: 292, Total Reward: -23\n",
      "Episode: 293, Total Reward: -33\n",
      "Episode: 294, Total Reward: -196\n",
      "Episode: 295, Total Reward: -17\n",
      "Episode: 296, Total Reward: -187\n",
      "Episode: 297, Total Reward: -111\n",
      "Episode: 298, Total Reward: -115\n",
      "Episode: 299, Total Reward: -30\n",
      "Episode: 300, Total Reward: -245\n",
      "Episode: 301, Total Reward: -34\n",
      "Episode: 302, Total Reward: -137\n",
      "Episode: 303, Total Reward: 13\n",
      "Episode: 304, Total Reward: -22\n",
      "Episode: 305, Total Reward: -272\n",
      "Episode: 306, Total Reward: 10\n",
      "Episode: 307, Total Reward: 5\n",
      "Episode: 308, Total Reward: -121\n",
      "Episode: 309, Total Reward: -93\n",
      "Episode: 310, Total Reward: -88\n",
      "Episode: 311, Total Reward: -166\n",
      "Episode: 312, Total Reward: -53\n",
      "Episode: 313, Total Reward: -227\n",
      "Episode: 314, Total Reward: -200\n",
      "Episode: 315, Total Reward: -77\n",
      "Episode: 316, Total Reward: -118\n",
      "Episode: 317, Total Reward: -211\n",
      "Episode: 318, Total Reward: -60\n",
      "Episode: 319, Total Reward: -58\n",
      "Episode: 320, Total Reward: -71\n",
      "Episode: 321, Total Reward: -108\n",
      "Episode: 322, Total Reward: -5\n",
      "Episode: 323, Total Reward: -145\n",
      "Episode: 324, Total Reward: -47\n",
      "Episode: 325, Total Reward: -84\n",
      "Episode: 326, Total Reward: -79\n",
      "Episode: 327, Total Reward: -245\n",
      "Episode: 328, Total Reward: -227\n",
      "Episode: 329, Total Reward: -245\n",
      "Episode: 330, Total Reward: -154\n",
      "Episode: 331, Total Reward: -112\n",
      "Episode: 332, Total Reward: -128\n",
      "Episode: 333, Total Reward: 0\n",
      "Episode: 334, Total Reward: -19\n",
      "Episode: 335, Total Reward: -108\n",
      "Episode: 336, Total Reward: -185\n",
      "Episode: 337, Total Reward: -139\n",
      "Episode: 338, Total Reward: -227\n",
      "Episode: 339, Total Reward: -167\n",
      "Episode: 340, Total Reward: -186\n",
      "Episode: 341, Total Reward: -189\n",
      "Episode: 342, Total Reward: -115\n",
      "Episode: 343, Total Reward: -218\n",
      "Episode: 344, Total Reward: -136\n",
      "Episode: 345, Total Reward: -2\n",
      "Episode: 346, Total Reward: -44\n",
      "Episode: 347, Total Reward: -186\n",
      "Episode: 348, Total Reward: -226\n",
      "Episode: 349, Total Reward: -63\n",
      "Episode: 350, Total Reward: -55\n",
      "Episode: 351, Total Reward: -25\n",
      "Episode: 352, Total Reward: -63\n",
      "Episode: 353, Total Reward: -61\n",
      "Episode: 354, Total Reward: -24\n",
      "Episode: 355, Total Reward: -84\n",
      "Episode: 356, Total Reward: -197\n",
      "Episode: 357, Total Reward: -218\n",
      "Episode: 358, Total Reward: -82\n",
      "Episode: 359, Total Reward: -10\n",
      "Episode: 360, Total Reward: -104\n",
      "Episode: 361, Total Reward: 15\n",
      "Episode: 362, Total Reward: -7\n",
      "Episode: 363, Total Reward: -149\n",
      "Episode: 364, Total Reward: -245\n",
      "Episode: 365, Total Reward: -171\n",
      "Episode: 366, Total Reward: -46\n",
      "Episode: 367, Total Reward: -200\n",
      "Episode: 368, Total Reward: 6\n",
      "Episode: 369, Total Reward: -168\n",
      "Episode: 370, Total Reward: -88\n",
      "Episode: 371, Total Reward: -27\n",
      "Episode: 372, Total Reward: -37\n",
      "Episode: 373, Total Reward: -147\n",
      "Episode: 374, Total Reward: -9\n",
      "Episode: 375, Total Reward: -42\n",
      "Episode: 376, Total Reward: -19\n",
      "Episode: 377, Total Reward: -147\n",
      "Episode: 378, Total Reward: -175\n",
      "Episode: 379, Total Reward: -182\n",
      "Episode: 380, Total Reward: -92\n",
      "Episode: 381, Total Reward: 0\n",
      "Episode: 382, Total Reward: -141\n",
      "Episode: 383, Total Reward: -40\n",
      "Episode: 384, Total Reward: -254\n",
      "Episode: 385, Total Reward: -140\n",
      "Episode: 386, Total Reward: -31\n",
      "Episode: 387, Total Reward: -83\n",
      "Episode: 388, Total Reward: -123\n",
      "Episode: 389, Total Reward: -130\n",
      "Episode: 390, Total Reward: -129\n",
      "Episode: 391, Total Reward: -203\n",
      "Episode: 392, Total Reward: -85\n",
      "Episode: 393, Total Reward: -63\n",
      "Episode: 394, Total Reward: -108\n",
      "Episode: 395, Total Reward: -153\n",
      "Episode: 396, Total Reward: 3\n",
      "Episode: 397, Total Reward: -176\n",
      "Episode: 398, Total Reward: -146\n",
      "Episode: 399, Total Reward: 4\n",
      "Episode: 400, Total Reward: 14\n",
      "Episode: 401, Total Reward: -40\n",
      "Episode: 402, Total Reward: -218\n",
      "Episode: 403, Total Reward: -77\n",
      "Episode: 404, Total Reward: 6\n",
      "Episode: 405, Total Reward: -121\n",
      "Episode: 406, Total Reward: -103\n",
      "Episode: 407, Total Reward: -141\n",
      "Episode: 408, Total Reward: -129\n",
      "Episode: 409, Total Reward: -52\n",
      "Episode: 410, Total Reward: -132\n",
      "Episode: 411, Total Reward: -4\n",
      "Episode: 412, Total Reward: 0\n",
      "Episode: 413, Total Reward: -70\n",
      "Episode: 414, Total Reward: -141\n",
      "Episode: 415, Total Reward: -28\n",
      "Episode: 416, Total Reward: -91\n",
      "Episode: 417, Total Reward: -97\n",
      "Episode: 418, Total Reward: -18\n",
      "Episode: 419, Total Reward: -197\n",
      "Episode: 420, Total Reward: -87\n",
      "Episode: 421, Total Reward: -106\n",
      "Episode: 422, Total Reward: -114\n",
      "Episode: 423, Total Reward: -183\n",
      "Episode: 424, Total Reward: -34\n",
      "Episode: 425, Total Reward: -160\n",
      "Episode: 426, Total Reward: -118\n",
      "Episode: 427, Total Reward: -56\n",
      "Episode: 428, Total Reward: -85\n",
      "Episode: 429, Total Reward: -47\n",
      "Episode: 430, Total Reward: -75\n",
      "Episode: 431, Total Reward: 9\n",
      "Episode: 432, Total Reward: -7\n",
      "Episode: 433, Total Reward: -81\n",
      "Episode: 434, Total Reward: -60\n",
      "Episode: 435, Total Reward: -30\n",
      "Episode: 436, Total Reward: -154\n",
      "Episode: 437, Total Reward: -108\n",
      "Episode: 438, Total Reward: -76\n",
      "Episode: 439, Total Reward: -131\n",
      "Episode: 440, Total Reward: -70\n",
      "Episode: 441, Total Reward: 12\n",
      "Episode: 442, Total Reward: 11\n",
      "Episode: 443, Total Reward: -81\n",
      "Episode: 444, Total Reward: -19\n",
      "Episode: 445, Total Reward: -111\n",
      "Episode: 446, Total Reward: -81\n",
      "Episode: 447, Total Reward: -97\n",
      "Episode: 448, Total Reward: -76\n",
      "Episode: 449, Total Reward: -137\n",
      "Episode: 450, Total Reward: -55\n",
      "Episode: 451, Total Reward: -64\n",
      "Episode: 452, Total Reward: -126\n",
      "Episode: 453, Total Reward: 7\n",
      "Episode: 454, Total Reward: 7\n",
      "Episode: 455, Total Reward: -110\n",
      "Episode: 456, Total Reward: -121\n",
      "Episode: 457, Total Reward: -64\n",
      "Episode: 458, Total Reward: -81\n",
      "Episode: 459, Total Reward: -79\n",
      "Episode: 460, Total Reward: -227\n",
      "Episode: 461, Total Reward: -89\n",
      "Episode: 462, Total Reward: -13\n",
      "Episode: 463, Total Reward: -64\n",
      "Episode: 464, Total Reward: 15\n",
      "Episode: 465, Total Reward: -28\n",
      "Episode: 466, Total Reward: -67\n",
      "Episode: 467, Total Reward: 6\n",
      "Episode: 468, Total Reward: 3\n",
      "Episode: 469, Total Reward: -74\n",
      "Episode: 470, Total Reward: -60\n",
      "Episode: 471, Total Reward: -74\n",
      "Episode: 472, Total Reward: -77\n",
      "Episode: 473, Total Reward: -144\n",
      "Episode: 474, Total Reward: -130\n",
      "Episode: 475, Total Reward: -59\n",
      "Episode: 476, Total Reward: -39\n",
      "Episode: 477, Total Reward: 2\n",
      "Episode: 478, Total Reward: -135\n",
      "Episode: 479, Total Reward: 12\n",
      "Episode: 480, Total Reward: -34\n",
      "Episode: 481, Total Reward: -32\n",
      "Episode: 482, Total Reward: -113\n",
      "Episode: 483, Total Reward: -93\n",
      "Episode: 484, Total Reward: 12\n",
      "Episode: 485, Total Reward: -2\n",
      "Episode: 486, Total Reward: -66\n",
      "Episode: 487, Total Reward: 12\n",
      "Episode: 488, Total Reward: -25\n",
      "Episode: 489, Total Reward: -101\n",
      "Episode: 490, Total Reward: -161\n",
      "Episode: 491, Total Reward: 15\n",
      "Episode: 492, Total Reward: 7\n",
      "Episode: 493, Total Reward: 15\n",
      "Episode: 494, Total Reward: -29\n",
      "Episode: 495, Total Reward: 13\n",
      "Episode: 496, Total Reward: 8\n",
      "Episode: 497, Total Reward: -85\n",
      "Episode: 498, Total Reward: -14\n",
      "Episode: 499, Total Reward: -59\n",
      "Episode: 500, Total Reward: -50\n",
      "Episode: 501, Total Reward: -75\n",
      "Episode: 502, Total Reward: -110\n",
      "Episode: 503, Total Reward: 4\n",
      "Episode: 504, Total Reward: -9\n",
      "Episode: 505, Total Reward: -93\n",
      "Episode: 506, Total Reward: 12\n",
      "Episode: 507, Total Reward: -21\n",
      "Episode: 508, Total Reward: 6\n",
      "Episode: 509, Total Reward: -138\n",
      "Episode: 510, Total Reward: -51\n",
      "Episode: 511, Total Reward: -131\n",
      "Episode: 512, Total Reward: -12\n",
      "Episode: 513, Total Reward: -8\n",
      "Episode: 514, Total Reward: -88\n",
      "Episode: 515, Total Reward: 11\n",
      "Episode: 516, Total Reward: -46\n",
      "Episode: 517, Total Reward: -58\n",
      "Episode: 518, Total Reward: -14\n",
      "Episode: 519, Total Reward: -27\n",
      "Episode: 520, Total Reward: -22\n",
      "Episode: 521, Total Reward: -29\n",
      "Episode: 522, Total Reward: -126\n",
      "Episode: 523, Total Reward: -109\n",
      "Episode: 524, Total Reward: -218\n",
      "Episode: 525, Total Reward: -42\n",
      "Episode: 526, Total Reward: -74\n",
      "Episode: 527, Total Reward: -3\n",
      "Episode: 528, Total Reward: 1\n",
      "Episode: 529, Total Reward: -148\n",
      "Episode: 530, Total Reward: -108\n",
      "Episode: 531, Total Reward: -5\n",
      "Episode: 532, Total Reward: -83\n",
      "Episode: 533, Total Reward: -50\n",
      "Episode: 534, Total Reward: 11\n",
      "Episode: 535, Total Reward: -3\n",
      "Episode: 536, Total Reward: -47\n",
      "Episode: 537, Total Reward: -48\n",
      "Episode: 538, Total Reward: -6\n",
      "Episode: 539, Total Reward: -38\n",
      "Episode: 540, Total Reward: -64\n",
      "Episode: 541, Total Reward: -89\n",
      "Episode: 542, Total Reward: 8\n",
      "Episode: 543, Total Reward: -133\n",
      "Episode: 544, Total Reward: -22\n",
      "Episode: 545, Total Reward: -100\n",
      "Episode: 546, Total Reward: -30\n",
      "Episode: 547, Total Reward: -77\n",
      "Episode: 548, Total Reward: -144\n",
      "Episode: 549, Total Reward: -81\n",
      "Episode: 550, Total Reward: -61\n",
      "Episode: 551, Total Reward: -218\n",
      "Episode: 552, Total Reward: -66\n",
      "Episode: 553, Total Reward: -19\n",
      "Episode: 554, Total Reward: -77\n",
      "Episode: 555, Total Reward: -112\n",
      "Episode: 556, Total Reward: -61\n",
      "Episode: 557, Total Reward: 1\n",
      "Episode: 558, Total Reward: -48\n",
      "Episode: 559, Total Reward: -55\n",
      "Episode: 560, Total Reward: 12\n",
      "Episode: 561, Total Reward: 0\n",
      "Episode: 562, Total Reward: -29\n",
      "Episode: 563, Total Reward: -135\n",
      "Episode: 564, Total Reward: -14\n",
      "Episode: 565, Total Reward: -113\n",
      "Episode: 566, Total Reward: -15\n",
      "Episode: 567, Total Reward: -10\n",
      "Episode: 568, Total Reward: -58\n",
      "Episode: 569, Total Reward: 11\n",
      "Episode: 570, Total Reward: 9\n",
      "Episode: 571, Total Reward: -37\n",
      "Episode: 572, Total Reward: 10\n",
      "Episode: 573, Total Reward: -41\n",
      "Episode: 574, Total Reward: -101\n",
      "Episode: 575, Total Reward: -29\n",
      "Episode: 576, Total Reward: -4\n",
      "Episode: 577, Total Reward: -126\n",
      "Episode: 578, Total Reward: -5\n",
      "Episode: 579, Total Reward: 8\n",
      "Episode: 580, Total Reward: -22\n",
      "Episode: 581, Total Reward: -31\n",
      "Episode: 582, Total Reward: 15\n",
      "Episode: 583, Total Reward: -142\n",
      "Episode: 584, Total Reward: -18\n",
      "Episode: 585, Total Reward: -68\n",
      "Episode: 586, Total Reward: -103\n",
      "Episode: 587, Total Reward: -112\n",
      "Episode: 588, Total Reward: 3\n",
      "Episode: 589, Total Reward: -96\n",
      "Episode: 590, Total Reward: -5\n",
      "Episode: 591, Total Reward: -133\n",
      "Episode: 592, Total Reward: -17\n",
      "Episode: 593, Total Reward: -34\n",
      "Episode: 594, Total Reward: -52\n",
      "Episode: 595, Total Reward: -9\n",
      "Episode: 596, Total Reward: 8\n",
      "Episode: 597, Total Reward: -17\n",
      "Episode: 598, Total Reward: -27\n",
      "Episode: 599, Total Reward: 7\n",
      "Episode: 600, Total Reward: -21\n",
      "Episode: 601, Total Reward: -19\n",
      "Episode: 602, Total Reward: -87\n",
      "Episode: 603, Total Reward: -36\n",
      "Episode: 604, Total Reward: -43\n",
      "Episode: 605, Total Reward: -106\n",
      "Episode: 606, Total Reward: 7\n",
      "Episode: 607, Total Reward: -29\n",
      "Episode: 608, Total Reward: 9\n",
      "Episode: 609, Total Reward: 9\n",
      "Episode: 610, Total Reward: 3\n",
      "Episode: 611, Total Reward: 5\n",
      "Episode: 612, Total Reward: -46\n",
      "Episode: 613, Total Reward: 14\n",
      "Episode: 614, Total Reward: -23\n",
      "Episode: 615, Total Reward: -4\n",
      "Episode: 616, Total Reward: -16\n",
      "Episode: 617, Total Reward: -3\n",
      "Episode: 618, Total Reward: -68\n",
      "Episode: 619, Total Reward: -61\n",
      "Episode: 620, Total Reward: -22\n",
      "Episode: 621, Total Reward: -26\n",
      "Episode: 622, Total Reward: -2\n",
      "Episode: 623, Total Reward: 3\n",
      "Episode: 624, Total Reward: -70\n",
      "Episode: 625, Total Reward: -63\n",
      "Episode: 626, Total Reward: -1\n",
      "Episode: 627, Total Reward: -72\n",
      "Episode: 628, Total Reward: -60\n",
      "Episode: 629, Total Reward: 12\n",
      "Episode: 630, Total Reward: -76\n",
      "Episode: 631, Total Reward: 11\n",
      "Episode: 632, Total Reward: -81\n",
      "Episode: 633, Total Reward: -9\n",
      "Episode: 634, Total Reward: -74\n",
      "Episode: 635, Total Reward: -26\n",
      "Episode: 636, Total Reward: -10\n",
      "Episode: 637, Total Reward: -41\n",
      "Episode: 638, Total Reward: -67\n",
      "Episode: 639, Total Reward: -31\n",
      "Episode: 640, Total Reward: -34\n",
      "Episode: 641, Total Reward: 4\n",
      "Episode: 642, Total Reward: -78\n",
      "Episode: 643, Total Reward: -8\n",
      "Episode: 644, Total Reward: -3\n",
      "Episode: 645, Total Reward: -43\n",
      "Episode: 646, Total Reward: -122\n",
      "Episode: 647, Total Reward: 7\n",
      "Episode: 648, Total Reward: 5\n",
      "Episode: 649, Total Reward: -21\n",
      "Episode: 650, Total Reward: -63\n",
      "Episode: 651, Total Reward: 12\n",
      "Episode: 652, Total Reward: -52\n",
      "Episode: 653, Total Reward: -70\n",
      "Episode: 654, Total Reward: -88\n",
      "Episode: 655, Total Reward: -7\n",
      "Episode: 656, Total Reward: 11\n",
      "Episode: 657, Total Reward: -11\n",
      "Episode: 658, Total Reward: -26\n",
      "Episode: 659, Total Reward: -39\n",
      "Episode: 660, Total Reward: -30\n",
      "Episode: 661, Total Reward: -68\n",
      "Episode: 662, Total Reward: -62\n",
      "Episode: 663, Total Reward: -42\n",
      "Episode: 664, Total Reward: 11\n",
      "Episode: 665, Total Reward: -1\n",
      "Episode: 666, Total Reward: 0\n",
      "Episode: 667, Total Reward: -12\n",
      "Episode: 668, Total Reward: -110\n",
      "Episode: 669, Total Reward: 10\n",
      "Episode: 670, Total Reward: -14\n",
      "Episode: 671, Total Reward: -47\n",
      "Episode: 672, Total Reward: -15\n",
      "Episode: 673, Total Reward: 6\n",
      "Episode: 674, Total Reward: 11\n",
      "Episode: 675, Total Reward: -20\n",
      "Episode: 676, Total Reward: -47\n",
      "Episode: 677, Total Reward: -84\n",
      "Episode: 678, Total Reward: -2\n",
      "Episode: 679, Total Reward: -21\n",
      "Episode: 680, Total Reward: -59\n",
      "Episode: 681, Total Reward: -57\n",
      "Episode: 682, Total Reward: -14\n",
      "Episode: 683, Total Reward: -7\n",
      "Episode: 684, Total Reward: 1\n",
      "Episode: 685, Total Reward: 5\n",
      "Episode: 686, Total Reward: -25\n",
      "Episode: 687, Total Reward: -92\n",
      "Episode: 688, Total Reward: 11\n",
      "Episode: 689, Total Reward: -49\n",
      "Episode: 690, Total Reward: 11\n",
      "Episode: 691, Total Reward: 10\n",
      "Episode: 692, Total Reward: -4\n",
      "Episode: 693, Total Reward: -12\n",
      "Episode: 694, Total Reward: -1\n",
      "Episode: 695, Total Reward: -39\n",
      "Episode: 696, Total Reward: -56\n",
      "Episode: 697, Total Reward: 10\n",
      "Episode: 698, Total Reward: -57\n",
      "Episode: 699, Total Reward: -3\n",
      "Episode: 700, Total Reward: 11\n",
      "Episode: 701, Total Reward: 15\n",
      "Episode: 702, Total Reward: 7\n",
      "Episode: 703, Total Reward: -114\n",
      "Episode: 704, Total Reward: -21\n",
      "Episode: 705, Total Reward: -2\n",
      "Episode: 706, Total Reward: 5\n",
      "Episode: 707, Total Reward: -26\n",
      "Episode: 708, Total Reward: -31\n",
      "Episode: 709, Total Reward: -23\n",
      "Episode: 710, Total Reward: -77\n",
      "Episode: 711, Total Reward: -50\n",
      "Episode: 712, Total Reward: -5\n",
      "Episode: 713, Total Reward: -10\n",
      "Episode: 714, Total Reward: -123\n",
      "Episode: 715, Total Reward: -13\n",
      "Episode: 716, Total Reward: 2\n",
      "Episode: 717, Total Reward: 5\n",
      "Episode: 718, Total Reward: -18\n",
      "Episode: 719, Total Reward: -95\n",
      "Episode: 720, Total Reward: 10\n",
      "Episode: 721, Total Reward: -118\n",
      "Episode: 722, Total Reward: 8\n",
      "Episode: 723, Total Reward: -26\n",
      "Episode: 724, Total Reward: -81\n",
      "Episode: 725, Total Reward: -19\n",
      "Episode: 726, Total Reward: -21\n",
      "Episode: 727, Total Reward: 7\n",
      "Episode: 728, Total Reward: -79\n",
      "Episode: 729, Total Reward: -26\n",
      "Episode: 730, Total Reward: 1\n",
      "Episode: 731, Total Reward: 6\n",
      "Episode: 732, Total Reward: -11\n",
      "Episode: 733, Total Reward: -13\n",
      "Episode: 734, Total Reward: 8\n",
      "Episode: 735, Total Reward: 3\n",
      "Episode: 736, Total Reward: -17\n",
      "Episode: 737, Total Reward: -32\n",
      "Episode: 738, Total Reward: 9\n",
      "Episode: 739, Total Reward: -18\n",
      "Episode: 740, Total Reward: 15\n",
      "Episode: 741, Total Reward: -71\n",
      "Episode: 742, Total Reward: -14\n",
      "Episode: 743, Total Reward: -21\n",
      "Episode: 744, Total Reward: 8\n",
      "Episode: 745, Total Reward: -3\n",
      "Episode: 746, Total Reward: -47\n",
      "Episode: 747, Total Reward: -2\n",
      "Episode: 748, Total Reward: 0\n",
      "Episode: 749, Total Reward: 3\n",
      "Episode: 750, Total Reward: -4\n",
      "Episode: 751, Total Reward: -55\n",
      "Episode: 752, Total Reward: 9\n",
      "Episode: 753, Total Reward: -41\n",
      "Episode: 754, Total Reward: -39\n",
      "Episode: 755, Total Reward: -25\n",
      "Episode: 756, Total Reward: -5\n",
      "Episode: 757, Total Reward: -49\n",
      "Episode: 758, Total Reward: -5\n",
      "Episode: 759, Total Reward: -4\n",
      "Episode: 760, Total Reward: -24\n",
      "Episode: 761, Total Reward: -4\n",
      "Episode: 762, Total Reward: -1\n",
      "Episode: 763, Total Reward: 7\n",
      "Episode: 764, Total Reward: 9\n",
      "Episode: 765, Total Reward: -15\n",
      "Episode: 766, Total Reward: 10\n",
      "Episode: 767, Total Reward: -6\n",
      "Episode: 768, Total Reward: -55\n",
      "Episode: 769, Total Reward: 7\n",
      "Episode: 770, Total Reward: -9\n",
      "Episode: 771, Total Reward: -43\n",
      "Episode: 772, Total Reward: -7\n",
      "Episode: 773, Total Reward: -9\n",
      "Episode: 774, Total Reward: 10\n",
      "Episode: 775, Total Reward: -5\n",
      "Episode: 776, Total Reward: 8\n",
      "Episode: 777, Total Reward: 11\n",
      "Episode: 778, Total Reward: 5\n",
      "Episode: 779, Total Reward: -4\n",
      "Episode: 780, Total Reward: -29\n",
      "Episode: 781, Total Reward: -41\n",
      "Episode: 782, Total Reward: -13\n",
      "Episode: 783, Total Reward: -26\n",
      "Episode: 784, Total Reward: -36\n",
      "Episode: 785, Total Reward: 10\n",
      "Episode: 786, Total Reward: -99\n",
      "Episode: 787, Total Reward: -35\n",
      "Episode: 788, Total Reward: 8\n",
      "Episode: 789, Total Reward: -4\n",
      "Episode: 790, Total Reward: -28\n",
      "Episode: 791, Total Reward: -52\n",
      "Episode: 792, Total Reward: -23\n",
      "Episode: 793, Total Reward: -4\n",
      "Episode: 794, Total Reward: -29\n",
      "Episode: 795, Total Reward: 2\n",
      "Episode: 796, Total Reward: -16\n",
      "Episode: 797, Total Reward: 5\n",
      "Episode: 798, Total Reward: -33\n",
      "Episode: 799, Total Reward: 11\n",
      "Episode: 800, Total Reward: -30\n",
      "Episode: 801, Total Reward: 2\n",
      "Episode: 802, Total Reward: 13\n",
      "Episode: 803, Total Reward: -55\n",
      "Episode: 804, Total Reward: 9\n",
      "Episode: 805, Total Reward: 5\n",
      "Episode: 806, Total Reward: 11\n",
      "Episode: 807, Total Reward: -39\n",
      "Episode: 808, Total Reward: 11\n",
      "Episode: 809, Total Reward: -53\n",
      "Episode: 810, Total Reward: -36\n",
      "Episode: 811, Total Reward: -29\n",
      "Episode: 812, Total Reward: -12\n",
      "Episode: 813, Total Reward: 10\n",
      "Episode: 814, Total Reward: -2\n",
      "Episode: 815, Total Reward: -80\n",
      "Episode: 816, Total Reward: 5\n",
      "Episode: 817, Total Reward: 1\n",
      "Episode: 818, Total Reward: -39\n",
      "Episode: 819, Total Reward: -51\n",
      "Episode: 820, Total Reward: -7\n",
      "Episode: 821, Total Reward: 13\n",
      "Episode: 822, Total Reward: -38\n",
      "Episode: 823, Total Reward: 11\n",
      "Episode: 824, Total Reward: 2\n",
      "Episode: 825, Total Reward: -19\n",
      "Episode: 826, Total Reward: 6\n",
      "Episode: 827, Total Reward: 15\n",
      "Episode: 828, Total Reward: -6\n",
      "Episode: 829, Total Reward: 9\n",
      "Episode: 830, Total Reward: 5\n",
      "Episode: 831, Total Reward: -13\n",
      "Episode: 832, Total Reward: 9\n",
      "Episode: 833, Total Reward: 13\n",
      "Episode: 834, Total Reward: 10\n",
      "Episode: 835, Total Reward: 9\n",
      "Episode: 836, Total Reward: -9\n",
      "Episode: 837, Total Reward: -21\n",
      "Episode: 838, Total Reward: 5\n",
      "Episode: 839, Total Reward: 0\n",
      "Episode: 840, Total Reward: -19\n",
      "Episode: 841, Total Reward: 6\n",
      "Episode: 842, Total Reward: 9\n",
      "Episode: 843, Total Reward: 6\n",
      "Episode: 844, Total Reward: 11\n",
      "Episode: 845, Total Reward: 11\n",
      "Episode: 846, Total Reward: -2\n",
      "Episode: 847, Total Reward: -32\n",
      "Episode: 848, Total Reward: 11\n",
      "Episode: 849, Total Reward: -42\n",
      "Episode: 850, Total Reward: 10\n",
      "Episode: 851, Total Reward: -21\n",
      "Episode: 852, Total Reward: -20\n",
      "Episode: 853, Total Reward: -23\n",
      "Episode: 854, Total Reward: 11\n",
      "Episode: 855, Total Reward: 11\n",
      "Episode: 856, Total Reward: -39\n",
      "Episode: 857, Total Reward: -2\n",
      "Episode: 858, Total Reward: 11\n",
      "Episode: 859, Total Reward: -39\n",
      "Episode: 860, Total Reward: 3\n",
      "Episode: 861, Total Reward: -43\n",
      "Episode: 862, Total Reward: -4\n",
      "Episode: 863, Total Reward: 12\n",
      "Episode: 864, Total Reward: 7\n",
      "Episode: 865, Total Reward: 2\n",
      "Episode: 866, Total Reward: -15\n",
      "Episode: 867, Total Reward: -47\n",
      "Episode: 868, Total Reward: -6\n",
      "Episode: 869, Total Reward: 1\n",
      "Episode: 870, Total Reward: 9\n",
      "Episode: 871, Total Reward: 9\n",
      "Episode: 872, Total Reward: -29\n",
      "Episode: 873, Total Reward: -21\n",
      "Episode: 874, Total Reward: 3\n",
      "Episode: 875, Total Reward: 12\n",
      "Episode: 876, Total Reward: -8\n",
      "Episode: 877, Total Reward: 11\n",
      "Episode: 878, Total Reward: -32\n",
      "Episode: 879, Total Reward: 3\n",
      "Episode: 880, Total Reward: -8\n",
      "Episode: 881, Total Reward: 3\n",
      "Episode: 882, Total Reward: 10\n",
      "Episode: 883, Total Reward: 12\n",
      "Episode: 884, Total Reward: 12\n",
      "Episode: 885, Total Reward: 8\n",
      "Episode: 886, Total Reward: -2\n",
      "Episode: 887, Total Reward: -90\n",
      "Episode: 888, Total Reward: -2\n",
      "Episode: 889, Total Reward: 0\n",
      "Episode: 890, Total Reward: -34\n",
      "Episode: 891, Total Reward: 9\n",
      "Episode: 892, Total Reward: 10\n",
      "Episode: 893, Total Reward: 0\n",
      "Episode: 894, Total Reward: -11\n",
      "Episode: 895, Total Reward: 3\n",
      "Episode: 896, Total Reward: -8\n",
      "Episode: 897, Total Reward: -6\n",
      "Episode: 898, Total Reward: 10\n",
      "Episode: 899, Total Reward: 8\n",
      "Episode: 900, Total Reward: 12\n",
      "Episode: 901, Total Reward: 4\n",
      "Episode: 902, Total Reward: -4\n",
      "Episode: 903, Total Reward: -20\n",
      "Episode: 904, Total Reward: -6\n",
      "Episode: 905, Total Reward: 10\n",
      "Episode: 906, Total Reward: -1\n",
      "Episode: 907, Total Reward: 6\n",
      "Episode: 908, Total Reward: 11\n",
      "Episode: 909, Total Reward: 10\n",
      "Episode: 910, Total Reward: 5\n",
      "Episode: 911, Total Reward: 14\n",
      "Episode: 912, Total Reward: 13\n",
      "Episode: 913, Total Reward: -35\n",
      "Episode: 914, Total Reward: -28\n",
      "Episode: 915, Total Reward: 8\n",
      "Episode: 916, Total Reward: -44\n",
      "Episode: 917, Total Reward: 8\n",
      "Episode: 918, Total Reward: 12\n",
      "Episode: 919, Total Reward: 9\n",
      "Episode: 920, Total Reward: -7\n",
      "Episode: 921, Total Reward: -5\n",
      "Episode: 922, Total Reward: 11\n",
      "Episode: 923, Total Reward: 6\n",
      "Episode: 924, Total Reward: 6\n",
      "Episode: 925, Total Reward: -37\n",
      "Episode: 926, Total Reward: 11\n",
      "Episode: 927, Total Reward: 10\n",
      "Episode: 928, Total Reward: 15\n",
      "Episode: 929, Total Reward: 10\n",
      "Episode: 930, Total Reward: -35\n",
      "Episode: 931, Total Reward: 8\n",
      "Episode: 932, Total Reward: 6\n",
      "Episode: 933, Total Reward: 3\n",
      "Episode: 934, Total Reward: 13\n",
      "Episode: 935, Total Reward: -74\n",
      "Episode: 936, Total Reward: -8\n",
      "Episode: 937, Total Reward: 6\n",
      "Episode: 938, Total Reward: -70\n",
      "Episode: 939, Total Reward: 6\n",
      "Episode: 940, Total Reward: -12\n",
      "Episode: 941, Total Reward: -23\n",
      "Episode: 942, Total Reward: -63\n",
      "Episode: 943, Total Reward: 7\n",
      "Episode: 944, Total Reward: 5\n",
      "Episode: 945, Total Reward: -48\n",
      "Episode: 946, Total Reward: 8\n",
      "Episode: 947, Total Reward: 7\n",
      "Episode: 948, Total Reward: 5\n",
      "Episode: 949, Total Reward: 9\n",
      "Episode: 950, Total Reward: 5\n",
      "Episode: 951, Total Reward: 3\n",
      "Episode: 952, Total Reward: 8\n",
      "Episode: 953, Total Reward: 8\n",
      "Episode: 954, Total Reward: 8\n",
      "Episode: 955, Total Reward: 9\n",
      "Episode: 956, Total Reward: 9\n",
      "Episode: 957, Total Reward: 7\n",
      "Episode: 958, Total Reward: 4\n",
      "Episode: 959, Total Reward: 11\n",
      "Episode: 960, Total Reward: 6\n",
      "Episode: 961, Total Reward: -4\n",
      "Episode: 962, Total Reward: -29\n",
      "Episode: 963, Total Reward: 3\n",
      "Episode: 964, Total Reward: 8\n",
      "Episode: 965, Total Reward: -21\n",
      "Episode: 966, Total Reward: 9\n",
      "Episode: 967, Total Reward: -3\n",
      "Episode: 968, Total Reward: 9\n",
      "Episode: 969, Total Reward: -10\n",
      "Episode: 970, Total Reward: 7\n",
      "Episode: 971, Total Reward: 12\n",
      "Episode: 972, Total Reward: -2\n",
      "Episode: 973, Total Reward: 12\n",
      "Episode: 974, Total Reward: -13\n",
      "Episode: 975, Total Reward: 11\n",
      "Episode: 976, Total Reward: -18\n",
      "Episode: 977, Total Reward: 9\n",
      "Episode: 978, Total Reward: -48\n",
      "Episode: 979, Total Reward: 9\n",
      "Episode: 980, Total Reward: -17\n",
      "Episode: 981, Total Reward: 2\n",
      "Episode: 982, Total Reward: 11\n",
      "Episode: 983, Total Reward: -19\n",
      "Episode: 984, Total Reward: 4\n",
      "Episode: 985, Total Reward: 15\n",
      "Episode: 986, Total Reward: 10\n",
      "Episode: 987, Total Reward: 9\n",
      "Episode: 988, Total Reward: -5\n",
      "Episode: 989, Total Reward: 12\n",
      "Episode: 990, Total Reward: -18\n",
      "Episode: 991, Total Reward: 14\n",
      "Episode: 992, Total Reward: -18\n",
      "Episode: 993, Total Reward: 10\n",
      "Episode: 994, Total Reward: 9\n",
      "Episode: 995, Total Reward: 10\n",
      "Episode: 996, Total Reward: -1\n",
      "Episode: 997, Total Reward: 10\n",
      "Episode: 998, Total Reward: -10\n",
      "Episode: 999, Total Reward: -20\n",
      "Episode: 1000, Total Reward: 12\n",
      "Episode: 1001, Total Reward: 11\n",
      "Episode: 1002, Total Reward: -8\n",
      "Episode: 1003, Total Reward: 1\n",
      "Episode: 1004, Total Reward: -10\n",
      "Episode: 1005, Total Reward: -6\n",
      "Episode: 1006, Total Reward: 6\n",
      "Episode: 1007, Total Reward: 9\n",
      "Episode: 1008, Total Reward: -16\n",
      "Episode: 1009, Total Reward: 9\n",
      "Episode: 1010, Total Reward: 11\n",
      "Episode: 1011, Total Reward: 4\n",
      "Episode: 1012, Total Reward: -6\n",
      "Episode: 1013, Total Reward: -6\n",
      "Episode: 1014, Total Reward: -59\n",
      "Episode: 1015, Total Reward: 10\n",
      "Episode: 1016, Total Reward: 11\n",
      "Episode: 1017, Total Reward: 7\n",
      "Episode: 1018, Total Reward: 4\n",
      "Episode: 1019, Total Reward: -41\n",
      "Episode: 1020, Total Reward: -1\n",
      "Episode: 1021, Total Reward: 11\n",
      "Episode: 1022, Total Reward: -4\n",
      "Episode: 1023, Total Reward: -5\n",
      "Episode: 1024, Total Reward: -21\n",
      "Episode: 1025, Total Reward: 11\n",
      "Episode: 1026, Total Reward: 9\n",
      "Episode: 1027, Total Reward: 0\n",
      "Episode: 1028, Total Reward: 10\n",
      "Episode: 1029, Total Reward: 10\n",
      "Episode: 1030, Total Reward: 11\n",
      "Episode: 1031, Total Reward: 0\n",
      "Episode: 1032, Total Reward: 3\n",
      "Episode: 1033, Total Reward: -7\n",
      "Episode: 1034, Total Reward: 5\n",
      "Episode: 1035, Total Reward: 0\n",
      "Episode: 1036, Total Reward: 6\n",
      "Episode: 1037, Total Reward: -1\n",
      "Episode: 1038, Total Reward: 12\n",
      "Episode: 1039, Total Reward: 12\n",
      "Episode: 1040, Total Reward: 2\n",
      "Episode: 1041, Total Reward: 13\n",
      "Episode: 1042, Total Reward: 1\n",
      "Episode: 1043, Total Reward: 7\n",
      "Episode: 1044, Total Reward: -2\n",
      "Episode: 1045, Total Reward: 10\n",
      "Episode: 1046, Total Reward: 6\n",
      "Episode: 1047, Total Reward: -10\n",
      "Episode: 1048, Total Reward: -50\n",
      "Episode: 1049, Total Reward: 8\n",
      "Episode: 1050, Total Reward: -1\n",
      "Episode: 1051, Total Reward: -14\n",
      "Episode: 1052, Total Reward: 6\n",
      "Episode: 1053, Total Reward: 11\n",
      "Episode: 1054, Total Reward: 10\n",
      "Episode: 1055, Total Reward: 8\n",
      "Episode: 1056, Total Reward: 15\n",
      "Episode: 1057, Total Reward: -6\n",
      "Episode: 1058, Total Reward: 6\n",
      "Episode: 1059, Total Reward: 3\n",
      "Episode: 1060, Total Reward: 10\n",
      "Episode: 1061, Total Reward: -4\n",
      "Episode: 1062, Total Reward: 10\n",
      "Episode: 1063, Total Reward: 2\n",
      "Episode: 1064, Total Reward: 11\n",
      "Episode: 1065, Total Reward: 5\n",
      "Episode: 1066, Total Reward: 6\n",
      "Episode: 1067, Total Reward: -4\n",
      "Episode: 1068, Total Reward: 8\n",
      "Episode: 1069, Total Reward: 0\n",
      "Episode: 1070, Total Reward: -68\n",
      "Episode: 1071, Total Reward: 9\n",
      "Episode: 1072, Total Reward: 4\n",
      "Episode: 1073, Total Reward: -17\n",
      "Episode: 1074, Total Reward: 7\n",
      "Episode: 1075, Total Reward: 9\n",
      "Episode: 1076, Total Reward: 5\n",
      "Episode: 1077, Total Reward: 4\n",
      "Episode: 1078, Total Reward: 12\n",
      "Episode: 1079, Total Reward: 11\n",
      "Episode: 1080, Total Reward: -58\n",
      "Episode: 1081, Total Reward: 3\n",
      "Episode: 1082, Total Reward: 2\n",
      "Episode: 1083, Total Reward: 8\n",
      "Episode: 1084, Total Reward: 10\n",
      "Episode: 1085, Total Reward: 4\n",
      "Episode: 1086, Total Reward: 8\n",
      "Episode: 1087, Total Reward: 6\n",
      "Episode: 1088, Total Reward: 7\n",
      "Episode: 1089, Total Reward: -40\n",
      "Episode: 1090, Total Reward: 10\n",
      "Episode: 1091, Total Reward: -34\n",
      "Episode: 1092, Total Reward: -1\n",
      "Episode: 1093, Total Reward: -8\n",
      "Episode: 1094, Total Reward: 12\n",
      "Episode: 1095, Total Reward: 0\n",
      "Episode: 1096, Total Reward: 8\n",
      "Episode: 1097, Total Reward: 11\n",
      "Episode: 1098, Total Reward: 11\n",
      "Episode: 1099, Total Reward: 9\n",
      "Episode: 1100, Total Reward: -64\n",
      "Episode: 1101, Total Reward: -35\n",
      "Episode: 1102, Total Reward: 9\n",
      "Episode: 1103, Total Reward: 6\n",
      "Episode: 1104, Total Reward: 8\n",
      "Episode: 1105, Total Reward: 3\n",
      "Episode: 1106, Total Reward: 0\n",
      "Episode: 1107, Total Reward: -4\n",
      "Episode: 1108, Total Reward: 14\n",
      "Episode: 1109, Total Reward: 9\n",
      "Episode: 1110, Total Reward: 2\n",
      "Episode: 1111, Total Reward: 4\n",
      "Episode: 1112, Total Reward: 10\n",
      "Episode: 1113, Total Reward: -9\n",
      "Episode: 1114, Total Reward: 10\n",
      "Episode: 1115, Total Reward: 9\n",
      "Episode: 1116, Total Reward: 0\n",
      "Episode: 1117, Total Reward: 9\n",
      "Episode: 1118, Total Reward: -5\n",
      "Episode: 1119, Total Reward: 5\n",
      "Episode: 1120, Total Reward: 11\n",
      "Episode: 1121, Total Reward: -36\n",
      "Episode: 1122, Total Reward: 7\n",
      "Episode: 1123, Total Reward: -18\n",
      "Episode: 1124, Total Reward: -8\n",
      "Episode: 1125, Total Reward: 3\n",
      "Episode: 1126, Total Reward: -10\n",
      "Episode: 1127, Total Reward: 14\n",
      "Episode: 1128, Total Reward: 8\n",
      "Episode: 1129, Total Reward: -16\n",
      "Episode: 1130, Total Reward: 1\n",
      "Episode: 1131, Total Reward: -17\n",
      "Episode: 1132, Total Reward: 8\n",
      "Episode: 1133, Total Reward: 10\n",
      "Episode: 1134, Total Reward: -26\n",
      "Episode: 1135, Total Reward: 13\n",
      "Episode: 1136, Total Reward: 6\n",
      "Episode: 1137, Total Reward: 4\n",
      "Episode: 1138, Total Reward: 10\n",
      "Episode: 1139, Total Reward: 8\n",
      "Episode: 1140, Total Reward: 3\n",
      "Episode: 1141, Total Reward: 9\n",
      "Episode: 1142, Total Reward: 5\n",
      "Episode: 1143, Total Reward: 2\n",
      "Episode: 1144, Total Reward: -7\n",
      "Episode: 1145, Total Reward: 11\n",
      "Episode: 1146, Total Reward: 3\n",
      "Episode: 1147, Total Reward: 6\n",
      "Episode: 1148, Total Reward: -8\n",
      "Episode: 1149, Total Reward: -41\n",
      "Episode: 1150, Total Reward: 10\n",
      "Episode: 1151, Total Reward: 7\n",
      "Episode: 1152, Total Reward: 11\n",
      "Episode: 1153, Total Reward: -1\n",
      "Episode: 1154, Total Reward: 13\n",
      "Episode: 1155, Total Reward: -17\n",
      "Episode: 1156, Total Reward: 7\n",
      "Episode: 1157, Total Reward: 12\n",
      "Episode: 1158, Total Reward: 11\n",
      "Episode: 1159, Total Reward: 11\n",
      "Episode: 1160, Total Reward: 4\n",
      "Episode: 1161, Total Reward: -20\n",
      "Episode: 1162, Total Reward: -3\n",
      "Episode: 1163, Total Reward: 8\n",
      "Episode: 1164, Total Reward: 9\n",
      "Episode: 1165, Total Reward: 10\n",
      "Episode: 1166, Total Reward: 2\n",
      "Episode: 1167, Total Reward: 4\n",
      "Episode: 1168, Total Reward: -4\n",
      "Episode: 1169, Total Reward: -26\n",
      "Episode: 1170, Total Reward: 2\n",
      "Episode: 1171, Total Reward: 8\n",
      "Episode: 1172, Total Reward: -36\n",
      "Episode: 1173, Total Reward: -12\n",
      "Episode: 1174, Total Reward: 9\n",
      "Episode: 1175, Total Reward: -27\n",
      "Episode: 1176, Total Reward: 10\n",
      "Episode: 1177, Total Reward: 7\n",
      "Episode: 1178, Total Reward: -14\n",
      "Episode: 1179, Total Reward: -32\n",
      "Episode: 1180, Total Reward: 7\n",
      "Episode: 1181, Total Reward: 8\n",
      "Episode: 1182, Total Reward: 7\n",
      "Episode: 1183, Total Reward: -67\n",
      "Episode: 1184, Total Reward: 11\n",
      "Episode: 1185, Total Reward: 14\n",
      "Episode: 1186, Total Reward: -11\n",
      "Episode: 1187, Total Reward: 11\n",
      "Episode: 1188, Total Reward: 5\n",
      "Episode: 1189, Total Reward: 10\n",
      "Episode: 1190, Total Reward: 10\n",
      "Episode: 1191, Total Reward: 6\n",
      "Episode: 1192, Total Reward: 4\n",
      "Episode: 1193, Total Reward: 7\n",
      "Episode: 1194, Total Reward: 10\n",
      "Episode: 1195, Total Reward: 9\n",
      "Episode: 1196, Total Reward: -7\n",
      "Episode: 1197, Total Reward: 14\n",
      "Episode: 1198, Total Reward: 11\n",
      "Episode: 1199, Total Reward: 6\n",
      "Episode: 1200, Total Reward: -3\n",
      "Episode: 1201, Total Reward: -18\n",
      "Episode: 1202, Total Reward: 12\n",
      "Episode: 1203, Total Reward: 11\n",
      "Episode: 1204, Total Reward: 6\n",
      "Episode: 1205, Total Reward: 10\n",
      "Episode: 1206, Total Reward: 9\n",
      "Episode: 1207, Total Reward: 7\n",
      "Episode: 1208, Total Reward: 7\n",
      "Episode: 1209, Total Reward: 8\n",
      "Episode: 1210, Total Reward: 1\n",
      "Episode: 1211, Total Reward: 2\n",
      "Episode: 1212, Total Reward: -5\n",
      "Episode: 1213, Total Reward: -10\n",
      "Episode: 1214, Total Reward: 11\n",
      "Episode: 1215, Total Reward: 13\n",
      "Episode: 1216, Total Reward: 8\n",
      "Episode: 1217, Total Reward: -10\n",
      "Episode: 1218, Total Reward: -1\n",
      "Episode: 1219, Total Reward: 10\n",
      "Episode: 1220, Total Reward: 7\n",
      "Episode: 1221, Total Reward: 1\n",
      "Episode: 1222, Total Reward: 9\n",
      "Episode: 1223, Total Reward: -3\n",
      "Episode: 1224, Total Reward: 3\n",
      "Episode: 1225, Total Reward: 13\n",
      "Episode: 1226, Total Reward: 7\n",
      "Episode: 1227, Total Reward: -3\n",
      "Episode: 1228, Total Reward: 11\n",
      "Episode: 1229, Total Reward: 13\n",
      "Episode: 1230, Total Reward: 6\n",
      "Episode: 1231, Total Reward: 11\n",
      "Episode: 1232, Total Reward: 6\n",
      "Episode: 1233, Total Reward: 4\n",
      "Episode: 1234, Total Reward: 12\n",
      "Episode: 1235, Total Reward: 1\n",
      "Episode: 1236, Total Reward: 7\n",
      "Episode: 1237, Total Reward: 14\n",
      "Episode: 1238, Total Reward: 4\n",
      "Episode: 1239, Total Reward: 5\n",
      "Episode: 1240, Total Reward: -14\n",
      "Episode: 1241, Total Reward: -7\n",
      "Episode: 1242, Total Reward: 12\n",
      "Episode: 1243, Total Reward: 4\n",
      "Episode: 1244, Total Reward: 1\n",
      "Episode: 1245, Total Reward: 10\n",
      "Episode: 1246, Total Reward: -5\n",
      "Episode: 1247, Total Reward: 12\n",
      "Episode: 1248, Total Reward: 2\n",
      "Episode: 1249, Total Reward: 4\n",
      "Episode: 1250, Total Reward: 8\n",
      "Episode: 1251, Total Reward: 3\n",
      "Episode: 1252, Total Reward: 1\n",
      "Episode: 1253, Total Reward: 8\n",
      "Episode: 1254, Total Reward: 7\n",
      "Episode: 1255, Total Reward: 11\n",
      "Episode: 1256, Total Reward: 3\n",
      "Episode: 1257, Total Reward: 9\n",
      "Episode: 1258, Total Reward: 7\n",
      "Episode: 1259, Total Reward: 4\n",
      "Episode: 1260, Total Reward: -9\n",
      "Episode: 1261, Total Reward: 9\n",
      "Episode: 1262, Total Reward: 8\n",
      "Episode: 1263, Total Reward: 8\n",
      "Episode: 1264, Total Reward: 9\n",
      "Episode: 1265, Total Reward: -3\n",
      "Episode: 1266, Total Reward: 6\n",
      "Episode: 1267, Total Reward: 9\n",
      "Episode: 1268, Total Reward: 10\n",
      "Episode: 1269, Total Reward: -4\n",
      "Episode: 1270, Total Reward: -1\n",
      "Episode: 1271, Total Reward: 8\n",
      "Episode: 1272, Total Reward: -1\n",
      "Episode: 1273, Total Reward: -4\n",
      "Episode: 1274, Total Reward: 7\n",
      "Episode: 1275, Total Reward: 9\n",
      "Episode: 1276, Total Reward: 8\n",
      "Episode: 1277, Total Reward: 2\n",
      "Episode: 1278, Total Reward: 5\n",
      "Episode: 1279, Total Reward: 7\n",
      "Episode: 1280, Total Reward: -3\n",
      "Episode: 1281, Total Reward: 11\n",
      "Episode: 1282, Total Reward: 10\n",
      "Episode: 1283, Total Reward: 7\n",
      "Episode: 1284, Total Reward: 9\n",
      "Episode: 1285, Total Reward: 10\n",
      "Episode: 1286, Total Reward: 6\n",
      "Episode: 1287, Total Reward: 5\n",
      "Episode: 1288, Total Reward: 10\n",
      "Episode: 1289, Total Reward: -2\n",
      "Episode: 1290, Total Reward: 3\n",
      "Episode: 1291, Total Reward: -3\n",
      "Episode: 1292, Total Reward: 9\n",
      "Episode: 1293, Total Reward: 1\n",
      "Episode: 1294, Total Reward: 3\n",
      "Episode: 1295, Total Reward: -42\n",
      "Episode: 1296, Total Reward: 8\n",
      "Episode: 1297, Total Reward: -1\n",
      "Episode: 1298, Total Reward: 3\n",
      "Episode: 1299, Total Reward: 12\n",
      "Episode: 1300, Total Reward: 1\n",
      "Episode: 1301, Total Reward: 9\n",
      "Episode: 1302, Total Reward: 2\n",
      "Episode: 1303, Total Reward: 9\n",
      "Episode: 1304, Total Reward: 12\n",
      "Episode: 1305, Total Reward: -9\n",
      "Episode: 1306, Total Reward: -13\n",
      "Episode: 1307, Total Reward: 10\n",
      "Episode: 1308, Total Reward: 6\n",
      "Episode: 1309, Total Reward: 14\n",
      "Episode: 1310, Total Reward: 8\n",
      "Episode: 1311, Total Reward: 6\n",
      "Episode: 1312, Total Reward: -11\n",
      "Episode: 1313, Total Reward: 12\n",
      "Episode: 1314, Total Reward: -1\n",
      "Episode: 1315, Total Reward: 6\n",
      "Episode: 1316, Total Reward: 10\n",
      "Episode: 1317, Total Reward: 5\n",
      "Episode: 1318, Total Reward: 7\n",
      "Episode: 1319, Total Reward: 11\n",
      "Episode: 1320, Total Reward: 8\n",
      "Episode: 1321, Total Reward: 10\n",
      "Episode: 1322, Total Reward: 10\n",
      "Episode: 1323, Total Reward: -32\n",
      "Episode: 1324, Total Reward: 8\n",
      "Episode: 1325, Total Reward: 1\n",
      "Episode: 1326, Total Reward: 1\n",
      "Episode: 1327, Total Reward: 10\n",
      "Episode: 1328, Total Reward: 5\n",
      "Episode: 1329, Total Reward: 9\n",
      "Episode: 1330, Total Reward: 6\n",
      "Episode: 1331, Total Reward: -13\n",
      "Episode: 1332, Total Reward: 9\n",
      "Episode: 1333, Total Reward: 8\n",
      "Episode: 1334, Total Reward: 10\n",
      "Episode: 1335, Total Reward: 4\n",
      "Episode: 1336, Total Reward: 8\n",
      "Episode: 1337, Total Reward: 6\n",
      "Episode: 1338, Total Reward: 8\n",
      "Episode: 1339, Total Reward: 3\n",
      "Episode: 1340, Total Reward: 9\n",
      "Episode: 1341, Total Reward: 8\n",
      "Episode: 1342, Total Reward: -4\n",
      "Episode: 1343, Total Reward: 10\n",
      "Episode: 1344, Total Reward: 3\n",
      "Episode: 1345, Total Reward: 10\n",
      "Episode: 1346, Total Reward: 2\n",
      "Episode: 1347, Total Reward: 11\n",
      "Episode: 1348, Total Reward: 7\n",
      "Episode: 1349, Total Reward: -15\n",
      "Episode: 1350, Total Reward: 8\n",
      "Episode: 1351, Total Reward: -10\n",
      "Episode: 1352, Total Reward: -10\n",
      "Episode: 1353, Total Reward: 14\n",
      "Episode: 1354, Total Reward: 6\n",
      "Episode: 1355, Total Reward: 4\n",
      "Episode: 1356, Total Reward: -1\n",
      "Episode: 1357, Total Reward: 10\n",
      "Episode: 1358, Total Reward: 11\n",
      "Episode: 1359, Total Reward: 4\n",
      "Episode: 1360, Total Reward: 10\n",
      "Episode: 1361, Total Reward: 9\n",
      "Episode: 1362, Total Reward: 0\n",
      "Episode: 1363, Total Reward: 9\n",
      "Episode: 1364, Total Reward: -11\n",
      "Episode: 1365, Total Reward: 6\n",
      "Episode: 1366, Total Reward: 12\n",
      "Episode: 1367, Total Reward: 10\n",
      "Episode: 1368, Total Reward: 6\n",
      "Episode: 1369, Total Reward: 10\n",
      "Episode: 1370, Total Reward: -6\n",
      "Episode: 1371, Total Reward: 8\n",
      "Episode: 1372, Total Reward: 8\n",
      "Episode: 1373, Total Reward: 8\n",
      "Episode: 1374, Total Reward: 1\n",
      "Episode: 1375, Total Reward: 6\n",
      "Episode: 1376, Total Reward: 9\n",
      "Episode: 1377, Total Reward: -4\n",
      "Episode: 1378, Total Reward: 11\n",
      "Episode: 1379, Total Reward: -1\n",
      "Episode: 1380, Total Reward: -8\n",
      "Episode: 1381, Total Reward: -6\n",
      "Episode: 1382, Total Reward: 7\n",
      "Episode: 1383, Total Reward: 13\n",
      "Episode: 1384, Total Reward: 7\n",
      "Episode: 1385, Total Reward: 7\n",
      "Episode: 1386, Total Reward: 14\n",
      "Episode: 1387, Total Reward: 3\n",
      "Episode: 1388, Total Reward: 8\n",
      "Episode: 1389, Total Reward: 12\n",
      "Episode: 1390, Total Reward: 15\n",
      "Episode: 1391, Total Reward: -4\n",
      "Episode: 1392, Total Reward: 7\n",
      "Episode: 1393, Total Reward: 10\n",
      "Episode: 1394, Total Reward: -9\n",
      "Episode: 1395, Total Reward: 10\n",
      "Episode: 1396, Total Reward: 4\n",
      "Episode: 1397, Total Reward: 0\n",
      "Episode: 1398, Total Reward: 10\n",
      "Episode: 1399, Total Reward: -19\n",
      "Episode: 1400, Total Reward: -6\n",
      "Episode: 1401, Total Reward: -21\n",
      "Episode: 1402, Total Reward: 15\n",
      "Episode: 1403, Total Reward: 11\n",
      "Episode: 1404, Total Reward: 4\n",
      "Episode: 1405, Total Reward: 9\n",
      "Episode: 1406, Total Reward: 9\n",
      "Episode: 1407, Total Reward: 5\n",
      "Episode: 1408, Total Reward: -6\n",
      "Episode: 1409, Total Reward: 7\n",
      "Episode: 1410, Total Reward: 2\n",
      "Episode: 1411, Total Reward: 3\n",
      "Episode: 1412, Total Reward: 2\n",
      "Episode: 1413, Total Reward: 3\n",
      "Episode: 1414, Total Reward: 11\n",
      "Episode: 1415, Total Reward: 6\n",
      "Episode: 1416, Total Reward: 12\n",
      "Episode: 1417, Total Reward: 3\n",
      "Episode: 1418, Total Reward: 5\n",
      "Episode: 1419, Total Reward: 6\n",
      "Episode: 1420, Total Reward: 3\n",
      "Episode: 1421, Total Reward: 11\n",
      "Episode: 1422, Total Reward: 5\n",
      "Episode: 1423, Total Reward: 8\n",
      "Episode: 1424, Total Reward: 8\n",
      "Episode: 1425, Total Reward: 10\n",
      "Episode: 1426, Total Reward: 1\n",
      "Episode: 1427, Total Reward: 7\n",
      "Episode: 1428, Total Reward: 1\n",
      "Episode: 1429, Total Reward: 7\n",
      "Episode: 1430, Total Reward: 7\n",
      "Episode: 1431, Total Reward: 6\n",
      "Episode: 1432, Total Reward: -8\n",
      "Episode: 1433, Total Reward: 8\n",
      "Episode: 1434, Total Reward: 9\n",
      "Episode: 1435, Total Reward: -17\n",
      "Episode: 1436, Total Reward: 4\n",
      "Episode: 1437, Total Reward: 11\n",
      "Episode: 1438, Total Reward: 8\n",
      "Episode: 1439, Total Reward: 13\n",
      "Episode: 1440, Total Reward: 13\n",
      "Episode: 1441, Total Reward: 6\n",
      "Episode: 1442, Total Reward: 7\n",
      "Episode: 1443, Total Reward: 11\n",
      "Episode: 1444, Total Reward: -1\n",
      "Episode: 1445, Total Reward: 8\n",
      "Episode: 1446, Total Reward: 0\n",
      "Episode: 1447, Total Reward: 9\n",
      "Episode: 1448, Total Reward: 4\n",
      "Episode: 1449, Total Reward: 0\n",
      "Episode: 1450, Total Reward: 8\n",
      "Episode: 1451, Total Reward: 10\n",
      "Episode: 1452, Total Reward: 8\n",
      "Episode: 1453, Total Reward: 3\n",
      "Episode: 1454, Total Reward: 12\n",
      "Episode: 1455, Total Reward: -1\n",
      "Episode: 1456, Total Reward: 5\n",
      "Episode: 1457, Total Reward: 11\n",
      "Episode: 1458, Total Reward: 5\n",
      "Episode: 1459, Total Reward: 11\n",
      "Episode: 1460, Total Reward: -4\n",
      "Episode: 1461, Total Reward: 8\n",
      "Episode: 1462, Total Reward: 12\n",
      "Episode: 1463, Total Reward: 10\n",
      "Episode: 1464, Total Reward: 5\n",
      "Episode: 1465, Total Reward: 2\n",
      "Episode: 1466, Total Reward: 11\n",
      "Episode: 1467, Total Reward: -15\n",
      "Episode: 1468, Total Reward: 2\n",
      "Episode: 1469, Total Reward: 13\n",
      "Episode: 1470, Total Reward: 8\n",
      "Episode: 1471, Total Reward: -34\n",
      "Episode: 1472, Total Reward: -11\n",
      "Episode: 1473, Total Reward: 7\n",
      "Episode: 1474, Total Reward: -6\n",
      "Episode: 1475, Total Reward: 8\n",
      "Episode: 1476, Total Reward: 13\n",
      "Episode: 1477, Total Reward: -6\n",
      "Episode: 1478, Total Reward: 8\n",
      "Episode: 1479, Total Reward: 0\n",
      "Episode: 1480, Total Reward: -7\n",
      "Episode: 1481, Total Reward: 2\n",
      "Episode: 1482, Total Reward: 5\n",
      "Episode: 1483, Total Reward: 11\n",
      "Episode: 1484, Total Reward: -21\n",
      "Episode: 1485, Total Reward: 5\n",
      "Episode: 1486, Total Reward: 6\n",
      "Episode: 1487, Total Reward: 8\n",
      "Episode: 1488, Total Reward: 2\n",
      "Episode: 1489, Total Reward: 15\n",
      "Episode: 1490, Total Reward: 12\n",
      "Episode: 1491, Total Reward: 13\n",
      "Episode: 1492, Total Reward: 12\n",
      "Episode: 1493, Total Reward: 6\n",
      "Episode: 1494, Total Reward: 4\n",
      "Episode: 1495, Total Reward: 7\n",
      "Episode: 1496, Total Reward: 6\n",
      "Episode: 1497, Total Reward: 7\n",
      "Episode: 1498, Total Reward: 12\n",
      "Episode: 1499, Total Reward: 12\n",
      "Episode: 1500, Total Reward: 9\n",
      "Episode: 1501, Total Reward: 6\n",
      "Episode: 1502, Total Reward: 11\n",
      "Episode: 1503, Total Reward: 4\n",
      "Episode: 1504, Total Reward: 6\n",
      "Episode: 1505, Total Reward: 4\n",
      "Episode: 1506, Total Reward: 5\n",
      "Episode: 1507, Total Reward: 3\n",
      "Episode: 1508, Total Reward: -23\n",
      "Episode: 1509, Total Reward: 7\n",
      "Episode: 1510, Total Reward: 13\n",
      "Episode: 1511, Total Reward: 10\n",
      "Episode: 1512, Total Reward: 9\n",
      "Episode: 1513, Total Reward: 11\n",
      "Episode: 1514, Total Reward: 11\n",
      "Episode: 1515, Total Reward: 6\n",
      "Episode: 1516, Total Reward: 10\n",
      "Episode: 1517, Total Reward: 7\n",
      "Episode: 1518, Total Reward: 12\n",
      "Episode: 1519, Total Reward: 6\n",
      "Episode: 1520, Total Reward: 5\n",
      "Episode: 1521, Total Reward: 13\n",
      "Episode: 1522, Total Reward: 12\n",
      "Episode: 1523, Total Reward: 9\n",
      "Episode: 1524, Total Reward: 8\n",
      "Episode: 1525, Total Reward: 13\n",
      "Episode: 1526, Total Reward: 9\n",
      "Episode: 1527, Total Reward: 4\n",
      "Episode: 1528, Total Reward: 9\n",
      "Episode: 1529, Total Reward: 13\n",
      "Episode: 1530, Total Reward: 8\n",
      "Episode: 1531, Total Reward: -2\n",
      "Episode: 1532, Total Reward: 6\n",
      "Episode: 1533, Total Reward: 8\n",
      "Episode: 1534, Total Reward: 13\n",
      "Episode: 1535, Total Reward: 0\n",
      "Episode: 1536, Total Reward: 11\n",
      "Episode: 1537, Total Reward: 7\n",
      "Episode: 1538, Total Reward: 6\n",
      "Episode: 1539, Total Reward: 12\n",
      "Episode: 1540, Total Reward: 6\n",
      "Episode: 1541, Total Reward: 7\n",
      "Episode: 1542, Total Reward: 8\n",
      "Episode: 1543, Total Reward: 11\n",
      "Episode: 1544, Total Reward: 14\n",
      "Episode: 1545, Total Reward: -10\n",
      "Episode: 1546, Total Reward: 8\n",
      "Episode: 1547, Total Reward: 8\n",
      "Episode: 1548, Total Reward: 6\n",
      "Episode: 1549, Total Reward: 7\n",
      "Episode: 1550, Total Reward: 6\n",
      "Episode: 1551, Total Reward: 7\n",
      "Episode: 1552, Total Reward: 9\n",
      "Episode: 1553, Total Reward: 10\n",
      "Episode: 1554, Total Reward: -2\n",
      "Episode: 1555, Total Reward: 6\n",
      "Episode: 1556, Total Reward: 14\n",
      "Episode: 1557, Total Reward: 9\n",
      "Episode: 1558, Total Reward: 9\n",
      "Episode: 1559, Total Reward: 13\n",
      "Episode: 1560, Total Reward: 0\n",
      "Episode: 1561, Total Reward: 7\n",
      "Episode: 1562, Total Reward: 7\n",
      "Episode: 1563, Total Reward: 5\n",
      "Episode: 1564, Total Reward: -3\n",
      "Episode: 1565, Total Reward: -7\n",
      "Episode: 1566, Total Reward: 10\n",
      "Episode: 1567, Total Reward: 5\n",
      "Episode: 1568, Total Reward: 5\n",
      "Episode: 1569, Total Reward: 6\n",
      "Episode: 1570, Total Reward: 13\n",
      "Episode: 1571, Total Reward: 4\n",
      "Episode: 1572, Total Reward: 12\n",
      "Episode: 1573, Total Reward: 14\n",
      "Episode: 1574, Total Reward: 7\n",
      "Episode: 1575, Total Reward: 2\n",
      "Episode: 1576, Total Reward: 8\n",
      "Episode: 1577, Total Reward: 9\n",
      "Episode: 1578, Total Reward: 6\n",
      "Episode: 1579, Total Reward: 9\n",
      "Episode: 1580, Total Reward: 6\n",
      "Episode: 1581, Total Reward: 12\n",
      "Episode: 1582, Total Reward: 5\n",
      "Episode: 1583, Total Reward: 9\n",
      "Episode: 1584, Total Reward: 7\n",
      "Episode: 1585, Total Reward: -27\n",
      "Episode: 1586, Total Reward: 7\n",
      "Episode: 1587, Total Reward: 14\n",
      "Episode: 1588, Total Reward: 6\n",
      "Episode: 1589, Total Reward: 8\n",
      "Episode: 1590, Total Reward: -4\n",
      "Episode: 1591, Total Reward: 11\n",
      "Episode: 1592, Total Reward: 12\n",
      "Episode: 1593, Total Reward: 6\n",
      "Episode: 1594, Total Reward: 7\n",
      "Episode: 1595, Total Reward: 9\n",
      "Episode: 1596, Total Reward: 9\n",
      "Episode: 1597, Total Reward: 1\n",
      "Episode: 1598, Total Reward: 11\n",
      "Episode: 1599, Total Reward: 6\n",
      "Episode: 1600, Total Reward: 8\n",
      "Episode: 1601, Total Reward: 7\n",
      "Episode: 1602, Total Reward: 9\n",
      "Episode: 1603, Total Reward: 7\n",
      "Episode: 1604, Total Reward: 0\n",
      "Episode: 1605, Total Reward: 9\n",
      "Episode: 1606, Total Reward: 13\n",
      "Episode: 1607, Total Reward: 1\n",
      "Episode: 1608, Total Reward: -4\n",
      "Episode: 1609, Total Reward: 2\n",
      "Episode: 1610, Total Reward: -4\n",
      "Episode: 1611, Total Reward: 7\n",
      "Episode: 1612, Total Reward: 0\n",
      "Episode: 1613, Total Reward: 14\n",
      "Episode: 1614, Total Reward: 9\n",
      "Episode: 1615, Total Reward: 6\n",
      "Episode: 1616, Total Reward: 9\n",
      "Episode: 1617, Total Reward: 12\n",
      "Episode: 1618, Total Reward: 4\n",
      "Episode: 1619, Total Reward: 6\n",
      "Episode: 1620, Total Reward: 14\n",
      "Episode: 1621, Total Reward: 6\n",
      "Episode: 1622, Total Reward: 7\n",
      "Episode: 1623, Total Reward: 7\n",
      "Episode: 1624, Total Reward: 4\n",
      "Episode: 1625, Total Reward: 8\n",
      "Episode: 1626, Total Reward: 9\n",
      "Episode: 1627, Total Reward: 10\n",
      "Episode: 1628, Total Reward: 7\n",
      "Episode: 1629, Total Reward: 5\n",
      "Episode: 1630, Total Reward: 9\n",
      "Episode: 1631, Total Reward: 10\n",
      "Episode: 1632, Total Reward: -1\n",
      "Episode: 1633, Total Reward: 6\n",
      "Episode: 1634, Total Reward: 9\n",
      "Episode: 1635, Total Reward: 11\n",
      "Episode: 1636, Total Reward: 11\n",
      "Episode: 1637, Total Reward: 6\n",
      "Episode: 1638, Total Reward: 13\n",
      "Episode: 1639, Total Reward: 7\n",
      "Episode: 1640, Total Reward: -2\n",
      "Episode: 1641, Total Reward: 12\n",
      "Episode: 1642, Total Reward: 7\n",
      "Episode: 1643, Total Reward: 5\n",
      "Episode: 1644, Total Reward: 8\n",
      "Episode: 1645, Total Reward: 7\n",
      "Episode: 1646, Total Reward: 9\n",
      "Episode: 1647, Total Reward: 9\n",
      "Episode: 1648, Total Reward: 11\n",
      "Episode: 1649, Total Reward: 13\n",
      "Episode: 1650, Total Reward: -12\n",
      "Episode: 1651, Total Reward: 10\n",
      "Episode: 1652, Total Reward: 9\n",
      "Episode: 1653, Total Reward: 8\n",
      "Episode: 1654, Total Reward: 11\n",
      "Episode: 1655, Total Reward: 9\n",
      "Episode: 1656, Total Reward: 10\n",
      "Episode: 1657, Total Reward: 5\n",
      "Episode: 1658, Total Reward: 1\n",
      "Episode: 1659, Total Reward: 7\n",
      "Episode: 1660, Total Reward: 9\n",
      "Episode: 1661, Total Reward: 6\n",
      "Episode: 1662, Total Reward: 1\n",
      "Episode: 1663, Total Reward: 7\n",
      "Episode: 1664, Total Reward: 13\n",
      "Episode: 1665, Total Reward: 4\n",
      "Episode: 1666, Total Reward: 4\n",
      "Episode: 1667, Total Reward: 2\n",
      "Episode: 1668, Total Reward: 6\n",
      "Episode: 1669, Total Reward: 8\n",
      "Episode: 1670, Total Reward: -4\n",
      "Episode: 1671, Total Reward: 6\n",
      "Episode: 1672, Total Reward: 11\n",
      "Episode: 1673, Total Reward: 8\n",
      "Episode: 1674, Total Reward: 15\n",
      "Episode: 1675, Total Reward: 1\n",
      "Episode: 1676, Total Reward: 8\n",
      "Episode: 1677, Total Reward: 3\n",
      "Episode: 1678, Total Reward: 13\n",
      "Episode: 1679, Total Reward: -20\n",
      "Episode: 1680, Total Reward: 5\n",
      "Episode: 1681, Total Reward: 11\n",
      "Episode: 1682, Total Reward: 9\n",
      "Episode: 1683, Total Reward: 2\n",
      "Episode: 1684, Total Reward: -5\n",
      "Episode: 1685, Total Reward: 8\n",
      "Episode: 1686, Total Reward: 14\n",
      "Episode: 1687, Total Reward: 6\n",
      "Episode: 1688, Total Reward: 10\n",
      "Episode: 1689, Total Reward: 7\n",
      "Episode: 1690, Total Reward: 10\n",
      "Episode: 1691, Total Reward: 8\n",
      "Episode: 1692, Total Reward: 7\n",
      "Episode: 1693, Total Reward: 10\n",
      "Episode: 1694, Total Reward: 4\n",
      "Episode: 1695, Total Reward: 8\n",
      "Episode: 1696, Total Reward: 14\n",
      "Episode: 1697, Total Reward: 10\n",
      "Episode: 1698, Total Reward: 7\n",
      "Episode: 1699, Total Reward: 8\n",
      "Episode: 1700, Total Reward: 8\n",
      "Episode: 1701, Total Reward: 6\n",
      "Episode: 1702, Total Reward: 3\n",
      "Episode: 1703, Total Reward: 10\n",
      "Episode: 1704, Total Reward: 11\n",
      "Episode: 1705, Total Reward: 7\n",
      "Episode: 1706, Total Reward: 8\n",
      "Episode: 1707, Total Reward: 8\n",
      "Episode: 1708, Total Reward: 10\n",
      "Episode: 1709, Total Reward: 9\n",
      "Episode: 1710, Total Reward: 8\n",
      "Episode: 1711, Total Reward: 6\n",
      "Episode: 1712, Total Reward: 9\n",
      "Episode: 1713, Total Reward: 10\n",
      "Episode: 1714, Total Reward: 8\n",
      "Episode: 1715, Total Reward: 11\n",
      "Episode: 1716, Total Reward: 12\n",
      "Episode: 1717, Total Reward: 5\n",
      "Episode: 1718, Total Reward: 9\n",
      "Episode: 1719, Total Reward: 10\n",
      "Episode: 1720, Total Reward: 9\n",
      "Episode: 1721, Total Reward: 13\n",
      "Episode: 1722, Total Reward: 9\n",
      "Episode: 1723, Total Reward: 8\n",
      "Episode: 1724, Total Reward: 10\n",
      "Episode: 1725, Total Reward: 7\n",
      "Episode: 1726, Total Reward: 11\n",
      "Episode: 1727, Total Reward: 9\n",
      "Episode: 1728, Total Reward: 5\n",
      "Episode: 1729, Total Reward: 8\n",
      "Episode: 1730, Total Reward: 5\n",
      "Episode: 1731, Total Reward: 6\n",
      "Episode: 1732, Total Reward: 9\n",
      "Episode: 1733, Total Reward: 4\n",
      "Episode: 1734, Total Reward: 9\n",
      "Episode: 1735, Total Reward: 8\n",
      "Episode: 1736, Total Reward: 5\n",
      "Episode: 1737, Total Reward: 10\n",
      "Episode: 1738, Total Reward: 3\n",
      "Episode: 1739, Total Reward: -6\n",
      "Episode: 1740, Total Reward: 6\n",
      "Episode: 1741, Total Reward: 0\n",
      "Episode: 1742, Total Reward: 5\n",
      "Episode: 1743, Total Reward: 9\n",
      "Episode: 1744, Total Reward: 6\n",
      "Episode: 1745, Total Reward: 10\n",
      "Episode: 1746, Total Reward: 12\n",
      "Episode: 1747, Total Reward: -9\n",
      "Episode: 1748, Total Reward: 14\n",
      "Episode: 1749, Total Reward: 7\n",
      "Episode: 1750, Total Reward: 11\n",
      "Episode: 1751, Total Reward: 7\n",
      "Episode: 1752, Total Reward: 8\n",
      "Episode: 1753, Total Reward: -7\n",
      "Episode: 1754, Total Reward: 7\n",
      "Episode: 1755, Total Reward: 5\n",
      "Episode: 1756, Total Reward: 9\n",
      "Episode: 1757, Total Reward: 5\n",
      "Episode: 1758, Total Reward: 5\n",
      "Episode: 1759, Total Reward: 9\n",
      "Episode: 1760, Total Reward: 11\n",
      "Episode: 1761, Total Reward: 6\n",
      "Episode: 1762, Total Reward: 0\n",
      "Episode: 1763, Total Reward: -4\n",
      "Episode: 1764, Total Reward: 6\n",
      "Episode: 1765, Total Reward: 4\n",
      "Episode: 1766, Total Reward: 8\n",
      "Episode: 1767, Total Reward: 11\n",
      "Episode: 1768, Total Reward: 5\n",
      "Episode: 1769, Total Reward: 13\n",
      "Episode: 1770, Total Reward: 8\n",
      "Episode: 1771, Total Reward: 9\n",
      "Episode: 1772, Total Reward: 6\n",
      "Episode: 1773, Total Reward: 7\n",
      "Episode: 1774, Total Reward: 11\n",
      "Episode: 1775, Total Reward: 9\n",
      "Episode: 1776, Total Reward: 9\n",
      "Episode: 1777, Total Reward: 6\n",
      "Episode: 1778, Total Reward: 6\n",
      "Episode: 1779, Total Reward: 10\n",
      "Episode: 1780, Total Reward: 8\n",
      "Episode: 1781, Total Reward: 12\n",
      "Episode: 1782, Total Reward: -2\n",
      "Episode: 1783, Total Reward: 13\n",
      "Episode: 1784, Total Reward: 12\n",
      "Episode: 1785, Total Reward: 6\n",
      "Episode: 1786, Total Reward: 8\n",
      "Episode: 1787, Total Reward: 6\n",
      "Episode: 1788, Total Reward: 8\n",
      "Episode: 1789, Total Reward: 7\n",
      "Episode: 1790, Total Reward: 10\n",
      "Episode: 1791, Total Reward: 7\n",
      "Episode: 1792, Total Reward: 9\n",
      "Episode: 1793, Total Reward: 9\n",
      "Episode: 1794, Total Reward: 0\n",
      "Episode: 1795, Total Reward: 15\n",
      "Episode: 1796, Total Reward: 11\n",
      "Episode: 1797, Total Reward: -2\n",
      "Episode: 1798, Total Reward: -12\n",
      "Episode: 1799, Total Reward: 1\n",
      "Episode: 1800, Total Reward: 8\n",
      "Episode: 1801, Total Reward: 6\n",
      "Episode: 1802, Total Reward: 8\n",
      "Episode: 1803, Total Reward: 7\n",
      "Episode: 1804, Total Reward: 6\n",
      "Episode: 1805, Total Reward: 9\n",
      "Episode: 1806, Total Reward: 12\n",
      "Episode: 1807, Total Reward: 6\n",
      "Episode: 1808, Total Reward: 9\n",
      "Episode: 1809, Total Reward: 9\n",
      "Episode: 1810, Total Reward: -1\n",
      "Episode: 1811, Total Reward: 10\n",
      "Episode: 1812, Total Reward: 9\n",
      "Episode: 1813, Total Reward: 11\n",
      "Episode: 1814, Total Reward: 12\n",
      "Episode: 1815, Total Reward: 7\n",
      "Episode: 1816, Total Reward: 6\n",
      "Episode: 1817, Total Reward: 7\n",
      "Episode: 1818, Total Reward: 11\n",
      "Episode: 1819, Total Reward: 8\n",
      "Episode: 1820, Total Reward: -5\n",
      "Episode: 1821, Total Reward: -1\n",
      "Episode: 1822, Total Reward: 4\n",
      "Episode: 1823, Total Reward: 6\n",
      "Episode: 1824, Total Reward: -17\n",
      "Episode: 1825, Total Reward: 8\n",
      "Episode: 1826, Total Reward: 10\n",
      "Episode: 1827, Total Reward: 12\n",
      "Episode: 1828, Total Reward: -4\n",
      "Episode: 1829, Total Reward: 9\n",
      "Episode: 1830, Total Reward: 8\n",
      "Episode: 1831, Total Reward: 9\n",
      "Episode: 1832, Total Reward: -2\n",
      "Episode: 1833, Total Reward: 2\n",
      "Episode: 1834, Total Reward: 12\n",
      "Episode: 1835, Total Reward: 11\n",
      "Episode: 1836, Total Reward: 3\n",
      "Episode: 1837, Total Reward: 14\n",
      "Episode: 1838, Total Reward: 9\n",
      "Episode: 1839, Total Reward: 9\n",
      "Episode: 1840, Total Reward: 8\n",
      "Episode: 1841, Total Reward: 3\n",
      "Episode: 1842, Total Reward: 11\n",
      "Episode: 1843, Total Reward: 10\n",
      "Episode: 1844, Total Reward: 5\n",
      "Episode: 1845, Total Reward: 9\n",
      "Episode: 1846, Total Reward: 12\n",
      "Episode: 1847, Total Reward: 8\n",
      "Episode: 1848, Total Reward: 9\n",
      "Episode: 1849, Total Reward: -2\n",
      "Episode: 1850, Total Reward: 7\n",
      "Episode: 1851, Total Reward: 7\n",
      "Episode: 1852, Total Reward: 9\n",
      "Episode: 1853, Total Reward: 5\n",
      "Episode: 1854, Total Reward: 8\n",
      "Episode: 1855, Total Reward: 8\n",
      "Episode: 1856, Total Reward: 12\n",
      "Episode: 1857, Total Reward: 9\n",
      "Episode: 1858, Total Reward: 6\n",
      "Episode: 1859, Total Reward: 11\n",
      "Episode: 1860, Total Reward: 6\n",
      "Episode: 1861, Total Reward: 12\n",
      "Episode: 1862, Total Reward: 10\n",
      "Episode: 1863, Total Reward: 13\n",
      "Episode: 1864, Total Reward: -14\n",
      "Episode: 1865, Total Reward: 6\n",
      "Episode: 1866, Total Reward: 13\n",
      "Episode: 1867, Total Reward: 12\n",
      "Episode: 1868, Total Reward: 12\n",
      "Episode: 1869, Total Reward: 10\n",
      "Episode: 1870, Total Reward: 12\n",
      "Episode: 1871, Total Reward: 6\n",
      "Episode: 1872, Total Reward: 11\n",
      "Episode: 1873, Total Reward: 9\n",
      "Episode: 1874, Total Reward: 10\n",
      "Episode: 1875, Total Reward: 9\n",
      "Episode: 1876, Total Reward: 10\n",
      "Episode: 1877, Total Reward: 11\n",
      "Episode: 1878, Total Reward: -1\n",
      "Episode: 1879, Total Reward: 13\n",
      "Episode: 1880, Total Reward: 11\n",
      "Episode: 1881, Total Reward: 10\n",
      "Episode: 1882, Total Reward: 10\n",
      "Episode: 1883, Total Reward: 13\n",
      "Episode: 1884, Total Reward: 6\n",
      "Episode: 1885, Total Reward: 8\n",
      "Episode: 1886, Total Reward: 4\n",
      "Episode: 1887, Total Reward: 1\n",
      "Episode: 1888, Total Reward: 6\n",
      "Episode: 1889, Total Reward: 8\n",
      "Episode: 1890, Total Reward: -7\n",
      "Episode: 1891, Total Reward: 6\n",
      "Episode: 1892, Total Reward: 8\n",
      "Episode: 1893, Total Reward: 6\n",
      "Episode: 1894, Total Reward: 5\n",
      "Episode: 1895, Total Reward: 6\n",
      "Episode: 1896, Total Reward: -6\n",
      "Episode: 1897, Total Reward: 5\n",
      "Episode: 1898, Total Reward: 10\n",
      "Episode: 1899, Total Reward: -7\n",
      "Episode: 1900, Total Reward: 13\n",
      "Episode: 1901, Total Reward: 7\n",
      "Episode: 1902, Total Reward: 8\n",
      "Episode: 1903, Total Reward: 9\n",
      "Episode: 1904, Total Reward: -2\n",
      "Episode: 1905, Total Reward: 8\n",
      "Episode: 1906, Total Reward: 9\n",
      "Episode: 1907, Total Reward: 12\n",
      "Episode: 1908, Total Reward: 11\n",
      "Episode: 1909, Total Reward: 1\n",
      "Episode: 1910, Total Reward: 3\n",
      "Episode: 1911, Total Reward: 13\n",
      "Episode: 1912, Total Reward: -4\n",
      "Episode: 1913, Total Reward: 9\n",
      "Episode: 1914, Total Reward: 7\n",
      "Episode: 1915, Total Reward: 5\n",
      "Episode: 1916, Total Reward: 8\n",
      "Episode: 1917, Total Reward: 9\n",
      "Episode: 1918, Total Reward: 7\n",
      "Episode: 1919, Total Reward: 6\n",
      "Episode: 1920, Total Reward: 8\n",
      "Episode: 1921, Total Reward: 0\n",
      "Episode: 1922, Total Reward: 12\n",
      "Episode: 1923, Total Reward: 8\n",
      "Episode: 1924, Total Reward: 13\n",
      "Episode: 1925, Total Reward: 9\n",
      "Episode: 1926, Total Reward: 6\n",
      "Episode: 1927, Total Reward: 1\n",
      "Episode: 1928, Total Reward: -4\n",
      "Episode: 1929, Total Reward: 9\n",
      "Episode: 1930, Total Reward: -1\n",
      "Episode: 1931, Total Reward: 9\n",
      "Episode: 1932, Total Reward: 5\n",
      "Episode: 1933, Total Reward: 6\n",
      "Episode: 1934, Total Reward: 10\n",
      "Episode: 1935, Total Reward: 10\n",
      "Episode: 1936, Total Reward: 5\n",
      "Episode: 1937, Total Reward: 0\n",
      "Episode: 1938, Total Reward: 7\n",
      "Episode: 1939, Total Reward: 12\n",
      "Episode: 1940, Total Reward: 7\n",
      "Episode: 1941, Total Reward: 7\n",
      "Episode: 1942, Total Reward: 10\n",
      "Episode: 1943, Total Reward: 8\n",
      "Episode: 1944, Total Reward: 6\n",
      "Episode: 1945, Total Reward: 7\n",
      "Episode: 1946, Total Reward: 1\n",
      "Episode: 1947, Total Reward: 11\n",
      "Episode: 1948, Total Reward: 1\n",
      "Episode: 1949, Total Reward: 9\n",
      "Episode: 1950, Total Reward: 3\n",
      "Episode: 1951, Total Reward: 8\n",
      "Episode: 1952, Total Reward: 4\n",
      "Episode: 1953, Total Reward: 11\n",
      "Episode: 1954, Total Reward: 9\n",
      "Episode: 1955, Total Reward: 14\n",
      "Episode: 1956, Total Reward: 5\n",
      "Episode: 1957, Total Reward: 5\n",
      "Episode: 1958, Total Reward: 5\n",
      "Episode: 1959, Total Reward: 8\n",
      "Episode: 1960, Total Reward: 5\n",
      "Episode: 1961, Total Reward: 8\n",
      "Episode: 1962, Total Reward: 7\n",
      "Episode: 1963, Total Reward: 7\n",
      "Episode: 1964, Total Reward: 3\n",
      "Episode: 1965, Total Reward: 6\n",
      "Episode: 1966, Total Reward: 10\n",
      "Episode: 1967, Total Reward: 10\n",
      "Episode: 1968, Total Reward: 6\n",
      "Episode: 1969, Total Reward: 9\n",
      "Episode: 1970, Total Reward: 4\n",
      "Episode: 1971, Total Reward: 7\n",
      "Episode: 1972, Total Reward: 7\n",
      "Episode: 1973, Total Reward: 6\n",
      "Episode: 1974, Total Reward: 6\n",
      "Episode: 1975, Total Reward: 10\n",
      "Episode: 1976, Total Reward: 6\n",
      "Episode: 1977, Total Reward: 6\n",
      "Episode: 1978, Total Reward: 8\n",
      "Episode: 1979, Total Reward: 7\n",
      "Episode: 1980, Total Reward: 9\n",
      "Episode: 1981, Total Reward: 9\n",
      "Episode: 1982, Total Reward: 14\n",
      "Episode: 1983, Total Reward: 9\n",
      "Episode: 1984, Total Reward: 5\n",
      "Episode: 1985, Total Reward: 9\n",
      "Episode: 1986, Total Reward: 8\n",
      "Episode: 1987, Total Reward: 9\n",
      "Episode: 1988, Total Reward: 14\n",
      "Episode: 1989, Total Reward: 5\n",
      "Episode: 1990, Total Reward: 8\n",
      "Episode: 1991, Total Reward: 12\n",
      "Episode: 1992, Total Reward: 5\n",
      "Episode: 1993, Total Reward: 7\n",
      "Episode: 1994, Total Reward: 11\n",
      "Episode: 1995, Total Reward: 6\n",
      "Episode: 1996, Total Reward: 2\n",
      "Episode: 1997, Total Reward: 12\n",
      "Episode: 1998, Total Reward: 9\n",
      "Episode: 1999, Total Reward: 5\n",
      "Episode: 2000, Total Reward: 9\n",
      "Episode: 2001, Total Reward: 2\n",
      "Episode: 2002, Total Reward: 5\n",
      "Episode: 2003, Total Reward: 7\n",
      "Episode: 2004, Total Reward: 6\n",
      "Episode: 2005, Total Reward: 4\n",
      "Episode: 2006, Total Reward: 8\n",
      "Episode: 2007, Total Reward: 5\n",
      "Episode: 2008, Total Reward: 5\n",
      "Episode: 2009, Total Reward: 9\n",
      "Episode: 2010, Total Reward: 9\n",
      "Episode: 2011, Total Reward: 5\n",
      "Episode: 2012, Total Reward: 7\n",
      "Episode: 2013, Total Reward: -4\n",
      "Episode: 2014, Total Reward: 2\n",
      "Episode: 2015, Total Reward: 5\n",
      "Episode: 2016, Total Reward: 5\n",
      "Episode: 2017, Total Reward: 11\n",
      "Episode: 2018, Total Reward: 1\n",
      "Episode: 2019, Total Reward: -1\n",
      "Episode: 2020, Total Reward: 6\n",
      "Episode: 2021, Total Reward: 4\n",
      "Episode: 2022, Total Reward: 3\n",
      "Episode: 2023, Total Reward: 3\n",
      "Episode: 2024, Total Reward: 9\n",
      "Episode: 2025, Total Reward: 6\n",
      "Episode: 2026, Total Reward: 4\n",
      "Episode: 2027, Total Reward: -1\n",
      "Episode: 2028, Total Reward: 7\n",
      "Episode: 2029, Total Reward: 10\n",
      "Episode: 2030, Total Reward: 12\n",
      "Episode: 2031, Total Reward: 10\n",
      "Episode: 2032, Total Reward: 14\n",
      "Episode: 2033, Total Reward: 9\n",
      "Episode: 2034, Total Reward: 9\n",
      "Episode: 2035, Total Reward: 6\n",
      "Episode: 2036, Total Reward: 5\n",
      "Episode: 2037, Total Reward: 4\n",
      "Episode: 2038, Total Reward: -1\n",
      "Episode: 2039, Total Reward: 8\n",
      "Episode: 2040, Total Reward: 6\n",
      "Episode: 2041, Total Reward: 8\n",
      "Episode: 2042, Total Reward: 12\n",
      "Episode: 2043, Total Reward: 7\n",
      "Episode: 2044, Total Reward: 15\n",
      "Episode: 2045, Total Reward: 2\n",
      "Episode: 2046, Total Reward: 9\n",
      "Episode: 2047, Total Reward: 11\n",
      "Episode: 2048, Total Reward: 14\n",
      "Episode: 2049, Total Reward: 3\n",
      "Episode: 2050, Total Reward: 14\n",
      "Episode: 2051, Total Reward: 8\n",
      "Episode: 2052, Total Reward: 1\n",
      "Episode: 2053, Total Reward: 5\n",
      "Episode: 2054, Total Reward: 5\n",
      "Episode: 2055, Total Reward: 10\n",
      "Episode: 2056, Total Reward: 1\n",
      "Episode: 2057, Total Reward: 5\n",
      "Episode: 2058, Total Reward: 7\n",
      "Episode: 2059, Total Reward: 9\n",
      "Episode: 2060, Total Reward: 5\n",
      "Episode: 2061, Total Reward: 7\n",
      "Episode: 2062, Total Reward: 10\n",
      "Episode: 2063, Total Reward: 10\n",
      "Episode: 2064, Total Reward: 10\n",
      "Episode: 2065, Total Reward: 7\n",
      "Episode: 2066, Total Reward: 12\n",
      "Episode: 2067, Total Reward: 11\n",
      "Episode: 2068, Total Reward: 9\n",
      "Episode: 2069, Total Reward: 9\n",
      "Episode: 2070, Total Reward: -10\n",
      "Episode: 2071, Total Reward: 7\n",
      "Episode: 2072, Total Reward: 9\n",
      "Episode: 2073, Total Reward: 7\n",
      "Episode: 2074, Total Reward: 8\n",
      "Episode: 2075, Total Reward: 10\n",
      "Episode: 2076, Total Reward: 10\n",
      "Episode: 2077, Total Reward: 5\n",
      "Episode: 2078, Total Reward: 6\n",
      "Episode: 2079, Total Reward: 6\n",
      "Episode: 2080, Total Reward: 12\n",
      "Episode: 2081, Total Reward: 4\n",
      "Episode: 2082, Total Reward: 12\n",
      "Episode: 2083, Total Reward: 4\n",
      "Episode: 2084, Total Reward: 3\n",
      "Episode: 2085, Total Reward: 9\n",
      "Episode: 2086, Total Reward: 4\n",
      "Episode: 2087, Total Reward: 5\n",
      "Episode: 2088, Total Reward: -5\n",
      "Episode: 2089, Total Reward: 6\n",
      "Episode: 2090, Total Reward: 12\n",
      "Episode: 2091, Total Reward: 6\n",
      "Episode: 2092, Total Reward: 9\n",
      "Episode: 2093, Total Reward: 7\n",
      "Episode: 2094, Total Reward: 5\n",
      "Episode: 2095, Total Reward: 7\n",
      "Episode: 2096, Total Reward: -9\n",
      "Episode: 2097, Total Reward: 7\n",
      "Episode: 2098, Total Reward: 7\n",
      "Episode: 2099, Total Reward: 8\n",
      "Episode: 2100, Total Reward: 9\n",
      "Episode: 2101, Total Reward: 11\n",
      "Episode: 2102, Total Reward: 0\n",
      "Episode: 2103, Total Reward: 10\n",
      "Episode: 2104, Total Reward: 9\n",
      "Episode: 2105, Total Reward: 5\n",
      "Episode: 2106, Total Reward: 4\n",
      "Episode: 2107, Total Reward: 10\n",
      "Episode: 2108, Total Reward: 12\n",
      "Episode: 2109, Total Reward: 5\n",
      "Episode: 2110, Total Reward: 11\n",
      "Episode: 2111, Total Reward: 8\n",
      "Episode: 2112, Total Reward: 9\n",
      "Episode: 2113, Total Reward: 11\n",
      "Episode: 2114, Total Reward: 5\n",
      "Episode: 2115, Total Reward: 6\n",
      "Episode: 2116, Total Reward: 11\n",
      "Episode: 2117, Total Reward: 7\n",
      "Episode: 2118, Total Reward: 8\n",
      "Episode: 2119, Total Reward: 7\n",
      "Episode: 2120, Total Reward: 7\n",
      "Episode: 2121, Total Reward: 5\n",
      "Episode: 2122, Total Reward: 7\n",
      "Episode: 2123, Total Reward: 11\n",
      "Episode: 2124, Total Reward: -2\n",
      "Episode: 2125, Total Reward: 10\n",
      "Episode: 2126, Total Reward: 10\n",
      "Episode: 2127, Total Reward: 5\n",
      "Episode: 2128, Total Reward: 7\n",
      "Episode: 2129, Total Reward: 9\n",
      "Episode: 2130, Total Reward: 4\n",
      "Episode: 2131, Total Reward: 12\n",
      "Episode: 2132, Total Reward: 8\n",
      "Episode: 2133, Total Reward: 11\n",
      "Episode: 2134, Total Reward: -2\n",
      "Episode: 2135, Total Reward: 5\n",
      "Episode: 2136, Total Reward: 7\n",
      "Episode: 2137, Total Reward: 8\n",
      "Episode: 2138, Total Reward: 9\n",
      "Episode: 2139, Total Reward: 5\n",
      "Episode: 2140, Total Reward: 7\n",
      "Episode: 2141, Total Reward: 3\n",
      "Episode: 2142, Total Reward: 6\n",
      "Episode: 2143, Total Reward: 6\n",
      "Episode: 2144, Total Reward: 6\n",
      "Episode: 2145, Total Reward: 5\n",
      "Episode: 2146, Total Reward: 9\n",
      "Episode: 2147, Total Reward: 11\n",
      "Episode: 2148, Total Reward: 5\n",
      "Episode: 2149, Total Reward: 8\n",
      "Episode: 2150, Total Reward: -17\n",
      "Episode: 2151, Total Reward: 2\n",
      "Episode: 2152, Total Reward: 10\n",
      "Episode: 2153, Total Reward: 6\n",
      "Episode: 2154, Total Reward: 6\n",
      "Episode: 2155, Total Reward: 8\n",
      "Episode: 2156, Total Reward: 11\n",
      "Episode: 2157, Total Reward: 9\n",
      "Episode: 2158, Total Reward: 6\n",
      "Episode: 2159, Total Reward: 8\n",
      "Episode: 2160, Total Reward: 10\n",
      "Episode: 2161, Total Reward: 8\n",
      "Episode: 2162, Total Reward: 8\n",
      "Episode: 2163, Total Reward: 5\n",
      "Episode: 2164, Total Reward: 11\n",
      "Episode: 2165, Total Reward: 7\n",
      "Episode: 2166, Total Reward: 10\n",
      "Episode: 2167, Total Reward: 0\n",
      "Episode: 2168, Total Reward: 5\n",
      "Episode: 2169, Total Reward: 9\n",
      "Episode: 2170, Total Reward: 4\n",
      "Episode: 2171, Total Reward: 10\n",
      "Episode: 2172, Total Reward: 13\n",
      "Episode: 2173, Total Reward: 6\n",
      "Episode: 2174, Total Reward: 6\n",
      "Episode: 2175, Total Reward: 6\n",
      "Episode: 2176, Total Reward: 10\n",
      "Episode: 2177, Total Reward: 9\n",
      "Episode: 2178, Total Reward: 3\n",
      "Episode: 2179, Total Reward: 8\n",
      "Episode: 2180, Total Reward: 8\n",
      "Episode: 2181, Total Reward: 5\n",
      "Episode: 2182, Total Reward: 4\n",
      "Episode: 2183, Total Reward: 6\n",
      "Episode: 2184, Total Reward: 7\n",
      "Episode: 2185, Total Reward: 9\n",
      "Episode: 2186, Total Reward: 5\n",
      "Episode: 2187, Total Reward: 8\n",
      "Episode: 2188, Total Reward: 7\n",
      "Episode: 2189, Total Reward: 10\n",
      "Episode: 2190, Total Reward: 8\n",
      "Episode: 2191, Total Reward: 7\n",
      "Episode: 2192, Total Reward: 7\n",
      "Episode: 2193, Total Reward: 10\n",
      "Episode: 2194, Total Reward: 6\n",
      "Episode: 2195, Total Reward: 5\n",
      "Episode: 2196, Total Reward: 5\n",
      "Episode: 2197, Total Reward: 8\n",
      "Episode: 2198, Total Reward: 14\n",
      "Episode: 2199, Total Reward: 6\n",
      "Episode: 2200, Total Reward: 4\n",
      "Episode: 2201, Total Reward: 6\n",
      "Episode: 2202, Total Reward: 7\n",
      "Episode: 2203, Total Reward: 6\n",
      "Episode: 2204, Total Reward: 5\n",
      "Episode: 2205, Total Reward: 5\n",
      "Episode: 2206, Total Reward: 4\n",
      "Episode: 2207, Total Reward: 12\n",
      "Episode: 2208, Total Reward: 5\n",
      "Episode: 2209, Total Reward: 8\n",
      "Episode: 2210, Total Reward: 5\n",
      "Episode: 2211, Total Reward: 8\n",
      "Episode: 2212, Total Reward: -3\n",
      "Episode: 2213, Total Reward: 7\n",
      "Episode: 2214, Total Reward: 9\n",
      "Episode: 2215, Total Reward: 8\n",
      "Episode: 2216, Total Reward: 8\n",
      "Episode: 2217, Total Reward: 7\n",
      "Episode: 2218, Total Reward: 9\n",
      "Episode: 2219, Total Reward: 5\n",
      "Episode: 2220, Total Reward: 7\n",
      "Episode: 2221, Total Reward: 5\n",
      "Episode: 2222, Total Reward: 12\n",
      "Episode: 2223, Total Reward: -4\n",
      "Episode: 2224, Total Reward: 10\n",
      "Episode: 2225, Total Reward: 7\n",
      "Episode: 2226, Total Reward: 14\n",
      "Episode: 2227, Total Reward: 4\n",
      "Episode: 2228, Total Reward: 6\n",
      "Episode: 2229, Total Reward: 10\n",
      "Episode: 2230, Total Reward: 5\n",
      "Episode: 2231, Total Reward: -10\n",
      "Episode: 2232, Total Reward: 7\n",
      "Episode: 2233, Total Reward: 15\n",
      "Episode: 2234, Total Reward: 8\n",
      "Episode: 2235, Total Reward: 11\n",
      "Episode: 2236, Total Reward: 6\n",
      "Episode: 2237, Total Reward: 7\n",
      "Episode: 2238, Total Reward: 12\n",
      "Episode: 2239, Total Reward: -1\n",
      "Episode: 2240, Total Reward: 10\n",
      "Episode: 2241, Total Reward: 6\n",
      "Episode: 2242, Total Reward: 11\n",
      "Episode: 2243, Total Reward: 7\n",
      "Episode: 2244, Total Reward: 7\n",
      "Episode: 2245, Total Reward: 8\n",
      "Episode: 2246, Total Reward: 8\n",
      "Episode: 2247, Total Reward: 9\n",
      "Episode: 2248, Total Reward: 9\n",
      "Episode: 2249, Total Reward: 10\n",
      "Episode: 2250, Total Reward: 8\n",
      "Episode: 2251, Total Reward: 12\n",
      "Episode: 2252, Total Reward: 6\n",
      "Episode: 2253, Total Reward: 3\n",
      "Episode: 2254, Total Reward: 5\n",
      "Episode: 2255, Total Reward: 4\n",
      "Episode: 2256, Total Reward: 2\n",
      "Episode: 2257, Total Reward: 5\n",
      "Episode: 2258, Total Reward: 6\n",
      "Episode: 2259, Total Reward: 8\n",
      "Episode: 2260, Total Reward: 7\n",
      "Episode: 2261, Total Reward: 2\n",
      "Episode: 2262, Total Reward: 7\n",
      "Episode: 2263, Total Reward: 5\n",
      "Episode: 2264, Total Reward: 9\n",
      "Episode: 2265, Total Reward: 10\n",
      "Episode: 2266, Total Reward: 12\n",
      "Episode: 2267, Total Reward: 5\n",
      "Episode: 2268, Total Reward: 10\n",
      "Episode: 2269, Total Reward: 7\n",
      "Episode: 2270, Total Reward: 9\n",
      "Episode: 2271, Total Reward: 13\n",
      "Episode: 2272, Total Reward: 12\n",
      "Episode: 2273, Total Reward: 6\n",
      "Episode: 2274, Total Reward: 4\n",
      "Episode: 2275, Total Reward: 7\n",
      "Episode: 2276, Total Reward: 7\n",
      "Episode: 2277, Total Reward: 6\n",
      "Episode: 2278, Total Reward: 10\n",
      "Episode: 2279, Total Reward: 4\n",
      "Episode: 2280, Total Reward: 6\n",
      "Episode: 2281, Total Reward: 11\n",
      "Episode: 2282, Total Reward: 7\n",
      "Episode: 2283, Total Reward: 7\n",
      "Episode: 2284, Total Reward: 3\n",
      "Episode: 2285, Total Reward: 3\n",
      "Episode: 2286, Total Reward: 9\n",
      "Episode: 2287, Total Reward: 8\n",
      "Episode: 2288, Total Reward: 8\n",
      "Episode: 2289, Total Reward: 10\n",
      "Episode: 2290, Total Reward: 7\n",
      "Episode: 2291, Total Reward: 2\n",
      "Episode: 2292, Total Reward: 7\n",
      "Episode: 2293, Total Reward: 10\n",
      "Episode: 2294, Total Reward: 3\n",
      "Episode: 2295, Total Reward: 6\n",
      "Episode: 2296, Total Reward: 6\n",
      "Episode: 2297, Total Reward: 10\n",
      "Episode: 2298, Total Reward: 11\n",
      "Episode: 2299, Total Reward: 5\n",
      "Episode: 2300, Total Reward: 10\n",
      "Episode: 2301, Total Reward: 11\n",
      "Episode: 2302, Total Reward: 12\n",
      "Episode: 2303, Total Reward: 10\n",
      "Episode: 2304, Total Reward: 5\n",
      "Episode: 2305, Total Reward: 2\n",
      "Episode: 2306, Total Reward: 7\n",
      "Episode: 2307, Total Reward: 5\n",
      "Episode: 2308, Total Reward: 6\n",
      "Episode: 2309, Total Reward: 8\n",
      "Episode: 2310, Total Reward: 5\n",
      "Episode: 2311, Total Reward: 4\n",
      "Episode: 2312, Total Reward: 1\n",
      "Episode: 2313, Total Reward: 2\n",
      "Episode: 2314, Total Reward: 7\n",
      "Episode: 2315, Total Reward: 6\n",
      "Episode: 2316, Total Reward: 8\n",
      "Episode: 2317, Total Reward: 5\n",
      "Episode: 2318, Total Reward: -3\n",
      "Episode: 2319, Total Reward: 11\n",
      "Episode: 2320, Total Reward: 8\n",
      "Episode: 2321, Total Reward: 9\n",
      "Episode: 2322, Total Reward: 6\n",
      "Episode: 2323, Total Reward: 11\n",
      "Episode: 2324, Total Reward: 10\n",
      "Episode: 2325, Total Reward: 8\n",
      "Episode: 2326, Total Reward: 8\n",
      "Episode: 2327, Total Reward: 9\n",
      "Episode: 2328, Total Reward: 5\n",
      "Episode: 2329, Total Reward: 5\n",
      "Episode: 2330, Total Reward: 9\n",
      "Episode: 2331, Total Reward: 8\n",
      "Episode: 2332, Total Reward: 5\n",
      "Episode: 2333, Total Reward: 4\n",
      "Episode: 2334, Total Reward: 6\n",
      "Episode: 2335, Total Reward: 7\n",
      "Episode: 2336, Total Reward: 7\n",
      "Episode: 2337, Total Reward: 11\n",
      "Episode: 2338, Total Reward: 5\n",
      "Episode: 2339, Total Reward: 6\n",
      "Episode: 2340, Total Reward: 10\n",
      "Episode: 2341, Total Reward: 6\n",
      "Episode: 2342, Total Reward: 4\n",
      "Episode: 2343, Total Reward: 3\n",
      "Episode: 2344, Total Reward: 6\n",
      "Episode: 2345, Total Reward: 5\n",
      "Episode: 2346, Total Reward: 13\n",
      "Episode: 2347, Total Reward: -4\n",
      "Episode: 2348, Total Reward: 7\n",
      "Episode: 2349, Total Reward: 8\n",
      "Episode: 2350, Total Reward: 8\n",
      "Episode: 2351, Total Reward: 9\n",
      "Episode: 2352, Total Reward: 7\n",
      "Episode: 2353, Total Reward: 8\n",
      "Episode: 2354, Total Reward: 11\n",
      "Episode: 2355, Total Reward: 11\n",
      "Episode: 2356, Total Reward: 9\n",
      "Episode: 2357, Total Reward: 8\n",
      "Episode: 2358, Total Reward: 10\n",
      "Episode: 2359, Total Reward: 9\n",
      "Episode: 2360, Total Reward: 12\n",
      "Episode: 2361, Total Reward: 6\n",
      "Episode: 2362, Total Reward: 7\n",
      "Episode: 2363, Total Reward: 5\n",
      "Episode: 2364, Total Reward: 9\n",
      "Episode: 2365, Total Reward: 15\n",
      "Episode: 2366, Total Reward: 8\n",
      "Episode: 2367, Total Reward: 7\n",
      "Episode: 2368, Total Reward: 6\n",
      "Episode: 2369, Total Reward: 5\n",
      "Episode: 2370, Total Reward: 7\n",
      "Episode: 2371, Total Reward: 10\n",
      "Episode: 2372, Total Reward: 13\n",
      "Episode: 2373, Total Reward: 12\n",
      "Episode: 2374, Total Reward: 3\n",
      "Episode: 2375, Total Reward: 6\n",
      "Episode: 2376, Total Reward: 7\n",
      "Episode: 2377, Total Reward: 7\n",
      "Episode: 2378, Total Reward: 10\n",
      "Episode: 2379, Total Reward: -1\n",
      "Episode: 2380, Total Reward: 6\n",
      "Episode: 2381, Total Reward: -6\n",
      "Episode: 2382, Total Reward: 9\n",
      "Episode: 2383, Total Reward: -3\n",
      "Episode: 2384, Total Reward: 8\n",
      "Episode: 2385, Total Reward: 9\n",
      "Episode: 2386, Total Reward: 7\n",
      "Episode: 2387, Total Reward: 9\n",
      "Episode: 2388, Total Reward: 10\n",
      "Episode: 2389, Total Reward: 7\n",
      "Episode: 2390, Total Reward: 10\n",
      "Episode: 2391, Total Reward: 4\n",
      "Episode: 2392, Total Reward: 6\n",
      "Episode: 2393, Total Reward: 8\n",
      "Episode: 2394, Total Reward: 5\n",
      "Episode: 2395, Total Reward: 6\n",
      "Episode: 2396, Total Reward: -18\n",
      "Episode: 2397, Total Reward: 10\n",
      "Episode: 2398, Total Reward: 3\n",
      "Episode: 2399, Total Reward: 9\n",
      "Episode: 2400, Total Reward: 7\n",
      "Episode: 2401, Total Reward: 12\n",
      "Episode: 2402, Total Reward: 9\n",
      "Episode: 2403, Total Reward: 7\n",
      "Episode: 2404, Total Reward: 11\n",
      "Episode: 2405, Total Reward: 8\n",
      "Episode: 2406, Total Reward: 11\n",
      "Episode: 2407, Total Reward: 6\n",
      "Episode: 2408, Total Reward: 12\n",
      "Episode: 2409, Total Reward: 6\n",
      "Episode: 2410, Total Reward: 11\n",
      "Episode: 2411, Total Reward: 6\n",
      "Episode: 2412, Total Reward: 11\n",
      "Episode: 2413, Total Reward: 7\n",
      "Episode: 2414, Total Reward: 5\n",
      "Episode: 2415, Total Reward: 9\n",
      "Episode: 2416, Total Reward: 6\n",
      "Episode: 2417, Total Reward: 5\n",
      "Episode: 2418, Total Reward: 8\n",
      "Episode: 2419, Total Reward: 7\n",
      "Episode: 2420, Total Reward: 9\n",
      "Episode: 2421, Total Reward: 7\n",
      "Episode: 2422, Total Reward: 5\n",
      "Episode: 2423, Total Reward: 5\n",
      "Episode: 2424, Total Reward: 13\n",
      "Episode: 2425, Total Reward: 11\n",
      "Episode: 2426, Total Reward: 11\n",
      "Episode: 2427, Total Reward: 8\n",
      "Episode: 2428, Total Reward: -8\n",
      "Episode: 2429, Total Reward: 6\n",
      "Episode: 2430, Total Reward: 6\n",
      "Episode: 2431, Total Reward: 7\n",
      "Episode: 2432, Total Reward: 7\n",
      "Episode: 2433, Total Reward: 6\n",
      "Episode: 2434, Total Reward: 5\n",
      "Episode: 2435, Total Reward: 6\n",
      "Episode: 2436, Total Reward: 9\n",
      "Episode: 2437, Total Reward: 9\n",
      "Episode: 2438, Total Reward: 8\n",
      "Episode: 2439, Total Reward: 10\n",
      "Episode: 2440, Total Reward: 8\n",
      "Episode: 2441, Total Reward: 10\n",
      "Episode: 2442, Total Reward: 5\n",
      "Episode: 2443, Total Reward: 10\n",
      "Episode: 2444, Total Reward: 11\n",
      "Episode: 2445, Total Reward: 8\n",
      "Episode: 2446, Total Reward: 7\n",
      "Episode: 2447, Total Reward: 6\n",
      "Episode: 2448, Total Reward: 10\n",
      "Episode: 2449, Total Reward: 10\n",
      "Episode: 2450, Total Reward: 15\n",
      "Episode: 2451, Total Reward: 4\n",
      "Episode: 2452, Total Reward: 6\n",
      "Episode: 2453, Total Reward: 8\n",
      "Episode: 2454, Total Reward: -2\n",
      "Episode: 2455, Total Reward: 14\n",
      "Episode: 2456, Total Reward: 9\n",
      "Episode: 2457, Total Reward: 2\n",
      "Episode: 2458, Total Reward: 5\n",
      "Episode: 2459, Total Reward: 13\n",
      "Episode: 2460, Total Reward: 6\n",
      "Episode: 2461, Total Reward: 10\n",
      "Episode: 2462, Total Reward: 4\n",
      "Episode: 2463, Total Reward: 8\n",
      "Episode: 2464, Total Reward: -4\n",
      "Episode: 2465, Total Reward: 11\n",
      "Episode: 2466, Total Reward: 3\n",
      "Episode: 2467, Total Reward: 10\n",
      "Episode: 2468, Total Reward: -1\n",
      "Episode: 2469, Total Reward: 4\n",
      "Episode: 2470, Total Reward: 9\n",
      "Episode: 2471, Total Reward: 9\n",
      "Episode: 2472, Total Reward: 9\n",
      "Episode: 2473, Total Reward: 5\n",
      "Episode: 2474, Total Reward: 5\n",
      "Episode: 2475, Total Reward: 8\n",
      "Episode: 2476, Total Reward: 6\n",
      "Episode: 2477, Total Reward: 7\n",
      "Episode: 2478, Total Reward: -3\n",
      "Episode: 2479, Total Reward: 6\n",
      "Episode: 2480, Total Reward: 7\n",
      "Episode: 2481, Total Reward: 10\n",
      "Episode: 2482, Total Reward: 5\n",
      "Episode: 2483, Total Reward: 8\n",
      "Episode: 2484, Total Reward: 12\n",
      "Episode: 2485, Total Reward: 4\n",
      "Episode: 2486, Total Reward: 8\n",
      "Episode: 2487, Total Reward: 3\n",
      "Episode: 2488, Total Reward: 7\n",
      "Episode: 2489, Total Reward: 4\n",
      "Episode: 2490, Total Reward: 9\n",
      "Episode: 2491, Total Reward: 9\n",
      "Episode: 2492, Total Reward: 8\n",
      "Episode: 2493, Total Reward: 10\n",
      "Episode: 2494, Total Reward: 6\n",
      "Episode: 2495, Total Reward: 12\n",
      "Episode: 2496, Total Reward: 8\n",
      "Episode: 2497, Total Reward: 4\n",
      "Episode: 2498, Total Reward: 11\n",
      "Episode: 2499, Total Reward: 8\n",
      "Episode: 2500, Total Reward: 10\n",
      "Episode: 2501, Total Reward: 6\n",
      "Episode: 2502, Total Reward: 7\n",
      "Episode: 2503, Total Reward: 9\n",
      "Episode: 2504, Total Reward: 7\n",
      "Episode: 2505, Total Reward: 8\n",
      "Episode: 2506, Total Reward: 4\n",
      "Episode: 2507, Total Reward: 6\n",
      "Episode: 2508, Total Reward: 5\n",
      "Episode: 2509, Total Reward: -3\n",
      "Episode: 2510, Total Reward: 13\n",
      "Episode: 2511, Total Reward: 11\n",
      "Episode: 2512, Total Reward: 10\n",
      "Episode: 2513, Total Reward: 8\n",
      "Episode: 2514, Total Reward: 10\n",
      "Episode: 2515, Total Reward: 11\n",
      "Episode: 2516, Total Reward: 6\n",
      "Episode: 2517, Total Reward: 10\n",
      "Episode: 2518, Total Reward: 4\n",
      "Episode: 2519, Total Reward: 9\n",
      "Episode: 2520, Total Reward: 4\n",
      "Episode: 2521, Total Reward: 4\n",
      "Episode: 2522, Total Reward: -4\n",
      "Episode: 2523, Total Reward: 9\n",
      "Episode: 2524, Total Reward: 11\n",
      "Episode: 2525, Total Reward: 8\n",
      "Episode: 2526, Total Reward: 10\n",
      "Episode: 2527, Total Reward: 5\n",
      "Episode: 2528, Total Reward: 9\n",
      "Episode: 2529, Total Reward: 8\n",
      "Episode: 2530, Total Reward: 10\n",
      "Episode: 2531, Total Reward: 1\n",
      "Episode: 2532, Total Reward: 10\n",
      "Episode: 2533, Total Reward: 9\n",
      "Episode: 2534, Total Reward: 6\n",
      "Episode: 2535, Total Reward: 2\n",
      "Episode: 2536, Total Reward: 10\n",
      "Episode: 2537, Total Reward: 8\n",
      "Episode: 2538, Total Reward: 9\n",
      "Episode: 2539, Total Reward: 9\n",
      "Episode: 2540, Total Reward: 9\n",
      "Episode: 2541, Total Reward: 5\n",
      "Episode: 2542, Total Reward: -1\n",
      "Episode: 2543, Total Reward: 11\n",
      "Episode: 2544, Total Reward: 8\n",
      "Episode: 2545, Total Reward: 7\n",
      "Episode: 2546, Total Reward: 10\n",
      "Episode: 2547, Total Reward: 5\n",
      "Episode: 2548, Total Reward: 6\n",
      "Episode: 2549, Total Reward: 14\n",
      "Episode: 2550, Total Reward: 8\n",
      "Episode: 2551, Total Reward: 9\n",
      "Episode: 2552, Total Reward: 7\n",
      "Episode: 2553, Total Reward: 8\n",
      "Episode: 2554, Total Reward: 3\n",
      "Episode: 2555, Total Reward: 5\n",
      "Episode: 2556, Total Reward: -5\n",
      "Episode: 2557, Total Reward: 8\n",
      "Episode: 2558, Total Reward: 11\n",
      "Episode: 2559, Total Reward: 6\n",
      "Episode: 2560, Total Reward: 6\n",
      "Episode: 2561, Total Reward: 14\n",
      "Episode: 2562, Total Reward: 6\n",
      "Episode: 2563, Total Reward: 7\n",
      "Episode: 2564, Total Reward: 5\n",
      "Episode: 2565, Total Reward: 11\n",
      "Episode: 2566, Total Reward: 8\n",
      "Episode: 2567, Total Reward: 9\n",
      "Episode: 2568, Total Reward: 15\n",
      "Episode: 2569, Total Reward: 5\n",
      "Episode: 2570, Total Reward: 5\n",
      "Episode: 2571, Total Reward: 10\n",
      "Episode: 2572, Total Reward: 13\n",
      "Episode: 2573, Total Reward: 11\n",
      "Episode: 2574, Total Reward: 9\n",
      "Episode: 2575, Total Reward: 10\n",
      "Episode: 2576, Total Reward: 13\n",
      "Episode: 2577, Total Reward: 7\n",
      "Episode: 2578, Total Reward: 9\n",
      "Episode: 2579, Total Reward: 6\n",
      "Episode: 2580, Total Reward: 9\n",
      "Episode: 2581, Total Reward: 5\n",
      "Episode: 2582, Total Reward: 4\n",
      "Episode: 2583, Total Reward: 7\n",
      "Episode: 2584, Total Reward: 12\n",
      "Episode: 2585, Total Reward: 4\n",
      "Episode: 2586, Total Reward: 10\n",
      "Episode: 2587, Total Reward: 11\n",
      "Episode: 2588, Total Reward: 11\n",
      "Episode: 2589, Total Reward: 10\n",
      "Episode: 2590, Total Reward: -9\n",
      "Episode: 2591, Total Reward: 7\n",
      "Episode: 2592, Total Reward: 7\n",
      "Episode: 2593, Total Reward: 5\n",
      "Episode: 2594, Total Reward: 9\n",
      "Episode: 2595, Total Reward: 10\n",
      "Episode: 2596, Total Reward: 10\n",
      "Episode: 2597, Total Reward: 3\n",
      "Episode: 2598, Total Reward: 14\n",
      "Episode: 2599, Total Reward: 8\n",
      "Episode: 2600, Total Reward: 10\n",
      "Episode: 2601, Total Reward: 7\n",
      "Episode: 2602, Total Reward: 7\n",
      "Episode: 2603, Total Reward: 10\n",
      "Episode: 2604, Total Reward: 8\n",
      "Episode: 2605, Total Reward: 14\n",
      "Episode: 2606, Total Reward: 6\n",
      "Episode: 2607, Total Reward: 9\n",
      "Episode: 2608, Total Reward: 9\n",
      "Episode: 2609, Total Reward: 11\n",
      "Episode: 2610, Total Reward: 9\n",
      "Episode: 2611, Total Reward: 13\n",
      "Episode: 2612, Total Reward: 14\n",
      "Episode: 2613, Total Reward: 9\n",
      "Episode: 2614, Total Reward: 10\n",
      "Episode: 2615, Total Reward: 10\n",
      "Episode: 2616, Total Reward: 3\n",
      "Episode: 2617, Total Reward: 3\n",
      "Episode: 2618, Total Reward: 11\n",
      "Episode: 2619, Total Reward: 10\n",
      "Episode: 2620, Total Reward: 8\n",
      "Episode: 2621, Total Reward: 9\n",
      "Episode: 2622, Total Reward: 14\n",
      "Episode: 2623, Total Reward: 8\n",
      "Episode: 2624, Total Reward: 8\n",
      "Episode: 2625, Total Reward: 4\n",
      "Episode: 2626, Total Reward: 8\n",
      "Episode: 2627, Total Reward: 6\n",
      "Episode: 2628, Total Reward: 7\n",
      "Episode: 2629, Total Reward: 5\n",
      "Episode: 2630, Total Reward: 10\n",
      "Episode: 2631, Total Reward: 9\n",
      "Episode: 2632, Total Reward: 5\n",
      "Episode: 2633, Total Reward: 10\n",
      "Episode: 2634, Total Reward: 5\n",
      "Episode: 2635, Total Reward: 6\n",
      "Episode: 2636, Total Reward: 8\n",
      "Episode: 2637, Total Reward: 10\n",
      "Episode: 2638, Total Reward: 9\n",
      "Episode: 2639, Total Reward: 10\n",
      "Episode: 2640, Total Reward: 10\n",
      "Episode: 2641, Total Reward: 11\n",
      "Episode: 2642, Total Reward: 7\n",
      "Episode: 2643, Total Reward: 6\n",
      "Episode: 2644, Total Reward: 4\n",
      "Episode: 2645, Total Reward: 12\n",
      "Episode: 2646, Total Reward: 3\n",
      "Episode: 2647, Total Reward: 8\n",
      "Episode: 2648, Total Reward: 5\n",
      "Episode: 2649, Total Reward: 5\n",
      "Episode: 2650, Total Reward: 14\n",
      "Episode: 2651, Total Reward: 3\n",
      "Episode: 2652, Total Reward: 11\n",
      "Episode: 2653, Total Reward: 4\n",
      "Episode: 2654, Total Reward: 15\n",
      "Episode: 2655, Total Reward: 8\n",
      "Episode: 2656, Total Reward: 8\n",
      "Episode: 2657, Total Reward: 7\n",
      "Episode: 2658, Total Reward: -10\n",
      "Episode: 2659, Total Reward: 11\n",
      "Episode: 2660, Total Reward: 10\n",
      "Episode: 2661, Total Reward: 5\n",
      "Episode: 2662, Total Reward: 11\n",
      "Episode: 2663, Total Reward: 7\n",
      "Episode: 2664, Total Reward: 4\n",
      "Episode: 2665, Total Reward: 10\n",
      "Episode: 2666, Total Reward: 10\n",
      "Episode: 2667, Total Reward: 8\n",
      "Episode: 2668, Total Reward: 14\n",
      "Episode: 2669, Total Reward: -7\n",
      "Episode: 2670, Total Reward: 5\n",
      "Episode: 2671, Total Reward: 11\n",
      "Episode: 2672, Total Reward: 3\n",
      "Episode: 2673, Total Reward: 13\n",
      "Episode: 2674, Total Reward: 7\n",
      "Episode: 2675, Total Reward: 6\n",
      "Episode: 2676, Total Reward: 9\n",
      "Episode: 2677, Total Reward: 6\n",
      "Episode: 2678, Total Reward: 7\n",
      "Episode: 2679, Total Reward: 8\n",
      "Episode: 2680, Total Reward: 5\n",
      "Episode: 2681, Total Reward: 11\n",
      "Episode: 2682, Total Reward: 15\n",
      "Episode: 2683, Total Reward: 9\n",
      "Episode: 2684, Total Reward: 8\n",
      "Episode: 2685, Total Reward: 10\n",
      "Episode: 2686, Total Reward: 9\n",
      "Episode: 2687, Total Reward: 10\n",
      "Episode: 2688, Total Reward: 12\n",
      "Episode: 2689, Total Reward: 8\n",
      "Episode: 2690, Total Reward: -1\n",
      "Episode: 2691, Total Reward: 5\n",
      "Episode: 2692, Total Reward: -5\n",
      "Episode: 2693, Total Reward: 5\n",
      "Episode: 2694, Total Reward: 11\n",
      "Episode: 2695, Total Reward: 11\n",
      "Episode: 2696, Total Reward: 6\n",
      "Episode: 2697, Total Reward: 0\n",
      "Episode: 2698, Total Reward: 8\n",
      "Episode: 2699, Total Reward: 6\n",
      "Episode: 2700, Total Reward: 4\n",
      "Episode: 2701, Total Reward: 5\n",
      "Episode: 2702, Total Reward: 6\n",
      "Episode: 2703, Total Reward: 8\n",
      "Episode: 2704, Total Reward: 14\n",
      "Episode: 2705, Total Reward: 7\n",
      "Episode: 2706, Total Reward: 11\n",
      "Episode: 2707, Total Reward: 5\n",
      "Episode: 2708, Total Reward: 7\n",
      "Episode: 2709, Total Reward: 7\n",
      "Episode: 2710, Total Reward: 14\n",
      "Episode: 2711, Total Reward: 11\n",
      "Episode: 2712, Total Reward: 3\n",
      "Episode: 2713, Total Reward: 11\n",
      "Episode: 2714, Total Reward: 10\n",
      "Episode: 2715, Total Reward: 4\n",
      "Episode: 2716, Total Reward: 12\n",
      "Episode: 2717, Total Reward: -3\n",
      "Episode: 2718, Total Reward: 4\n",
      "Episode: 2719, Total Reward: 8\n",
      "Episode: 2720, Total Reward: 7\n",
      "Episode: 2721, Total Reward: 6\n",
      "Episode: 2722, Total Reward: 7\n",
      "Episode: 2723, Total Reward: 12\n",
      "Episode: 2724, Total Reward: 8\n",
      "Episode: 2725, Total Reward: 7\n",
      "Episode: 2726, Total Reward: 6\n",
      "Episode: 2727, Total Reward: 7\n",
      "Episode: 2728, Total Reward: 8\n",
      "Episode: 2729, Total Reward: 10\n",
      "Episode: 2730, Total Reward: 5\n",
      "Episode: 2731, Total Reward: 9\n",
      "Episode: 2732, Total Reward: 4\n",
      "Episode: 2733, Total Reward: 8\n",
      "Episode: 2734, Total Reward: 7\n",
      "Episode: 2735, Total Reward: 6\n",
      "Episode: 2736, Total Reward: 9\n",
      "Episode: 2737, Total Reward: 14\n",
      "Episode: 2738, Total Reward: 7\n",
      "Episode: 2739, Total Reward: 7\n",
      "Episode: 2740, Total Reward: 4\n",
      "Episode: 2741, Total Reward: 8\n",
      "Episode: 2742, Total Reward: 7\n",
      "Episode: 2743, Total Reward: 4\n",
      "Episode: 2744, Total Reward: 13\n",
      "Episode: 2745, Total Reward: 8\n",
      "Episode: 2746, Total Reward: 7\n",
      "Episode: 2747, Total Reward: 8\n",
      "Episode: 2748, Total Reward: 8\n",
      "Episode: 2749, Total Reward: 7\n",
      "Episode: 2750, Total Reward: 4\n",
      "Episode: 2751, Total Reward: 7\n",
      "Episode: 2752, Total Reward: 10\n",
      "Episode: 2753, Total Reward: 14\n",
      "Episode: 2754, Total Reward: 8\n",
      "Episode: 2755, Total Reward: 9\n",
      "Episode: 2756, Total Reward: 8\n",
      "Episode: 2757, Total Reward: 12\n",
      "Episode: 2758, Total Reward: 5\n",
      "Episode: 2759, Total Reward: 8\n",
      "Episode: 2760, Total Reward: 7\n",
      "Episode: 2761, Total Reward: 6\n",
      "Episode: 2762, Total Reward: 2\n",
      "Episode: 2763, Total Reward: 9\n",
      "Episode: 2764, Total Reward: 0\n",
      "Episode: 2765, Total Reward: 10\n",
      "Episode: 2766, Total Reward: 6\n",
      "Episode: 2767, Total Reward: 10\n",
      "Episode: 2768, Total Reward: 7\n",
      "Episode: 2769, Total Reward: 10\n",
      "Episode: 2770, Total Reward: 9\n",
      "Episode: 2771, Total Reward: 8\n",
      "Episode: 2772, Total Reward: 10\n",
      "Episode: 2773, Total Reward: 10\n",
      "Episode: 2774, Total Reward: 10\n",
      "Episode: 2775, Total Reward: 5\n",
      "Episode: 2776, Total Reward: 11\n",
      "Episode: 2777, Total Reward: 7\n",
      "Episode: 2778, Total Reward: 7\n",
      "Episode: 2779, Total Reward: 11\n",
      "Episode: 2780, Total Reward: 7\n",
      "Episode: 2781, Total Reward: 7\n",
      "Episode: 2782, Total Reward: 6\n",
      "Episode: 2783, Total Reward: 10\n",
      "Episode: 2784, Total Reward: 10\n",
      "Episode: 2785, Total Reward: 10\n",
      "Episode: 2786, Total Reward: 7\n",
      "Episode: 2787, Total Reward: 10\n",
      "Episode: 2788, Total Reward: 9\n",
      "Episode: 2789, Total Reward: 8\n",
      "Episode: 2790, Total Reward: 11\n",
      "Episode: 2791, Total Reward: 7\n",
      "Episode: 2792, Total Reward: 12\n",
      "Episode: 2793, Total Reward: -2\n",
      "Episode: 2794, Total Reward: 7\n",
      "Episode: 2795, Total Reward: 10\n",
      "Episode: 2796, Total Reward: 6\n",
      "Episode: 2797, Total Reward: 8\n",
      "Episode: 2798, Total Reward: 5\n",
      "Episode: 2799, Total Reward: 4\n",
      "Episode: 2800, Total Reward: 5\n",
      "Episode: 2801, Total Reward: 4\n",
      "Episode: 2802, Total Reward: 6\n",
      "Episode: 2803, Total Reward: 7\n",
      "Episode: 2804, Total Reward: 8\n",
      "Episode: 2805, Total Reward: 13\n",
      "Episode: 2806, Total Reward: 7\n",
      "Episode: 2807, Total Reward: 9\n",
      "Episode: 2808, Total Reward: 12\n",
      "Episode: 2809, Total Reward: 9\n",
      "Episode: 2810, Total Reward: 6\n",
      "Episode: 2811, Total Reward: 2\n",
      "Episode: 2812, Total Reward: 8\n",
      "Episode: 2813, Total Reward: 4\n",
      "Episode: 2814, Total Reward: 9\n",
      "Episode: 2815, Total Reward: 10\n",
      "Episode: 2816, Total Reward: 12\n",
      "Episode: 2817, Total Reward: 9\n",
      "Episode: 2818, Total Reward: 5\n",
      "Episode: 2819, Total Reward: 11\n",
      "Episode: 2820, Total Reward: 2\n",
      "Episode: 2821, Total Reward: 14\n",
      "Episode: 2822, Total Reward: 5\n",
      "Episode: 2823, Total Reward: 4\n",
      "Episode: 2824, Total Reward: 7\n",
      "Episode: 2825, Total Reward: 4\n",
      "Episode: 2826, Total Reward: 6\n",
      "Episode: 2827, Total Reward: 2\n",
      "Episode: 2828, Total Reward: 8\n",
      "Episode: 2829, Total Reward: 5\n",
      "Episode: 2830, Total Reward: 7\n",
      "Episode: 2831, Total Reward: 11\n",
      "Episode: 2832, Total Reward: 8\n",
      "Episode: 2833, Total Reward: 4\n",
      "Episode: 2834, Total Reward: 11\n",
      "Episode: 2835, Total Reward: -4\n",
      "Episode: 2836, Total Reward: 4\n",
      "Episode: 2837, Total Reward: 5\n",
      "Episode: 2838, Total Reward: 5\n",
      "Episode: 2839, Total Reward: 13\n",
      "Episode: 2840, Total Reward: 0\n",
      "Episode: 2841, Total Reward: 4\n",
      "Episode: 2842, Total Reward: 10\n",
      "Episode: 2843, Total Reward: 7\n",
      "Episode: 2844, Total Reward: 7\n",
      "Episode: 2845, Total Reward: 10\n",
      "Episode: 2846, Total Reward: 7\n",
      "Episode: 2847, Total Reward: 10\n",
      "Episode: 2848, Total Reward: 7\n",
      "Episode: 2849, Total Reward: 6\n",
      "Episode: 2850, Total Reward: 9\n",
      "Episode: 2851, Total Reward: 10\n",
      "Episode: 2852, Total Reward: 9\n",
      "Episode: 2853, Total Reward: 6\n",
      "Episode: 2854, Total Reward: 10\n",
      "Episode: 2855, Total Reward: 6\n",
      "Episode: 2856, Total Reward: 10\n",
      "Episode: 2857, Total Reward: 6\n",
      "Episode: 2858, Total Reward: 10\n",
      "Episode: 2859, Total Reward: 4\n",
      "Episode: 2860, Total Reward: 10\n",
      "Episode: 2861, Total Reward: 6\n",
      "Episode: 2862, Total Reward: 12\n",
      "Episode: 2863, Total Reward: 9\n",
      "Episode: 2864, Total Reward: 5\n",
      "Episode: 2865, Total Reward: -4\n",
      "Episode: 2866, Total Reward: 4\n",
      "Episode: 2867, Total Reward: 12\n",
      "Episode: 2868, Total Reward: 7\n",
      "Episode: 2869, Total Reward: 4\n",
      "Episode: 2870, Total Reward: 9\n",
      "Episode: 2871, Total Reward: 11\n",
      "Episode: 2872, Total Reward: 5\n",
      "Episode: 2873, Total Reward: 7\n",
      "Episode: 2874, Total Reward: 8\n",
      "Episode: 2875, Total Reward: 10\n",
      "Episode: 2876, Total Reward: 11\n",
      "Episode: 2877, Total Reward: 5\n",
      "Episode: 2878, Total Reward: 10\n",
      "Episode: 2879, Total Reward: 8\n",
      "Episode: 2880, Total Reward: 4\n",
      "Episode: 2881, Total Reward: 10\n",
      "Episode: 2882, Total Reward: 8\n",
      "Episode: 2883, Total Reward: 7\n",
      "Episode: 2884, Total Reward: 6\n",
      "Episode: 2885, Total Reward: 8\n",
      "Episode: 2886, Total Reward: 9\n",
      "Episode: 2887, Total Reward: 5\n",
      "Episode: 2888, Total Reward: 5\n",
      "Episode: 2889, Total Reward: 6\n",
      "Episode: 2890, Total Reward: 8\n",
      "Episode: 2891, Total Reward: 7\n",
      "Episode: 2892, Total Reward: 8\n",
      "Episode: 2893, Total Reward: 10\n",
      "Episode: 2894, Total Reward: 11\n",
      "Episode: 2895, Total Reward: 11\n",
      "Episode: 2896, Total Reward: 7\n",
      "Episode: 2897, Total Reward: 15\n",
      "Episode: 2898, Total Reward: 9\n",
      "Episode: 2899, Total Reward: 6\n",
      "Episode: 2900, Total Reward: 4\n",
      "Episode: 2901, Total Reward: 7\n",
      "Episode: 2902, Total Reward: 9\n",
      "Episode: 2903, Total Reward: 9\n",
      "Episode: 2904, Total Reward: 11\n",
      "Episode: 2905, Total Reward: 7\n",
      "Episode: 2906, Total Reward: 10\n",
      "Episode: 2907, Total Reward: 6\n",
      "Episode: 2908, Total Reward: 6\n",
      "Episode: 2909, Total Reward: 12\n",
      "Episode: 2910, Total Reward: 9\n",
      "Episode: 2911, Total Reward: 11\n",
      "Episode: 2912, Total Reward: 11\n",
      "Episode: 2913, Total Reward: 4\n",
      "Episode: 2914, Total Reward: 7\n",
      "Episode: 2915, Total Reward: 7\n",
      "Episode: 2916, Total Reward: 8\n",
      "Episode: 2917, Total Reward: 6\n",
      "Episode: 2918, Total Reward: 11\n",
      "Episode: 2919, Total Reward: 5\n",
      "Episode: 2920, Total Reward: 10\n",
      "Episode: 2921, Total Reward: 8\n",
      "Episode: 2922, Total Reward: 14\n",
      "Episode: 2923, Total Reward: 9\n",
      "Episode: 2924, Total Reward: 6\n",
      "Episode: 2925, Total Reward: 10\n",
      "Episode: 2926, Total Reward: 13\n",
      "Episode: 2927, Total Reward: 9\n",
      "Episode: 2928, Total Reward: 5\n",
      "Episode: 2929, Total Reward: 9\n",
      "Episode: 2930, Total Reward: 13\n",
      "Episode: 2931, Total Reward: 15\n",
      "Episode: 2932, Total Reward: 10\n",
      "Episode: 2933, Total Reward: 7\n",
      "Episode: 2934, Total Reward: 7\n",
      "Episode: 2935, Total Reward: 8\n",
      "Episode: 2936, Total Reward: 7\n",
      "Episode: 2937, Total Reward: 4\n",
      "Episode: 2938, Total Reward: 9\n",
      "Episode: 2939, Total Reward: 9\n",
      "Episode: 2940, Total Reward: 9\n",
      "Episode: 2941, Total Reward: 15\n",
      "Episode: 2942, Total Reward: -4\n",
      "Episode: 2943, Total Reward: 4\n",
      "Episode: 2944, Total Reward: 7\n",
      "Episode: 2945, Total Reward: 12\n",
      "Episode: 2946, Total Reward: 13\n",
      "Episode: 2947, Total Reward: 11\n",
      "Episode: 2948, Total Reward: -2\n",
      "Episode: 2949, Total Reward: 12\n",
      "Episode: 2950, Total Reward: 8\n",
      "Episode: 2951, Total Reward: 9\n",
      "Episode: 2952, Total Reward: 8\n",
      "Episode: 2953, Total Reward: 13\n",
      "Episode: 2954, Total Reward: 9\n",
      "Episode: 2955, Total Reward: 10\n",
      "Episode: 2956, Total Reward: 11\n",
      "Episode: 2957, Total Reward: 7\n",
      "Episode: 2958, Total Reward: 8\n",
      "Episode: 2959, Total Reward: 11\n",
      "Episode: 2960, Total Reward: 7\n",
      "Episode: 2961, Total Reward: 7\n",
      "Episode: 2962, Total Reward: 10\n",
      "Episode: 2963, Total Reward: 6\n",
      "Episode: 2964, Total Reward: 9\n",
      "Episode: 2965, Total Reward: 7\n",
      "Episode: 2966, Total Reward: 8\n",
      "Episode: 2967, Total Reward: 6\n",
      "Episode: 2968, Total Reward: 8\n",
      "Episode: 2969, Total Reward: 8\n",
      "Episode: 2970, Total Reward: -2\n",
      "Episode: 2971, Total Reward: 7\n",
      "Episode: 2972, Total Reward: 7\n",
      "Episode: 2973, Total Reward: 13\n",
      "Episode: 2974, Total Reward: 7\n",
      "Episode: 2975, Total Reward: 10\n",
      "Episode: 2976, Total Reward: 7\n",
      "Episode: 2977, Total Reward: 8\n",
      "Episode: 2978, Total Reward: 3\n",
      "Episode: 2979, Total Reward: 12\n",
      "Episode: 2980, Total Reward: 8\n",
      "Episode: 2981, Total Reward: 4\n",
      "Episode: 2982, Total Reward: 7\n",
      "Episode: 2983, Total Reward: 8\n",
      "Episode: 2984, Total Reward: 8\n",
      "Episode: 2985, Total Reward: 7\n",
      "Episode: 2986, Total Reward: 7\n",
      "Episode: 2987, Total Reward: 10\n",
      "Episode: 2988, Total Reward: 9\n",
      "Episode: 2989, Total Reward: 7\n",
      "Episode: 2990, Total Reward: 5\n",
      "Episode: 2991, Total Reward: 10\n",
      "Episode: 2992, Total Reward: 8\n",
      "Episode: 2993, Total Reward: 5\n",
      "Episode: 2994, Total Reward: 6\n",
      "Episode: 2995, Total Reward: 11\n",
      "Episode: 2996, Total Reward: 6\n",
      "Episode: 2997, Total Reward: 8\n",
      "Episode: 2998, Total Reward: 10\n",
      "Episode: 2999, Total Reward: 7\n",
      "Episode: 3000, Total Reward: 5\n",
      "Episode: 3001, Total Reward: 6\n",
      "Episode: 3002, Total Reward: 15\n",
      "Episode: 3003, Total Reward: 9\n",
      "Episode: 3004, Total Reward: -8\n",
      "Episode: 3005, Total Reward: 9\n",
      "Episode: 3006, Total Reward: 12\n",
      "Episode: 3007, Total Reward: 7\n",
      "Episode: 3008, Total Reward: 7\n",
      "Episode: 3009, Total Reward: 13\n",
      "Episode: 3010, Total Reward: 9\n",
      "Episode: 3011, Total Reward: 12\n",
      "Episode: 3012, Total Reward: 7\n",
      "Episode: 3013, Total Reward: 9\n",
      "Episode: 3014, Total Reward: 11\n",
      "Episode: 3015, Total Reward: 6\n",
      "Episode: 3016, Total Reward: 7\n",
      "Episode: 3017, Total Reward: 11\n",
      "Episode: 3018, Total Reward: 8\n",
      "Episode: 3019, Total Reward: 14\n",
      "Episode: 3020, Total Reward: 13\n",
      "Episode: 3021, Total Reward: -2\n",
      "Episode: 3022, Total Reward: 10\n",
      "Episode: 3023, Total Reward: 11\n",
      "Episode: 3024, Total Reward: 8\n",
      "Episode: 3025, Total Reward: 6\n",
      "Episode: 3026, Total Reward: 10\n",
      "Episode: 3027, Total Reward: 4\n",
      "Episode: 3028, Total Reward: 9\n",
      "Episode: 3029, Total Reward: 10\n",
      "Episode: 3030, Total Reward: 9\n",
      "Episode: 3031, Total Reward: 7\n",
      "Episode: 3032, Total Reward: 7\n",
      "Episode: 3033, Total Reward: 10\n",
      "Episode: 3034, Total Reward: 11\n",
      "Episode: 3035, Total Reward: 2\n",
      "Episode: 3036, Total Reward: 7\n",
      "Episode: 3037, Total Reward: 6\n",
      "Episode: 3038, Total Reward: 11\n",
      "Episode: 3039, Total Reward: 1\n",
      "Episode: 3040, Total Reward: 11\n",
      "Episode: 3041, Total Reward: 8\n",
      "Episode: 3042, Total Reward: 3\n",
      "Episode: 3043, Total Reward: 12\n",
      "Episode: 3044, Total Reward: 0\n",
      "Episode: 3045, Total Reward: 7\n",
      "Episode: 3046, Total Reward: 7\n",
      "Episode: 3047, Total Reward: 4\n",
      "Episode: 3048, Total Reward: 8\n",
      "Episode: 3049, Total Reward: 6\n",
      "Episode: 3050, Total Reward: 4\n",
      "Episode: 3051, Total Reward: 14\n",
      "Episode: 3052, Total Reward: 9\n",
      "Episode: 3053, Total Reward: 9\n",
      "Episode: 3054, Total Reward: 11\n",
      "Episode: 3055, Total Reward: 8\n",
      "Episode: 3056, Total Reward: 10\n",
      "Episode: 3057, Total Reward: 9\n",
      "Episode: 3058, Total Reward: 9\n",
      "Episode: 3059, Total Reward: 7\n",
      "Episode: 3060, Total Reward: 3\n",
      "Episode: 3061, Total Reward: 7\n",
      "Episode: 3062, Total Reward: 11\n",
      "Episode: 3063, Total Reward: 9\n",
      "Episode: 3064, Total Reward: 9\n",
      "Episode: 3065, Total Reward: 13\n",
      "Episode: 3066, Total Reward: 8\n",
      "Episode: 3067, Total Reward: 9\n",
      "Episode: 3068, Total Reward: 10\n",
      "Episode: 3069, Total Reward: 11\n",
      "Episode: 3070, Total Reward: 11\n",
      "Episode: 3071, Total Reward: 5\n",
      "Episode: 3072, Total Reward: 11\n",
      "Episode: 3073, Total Reward: 9\n",
      "Episode: 3074, Total Reward: 8\n",
      "Episode: 3075, Total Reward: -16\n",
      "Episode: 3076, Total Reward: 7\n",
      "Episode: 3077, Total Reward: 1\n",
      "Episode: 3078, Total Reward: 10\n",
      "Episode: 3079, Total Reward: 5\n",
      "Episode: 3080, Total Reward: 12\n",
      "Episode: 3081, Total Reward: 4\n",
      "Episode: 3082, Total Reward: 6\n",
      "Episode: 3083, Total Reward: 8\n",
      "Episode: 3084, Total Reward: 8\n",
      "Episode: 3085, Total Reward: 10\n",
      "Episode: 3086, Total Reward: 7\n",
      "Episode: 3087, Total Reward: 14\n",
      "Episode: 3088, Total Reward: 5\n",
      "Episode: 3089, Total Reward: 5\n",
      "Episode: 3090, Total Reward: 4\n",
      "Episode: 3091, Total Reward: 11\n",
      "Episode: 3092, Total Reward: 9\n",
      "Episode: 3093, Total Reward: 12\n",
      "Episode: 3094, Total Reward: 4\n",
      "Episode: 3095, Total Reward: 10\n",
      "Episode: 3096, Total Reward: 7\n",
      "Episode: 3097, Total Reward: 5\n",
      "Episode: 3098, Total Reward: 8\n",
      "Episode: 3099, Total Reward: 7\n",
      "Episode: 3100, Total Reward: 11\n",
      "Episode: 3101, Total Reward: 9\n",
      "Episode: 3102, Total Reward: 8\n",
      "Episode: 3103, Total Reward: 5\n",
      "Episode: 3104, Total Reward: 11\n",
      "Episode: 3105, Total Reward: 3\n",
      "Episode: 3106, Total Reward: 11\n",
      "Episode: 3107, Total Reward: 5\n",
      "Episode: 3108, Total Reward: 8\n",
      "Episode: 3109, Total Reward: 13\n",
      "Episode: 3110, Total Reward: 8\n",
      "Episode: 3111, Total Reward: 9\n",
      "Episode: 3112, Total Reward: 8\n",
      "Episode: 3113, Total Reward: 7\n",
      "Episode: 3114, Total Reward: 5\n",
      "Episode: 3115, Total Reward: 6\n",
      "Episode: 3116, Total Reward: 6\n",
      "Episode: 3117, Total Reward: 9\n",
      "Episode: 3118, Total Reward: 7\n",
      "Episode: 3119, Total Reward: 10\n",
      "Episode: 3120, Total Reward: 9\n",
      "Episode: 3121, Total Reward: 6\n",
      "Episode: 3122, Total Reward: 12\n",
      "Episode: 3123, Total Reward: 7\n",
      "Episode: 3124, Total Reward: 3\n",
      "Episode: 3125, Total Reward: 10\n",
      "Episode: 3126, Total Reward: 3\n",
      "Episode: 3127, Total Reward: 8\n",
      "Episode: 3128, Total Reward: 5\n",
      "Episode: 3129, Total Reward: 9\n",
      "Episode: 3130, Total Reward: 11\n",
      "Episode: 3131, Total Reward: 9\n",
      "Episode: 3132, Total Reward: 8\n",
      "Episode: 3133, Total Reward: 7\n",
      "Episode: 3134, Total Reward: 10\n",
      "Episode: 3135, Total Reward: 9\n",
      "Episode: 3136, Total Reward: 9\n",
      "Episode: 3137, Total Reward: 8\n",
      "Episode: 3138, Total Reward: -3\n",
      "Episode: 3139, Total Reward: 9\n",
      "Episode: 3140, Total Reward: 9\n",
      "Episode: 3141, Total Reward: 9\n",
      "Episode: 3142, Total Reward: 7\n",
      "Episode: 3143, Total Reward: 7\n",
      "Episode: 3144, Total Reward: 8\n",
      "Episode: 3145, Total Reward: 11\n",
      "Episode: 3146, Total Reward: 6\n",
      "Episode: 3147, Total Reward: 7\n",
      "Episode: 3148, Total Reward: 7\n",
      "Episode: 3149, Total Reward: 4\n",
      "Episode: 3150, Total Reward: -4\n",
      "Episode: 3151, Total Reward: 9\n",
      "Episode: 3152, Total Reward: 10\n",
      "Episode: 3153, Total Reward: 5\n",
      "Episode: 3154, Total Reward: 8\n",
      "Episode: 3155, Total Reward: 6\n",
      "Episode: 3156, Total Reward: -1\n",
      "Episode: 3157, Total Reward: 11\n",
      "Episode: 3158, Total Reward: 10\n",
      "Episode: 3159, Total Reward: 10\n",
      "Episode: 3160, Total Reward: 6\n",
      "Episode: 3161, Total Reward: 5\n",
      "Episode: 3162, Total Reward: 7\n",
      "Episode: 3163, Total Reward: 10\n",
      "Episode: 3164, Total Reward: 13\n",
      "Episode: 3165, Total Reward: 4\n",
      "Episode: 3166, Total Reward: 7\n",
      "Episode: 3167, Total Reward: 10\n",
      "Episode: 3168, Total Reward: 9\n",
      "Episode: 3169, Total Reward: 4\n",
      "Episode: 3170, Total Reward: 5\n",
      "Episode: 3171, Total Reward: 12\n",
      "Episode: 3172, Total Reward: 9\n",
      "Episode: 3173, Total Reward: 7\n",
      "Episode: 3174, Total Reward: 10\n",
      "Episode: 3175, Total Reward: 13\n",
      "Episode: 3176, Total Reward: 8\n",
      "Episode: 3177, Total Reward: 11\n",
      "Episode: 3178, Total Reward: 11\n",
      "Episode: 3179, Total Reward: 12\n",
      "Episode: 3180, Total Reward: 7\n",
      "Episode: 3181, Total Reward: 4\n",
      "Episode: 3182, Total Reward: 11\n",
      "Episode: 3183, Total Reward: 8\n",
      "Episode: 3184, Total Reward: 11\n",
      "Episode: 3185, Total Reward: 6\n",
      "Episode: 3186, Total Reward: 4\n",
      "Episode: 3187, Total Reward: 7\n",
      "Episode: 3188, Total Reward: 4\n",
      "Episode: 3189, Total Reward: 3\n",
      "Episode: 3190, Total Reward: 7\n",
      "Episode: 3191, Total Reward: 10\n",
      "Episode: 3192, Total Reward: 5\n",
      "Episode: 3193, Total Reward: 13\n",
      "Episode: 3194, Total Reward: 6\n",
      "Episode: 3195, Total Reward: 9\n",
      "Episode: 3196, Total Reward: 5\n",
      "Episode: 3197, Total Reward: 6\n",
      "Episode: 3198, Total Reward: 5\n",
      "Episode: 3199, Total Reward: 5\n",
      "Episode: 3200, Total Reward: 11\n",
      "Episode: 3201, Total Reward: 6\n",
      "Episode: 3202, Total Reward: 12\n",
      "Episode: 3203, Total Reward: 9\n",
      "Episode: 3204, Total Reward: 7\n",
      "Episode: 3205, Total Reward: 6\n",
      "Episode: 3206, Total Reward: 7\n",
      "Episode: 3207, Total Reward: 4\n",
      "Episode: 3208, Total Reward: 7\n",
      "Episode: 3209, Total Reward: 11\n",
      "Episode: 3210, Total Reward: 5\n",
      "Episode: 3211, Total Reward: 5\n",
      "Episode: 3212, Total Reward: 2\n",
      "Episode: 3213, Total Reward: 6\n",
      "Episode: 3214, Total Reward: 12\n",
      "Episode: 3215, Total Reward: 7\n",
      "Episode: 3216, Total Reward: 6\n",
      "Episode: 3217, Total Reward: 8\n",
      "Episode: 3218, Total Reward: 6\n",
      "Episode: 3219, Total Reward: 6\n",
      "Episode: 3220, Total Reward: 9\n",
      "Episode: 3221, Total Reward: 10\n",
      "Episode: 3222, Total Reward: 5\n",
      "Episode: 3223, Total Reward: 8\n",
      "Episode: 3224, Total Reward: 11\n",
      "Episode: 3225, Total Reward: 8\n",
      "Episode: 3226, Total Reward: 6\n",
      "Episode: 3227, Total Reward: 7\n",
      "Episode: 3228, Total Reward: 13\n",
      "Episode: 3229, Total Reward: 6\n",
      "Episode: 3230, Total Reward: 8\n",
      "Episode: 3231, Total Reward: 7\n",
      "Episode: 3232, Total Reward: 6\n",
      "Episode: 3233, Total Reward: 7\n",
      "Episode: 3234, Total Reward: 7\n",
      "Episode: 3235, Total Reward: 7\n",
      "Episode: 3236, Total Reward: 9\n",
      "Episode: 3237, Total Reward: 7\n",
      "Episode: 3238, Total Reward: 7\n",
      "Episode: 3239, Total Reward: 7\n",
      "Episode: 3240, Total Reward: 8\n",
      "Episode: 3241, Total Reward: 5\n",
      "Episode: 3242, Total Reward: 6\n",
      "Episode: 3243, Total Reward: 2\n",
      "Episode: 3244, Total Reward: 5\n",
      "Episode: 3245, Total Reward: 9\n",
      "Episode: 3246, Total Reward: 13\n",
      "Episode: 3247, Total Reward: 6\n",
      "Episode: 3248, Total Reward: 1\n",
      "Episode: 3249, Total Reward: 4\n",
      "Episode: 3250, Total Reward: 8\n",
      "Episode: 3251, Total Reward: 12\n",
      "Episode: 3252, Total Reward: 6\n",
      "Episode: 3253, Total Reward: 6\n",
      "Episode: 3254, Total Reward: 13\n",
      "Episode: 3255, Total Reward: 8\n",
      "Episode: 3256, Total Reward: 7\n",
      "Episode: 3257, Total Reward: -4\n",
      "Episode: 3258, Total Reward: 7\n",
      "Episode: 3259, Total Reward: 5\n",
      "Episode: 3260, Total Reward: 10\n",
      "Episode: 3261, Total Reward: 5\n",
      "Episode: 3262, Total Reward: 9\n",
      "Episode: 3263, Total Reward: 5\n",
      "Episode: 3264, Total Reward: 8\n",
      "Episode: 3265, Total Reward: 7\n",
      "Episode: 3266, Total Reward: 8\n",
      "Episode: 3267, Total Reward: 8\n",
      "Episode: 3268, Total Reward: 6\n",
      "Episode: 3269, Total Reward: 10\n",
      "Episode: 3270, Total Reward: 5\n",
      "Episode: 3271, Total Reward: 6\n",
      "Episode: 3272, Total Reward: 14\n",
      "Episode: 3273, Total Reward: 7\n",
      "Episode: 3274, Total Reward: 10\n",
      "Episode: 3275, Total Reward: 6\n",
      "Episode: 3276, Total Reward: 3\n",
      "Episode: 3277, Total Reward: 8\n",
      "Episode: 3278, Total Reward: 6\n",
      "Episode: 3279, Total Reward: 9\n",
      "Episode: 3280, Total Reward: 7\n",
      "Episode: 3281, Total Reward: 9\n",
      "Episode: 3282, Total Reward: 4\n",
      "Episode: 3283, Total Reward: 7\n",
      "Episode: 3284, Total Reward: 11\n",
      "Episode: 3285, Total Reward: 6\n",
      "Episode: 3286, Total Reward: 5\n",
      "Episode: 3287, Total Reward: 7\n",
      "Episode: 3288, Total Reward: 6\n",
      "Episode: 3289, Total Reward: 8\n",
      "Episode: 3290, Total Reward: 6\n",
      "Episode: 3291, Total Reward: 9\n",
      "Episode: 3292, Total Reward: 8\n",
      "Episode: 3293, Total Reward: 9\n",
      "Episode: 3294, Total Reward: 6\n",
      "Episode: 3295, Total Reward: 13\n",
      "Episode: 3296, Total Reward: 9\n",
      "Episode: 3297, Total Reward: 11\n",
      "Episode: 3298, Total Reward: 8\n",
      "Episode: 3299, Total Reward: 5\n",
      "Episode: 3300, Total Reward: -4\n",
      "Episode: 3301, Total Reward: 11\n",
      "Episode: 3302, Total Reward: 9\n",
      "Episode: 3303, Total Reward: 3\n",
      "Episode: 3304, Total Reward: 10\n",
      "Episode: 3305, Total Reward: 13\n",
      "Episode: 3306, Total Reward: 12\n",
      "Episode: 3307, Total Reward: 4\n",
      "Episode: 3308, Total Reward: 8\n",
      "Episode: 3309, Total Reward: 9\n",
      "Episode: 3310, Total Reward: 9\n",
      "Episode: 3311, Total Reward: 14\n",
      "Episode: 3312, Total Reward: 7\n",
      "Episode: 3313, Total Reward: 8\n",
      "Episode: 3314, Total Reward: 9\n",
      "Episode: 3315, Total Reward: 12\n",
      "Episode: 3316, Total Reward: 13\n",
      "Episode: 3317, Total Reward: 5\n",
      "Episode: 3318, Total Reward: 5\n",
      "Episode: 3319, Total Reward: 4\n",
      "Episode: 3320, Total Reward: 7\n",
      "Episode: 3321, Total Reward: 9\n",
      "Episode: 3322, Total Reward: 10\n",
      "Episode: 3323, Total Reward: 10\n",
      "Episode: 3324, Total Reward: 6\n",
      "Episode: 3325, Total Reward: 7\n",
      "Episode: 3326, Total Reward: 9\n",
      "Episode: 3327, Total Reward: 10\n",
      "Episode: 3328, Total Reward: 0\n",
      "Episode: 3329, Total Reward: 10\n",
      "Episode: 3330, Total Reward: 8\n",
      "Episode: 3331, Total Reward: 11\n",
      "Episode: 3332, Total Reward: 5\n",
      "Episode: 3333, Total Reward: 14\n",
      "Episode: 3334, Total Reward: 4\n",
      "Episode: 3335, Total Reward: 10\n",
      "Episode: 3336, Total Reward: 7\n",
      "Episode: 3337, Total Reward: 3\n",
      "Episode: 3338, Total Reward: 7\n",
      "Episode: 3339, Total Reward: 9\n",
      "Episode: 3340, Total Reward: 2\n",
      "Episode: 3341, Total Reward: 7\n",
      "Episode: 3342, Total Reward: 11\n",
      "Episode: 3343, Total Reward: 5\n",
      "Episode: 3344, Total Reward: 7\n",
      "Episode: 3345, Total Reward: 8\n",
      "Episode: 3346, Total Reward: 13\n",
      "Episode: 3347, Total Reward: 9\n",
      "Episode: 3348, Total Reward: 5\n",
      "Episode: 3349, Total Reward: 5\n",
      "Episode: 3350, Total Reward: 10\n",
      "Episode: 3351, Total Reward: 4\n",
      "Episode: 3352, Total Reward: 7\n",
      "Episode: 3353, Total Reward: 8\n",
      "Episode: 3354, Total Reward: 9\n",
      "Episode: 3355, Total Reward: 5\n",
      "Episode: 3356, Total Reward: 6\n",
      "Episode: 3357, Total Reward: 10\n",
      "Episode: 3358, Total Reward: 13\n",
      "Episode: 3359, Total Reward: 9\n",
      "Episode: 3360, Total Reward: 4\n",
      "Episode: 3361, Total Reward: 6\n",
      "Episode: 3362, Total Reward: 6\n",
      "Episode: 3363, Total Reward: 5\n",
      "Episode: 3364, Total Reward: 10\n",
      "Episode: 3365, Total Reward: 10\n",
      "Episode: 3366, Total Reward: 7\n",
      "Episode: 3367, Total Reward: 11\n",
      "Episode: 3368, Total Reward: 9\n",
      "Episode: 3369, Total Reward: 5\n",
      "Episode: 3370, Total Reward: 13\n",
      "Episode: 3371, Total Reward: 11\n",
      "Episode: 3372, Total Reward: 8\n",
      "Episode: 3373, Total Reward: 4\n",
      "Episode: 3374, Total Reward: 8\n",
      "Episode: 3375, Total Reward: 7\n",
      "Episode: 3376, Total Reward: 7\n",
      "Episode: 3377, Total Reward: 7\n",
      "Episode: 3378, Total Reward: 12\n",
      "Episode: 3379, Total Reward: 10\n",
      "Episode: 3380, Total Reward: 8\n",
      "Episode: 3381, Total Reward: 7\n",
      "Episode: 3382, Total Reward: 11\n",
      "Episode: 3383, Total Reward: 10\n",
      "Episode: 3384, Total Reward: 9\n",
      "Episode: 3385, Total Reward: 7\n",
      "Episode: 3386, Total Reward: 7\n",
      "Episode: 3387, Total Reward: 4\n",
      "Episode: 3388, Total Reward: 6\n",
      "Episode: 3389, Total Reward: 11\n",
      "Episode: 3390, Total Reward: 11\n",
      "Episode: 3391, Total Reward: 8\n",
      "Episode: 3392, Total Reward: 7\n",
      "Episode: 3393, Total Reward: 5\n",
      "Episode: 3394, Total Reward: 9\n",
      "Episode: 3395, Total Reward: 9\n",
      "Episode: 3396, Total Reward: 8\n",
      "Episode: 3397, Total Reward: 9\n",
      "Episode: 3398, Total Reward: 11\n",
      "Episode: 3399, Total Reward: 6\n",
      "Episode: 3400, Total Reward: 7\n",
      "Episode: 3401, Total Reward: 9\n",
      "Episode: 3402, Total Reward: 5\n",
      "Episode: 3403, Total Reward: 3\n",
      "Episode: 3404, Total Reward: 10\n",
      "Episode: 3405, Total Reward: 6\n",
      "Episode: 3406, Total Reward: 9\n",
      "Episode: 3407, Total Reward: 12\n",
      "Episode: 3408, Total Reward: 10\n",
      "Episode: 3409, Total Reward: 4\n",
      "Episode: 3410, Total Reward: 13\n",
      "Episode: 3411, Total Reward: 7\n",
      "Episode: 3412, Total Reward: -5\n",
      "Episode: 3413, Total Reward: 7\n",
      "Episode: 3414, Total Reward: 6\n",
      "Episode: 3415, Total Reward: 7\n",
      "Episode: 3416, Total Reward: 4\n",
      "Episode: 3417, Total Reward: 9\n",
      "Episode: 3418, Total Reward: 11\n",
      "Episode: 3419, Total Reward: 9\n",
      "Episode: 3420, Total Reward: 10\n",
      "Episode: 3421, Total Reward: 10\n",
      "Episode: 3422, Total Reward: 13\n",
      "Episode: 3423, Total Reward: 5\n",
      "Episode: 3424, Total Reward: 9\n",
      "Episode: 3425, Total Reward: 10\n",
      "Episode: 3426, Total Reward: 9\n",
      "Episode: 3427, Total Reward: 10\n",
      "Episode: 3428, Total Reward: 12\n",
      "Episode: 3429, Total Reward: 13\n",
      "Episode: 3430, Total Reward: 7\n",
      "Episode: 3431, Total Reward: 10\n",
      "Episode: 3432, Total Reward: 11\n",
      "Episode: 3433, Total Reward: 5\n",
      "Episode: 3434, Total Reward: 10\n",
      "Episode: 3435, Total Reward: 10\n",
      "Episode: 3436, Total Reward: 9\n",
      "Episode: 3437, Total Reward: 6\n",
      "Episode: 3438, Total Reward: 9\n",
      "Episode: 3439, Total Reward: 8\n",
      "Episode: 3440, Total Reward: 4\n",
      "Episode: 3441, Total Reward: 12\n",
      "Episode: 3442, Total Reward: 15\n",
      "Episode: 3443, Total Reward: 6\n",
      "Episode: 3444, Total Reward: 11\n",
      "Episode: 3445, Total Reward: 5\n",
      "Episode: 3446, Total Reward: 11\n",
      "Episode: 3447, Total Reward: -1\n",
      "Episode: 3448, Total Reward: 4\n",
      "Episode: 3449, Total Reward: 11\n",
      "Episode: 3450, Total Reward: 5\n",
      "Episode: 3451, Total Reward: 12\n",
      "Episode: 3452, Total Reward: 7\n",
      "Episode: 3453, Total Reward: 10\n",
      "Episode: 3454, Total Reward: 11\n",
      "Episode: 3455, Total Reward: 12\n",
      "Episode: 3456, Total Reward: 7\n",
      "Episode: 3457, Total Reward: 7\n",
      "Episode: 3458, Total Reward: 7\n",
      "Episode: 3459, Total Reward: 10\n",
      "Episode: 3460, Total Reward: 9\n",
      "Episode: 3461, Total Reward: -6\n",
      "Episode: 3462, Total Reward: 10\n",
      "Episode: 3463, Total Reward: 4\n",
      "Episode: 3464, Total Reward: 13\n",
      "Episode: 3465, Total Reward: 4\n",
      "Episode: 3466, Total Reward: 4\n",
      "Episode: 3467, Total Reward: 10\n",
      "Episode: 3468, Total Reward: 5\n",
      "Episode: 3469, Total Reward: 13\n",
      "Episode: 3470, Total Reward: 9\n",
      "Episode: 3471, Total Reward: 11\n",
      "Episode: 3472, Total Reward: 5\n",
      "Episode: 3473, Total Reward: 7\n",
      "Episode: 3474, Total Reward: 8\n",
      "Episode: 3475, Total Reward: 5\n",
      "Episode: 3476, Total Reward: 8\n",
      "Episode: 3477, Total Reward: 7\n",
      "Episode: 3478, Total Reward: 4\n",
      "Episode: 3479, Total Reward: 6\n",
      "Episode: 3480, Total Reward: 3\n",
      "Episode: 3481, Total Reward: 9\n",
      "Episode: 3482, Total Reward: 10\n",
      "Episode: 3483, Total Reward: 13\n",
      "Episode: 3484, Total Reward: 9\n",
      "Episode: 3485, Total Reward: 13\n",
      "Episode: 3486, Total Reward: 6\n",
      "Episode: 3487, Total Reward: 9\n",
      "Episode: 3488, Total Reward: 8\n",
      "Episode: 3489, Total Reward: 8\n",
      "Episode: 3490, Total Reward: 9\n",
      "Episode: 3491, Total Reward: 7\n",
      "Episode: 3492, Total Reward: 11\n",
      "Episode: 3493, Total Reward: 11\n",
      "Episode: 3494, Total Reward: 7\n",
      "Episode: 3495, Total Reward: 8\n",
      "Episode: 3496, Total Reward: 10\n",
      "Episode: 3497, Total Reward: 14\n",
      "Episode: 3498, Total Reward: 11\n",
      "Episode: 3499, Total Reward: 10\n",
      "Episode: 3500, Total Reward: 5\n",
      "Episode: 3501, Total Reward: 6\n",
      "Episode: 3502, Total Reward: 8\n",
      "Episode: 3503, Total Reward: 6\n",
      "Episode: 3504, Total Reward: 9\n",
      "Episode: 3505, Total Reward: 8\n",
      "Episode: 3506, Total Reward: 8\n",
      "Episode: 3507, Total Reward: 10\n",
      "Episode: 3508, Total Reward: 5\n",
      "Episode: 3509, Total Reward: 6\n",
      "Episode: 3510, Total Reward: 10\n",
      "Episode: 3511, Total Reward: 8\n",
      "Episode: 3512, Total Reward: 8\n",
      "Episode: 3513, Total Reward: 9\n",
      "Episode: 3514, Total Reward: 7\n",
      "Episode: 3515, Total Reward: 12\n",
      "Episode: 3516, Total Reward: 8\n",
      "Episode: 3517, Total Reward: 10\n",
      "Episode: 3518, Total Reward: 7\n",
      "Episode: 3519, Total Reward: 9\n",
      "Episode: 3520, Total Reward: 12\n",
      "Episode: 3521, Total Reward: 7\n",
      "Episode: 3522, Total Reward: 12\n",
      "Episode: 3523, Total Reward: 6\n",
      "Episode: 3524, Total Reward: 9\n",
      "Episode: 3525, Total Reward: 5\n",
      "Episode: 3526, Total Reward: 14\n",
      "Episode: 3527, Total Reward: 7\n",
      "Episode: 3528, Total Reward: 6\n",
      "Episode: 3529, Total Reward: 3\n",
      "Episode: 3530, Total Reward: 8\n",
      "Episode: 3531, Total Reward: 11\n",
      "Episode: 3532, Total Reward: 6\n",
      "Episode: 3533, Total Reward: 6\n",
      "Episode: 3534, Total Reward: 9\n",
      "Episode: 3535, Total Reward: 8\n",
      "Episode: 3536, Total Reward: 4\n",
      "Episode: 3537, Total Reward: 5\n",
      "Episode: 3538, Total Reward: 4\n",
      "Episode: 3539, Total Reward: 9\n",
      "Episode: 3540, Total Reward: 10\n",
      "Episode: 3541, Total Reward: 6\n",
      "Episode: 3542, Total Reward: 10\n",
      "Episode: 3543, Total Reward: 10\n",
      "Episode: 3544, Total Reward: 6\n",
      "Episode: 3545, Total Reward: 7\n",
      "Episode: 3546, Total Reward: 4\n",
      "Episode: 3547, Total Reward: 5\n",
      "Episode: 3548, Total Reward: 9\n",
      "Episode: 3549, Total Reward: 6\n",
      "Episode: 3550, Total Reward: -3\n",
      "Episode: 3551, Total Reward: 11\n",
      "Episode: 3552, Total Reward: 6\n",
      "Episode: 3553, Total Reward: 10\n",
      "Episode: 3554, Total Reward: 7\n",
      "Episode: 3555, Total Reward: 8\n",
      "Episode: 3556, Total Reward: 11\n",
      "Episode: 3557, Total Reward: 7\n",
      "Episode: 3558, Total Reward: 8\n",
      "Episode: 3559, Total Reward: 13\n",
      "Episode: 3560, Total Reward: 9\n",
      "Episode: 3561, Total Reward: 12\n",
      "Episode: 3562, Total Reward: 9\n",
      "Episode: 3563, Total Reward: 7\n",
      "Episode: 3564, Total Reward: 8\n",
      "Episode: 3565, Total Reward: 6\n",
      "Episode: 3566, Total Reward: 9\n",
      "Episode: 3567, Total Reward: 13\n",
      "Episode: 3568, Total Reward: 6\n",
      "Episode: 3569, Total Reward: 4\n",
      "Episode: 3570, Total Reward: -2\n",
      "Episode: 3571, Total Reward: 4\n",
      "Episode: 3572, Total Reward: 11\n",
      "Episode: 3573, Total Reward: 5\n",
      "Episode: 3574, Total Reward: 7\n",
      "Episode: 3575, Total Reward: -4\n",
      "Episode: 3576, Total Reward: 5\n",
      "Episode: 3577, Total Reward: 9\n",
      "Episode: 3578, Total Reward: 8\n",
      "Episode: 3579, Total Reward: 10\n",
      "Episode: 3580, Total Reward: 7\n",
      "Episode: 3581, Total Reward: 10\n",
      "Episode: 3582, Total Reward: 10\n",
      "Episode: 3583, Total Reward: 8\n",
      "Episode: 3584, Total Reward: 6\n",
      "Episode: 3585, Total Reward: 10\n",
      "Episode: 3586, Total Reward: 3\n",
      "Episode: 3587, Total Reward: 5\n",
      "Episode: 3588, Total Reward: 7\n",
      "Episode: 3589, Total Reward: 7\n",
      "Episode: 3590, Total Reward: 6\n",
      "Episode: 3591, Total Reward: 4\n",
      "Episode: 3592, Total Reward: 3\n",
      "Episode: 3593, Total Reward: 9\n",
      "Episode: 3594, Total Reward: 3\n",
      "Episode: 3595, Total Reward: 9\n",
      "Episode: 3596, Total Reward: 5\n",
      "Episode: 3597, Total Reward: 11\n",
      "Episode: 3598, Total Reward: -2\n",
      "Episode: 3599, Total Reward: 8\n",
      "Episode: 3600, Total Reward: -2\n",
      "Episode: 3601, Total Reward: 9\n",
      "Episode: 3602, Total Reward: 5\n",
      "Episode: 3603, Total Reward: 6\n",
      "Episode: 3604, Total Reward: 11\n",
      "Episode: 3605, Total Reward: 12\n",
      "Episode: 3606, Total Reward: 9\n",
      "Episode: 3607, Total Reward: 11\n",
      "Episode: 3608, Total Reward: 10\n",
      "Episode: 3609, Total Reward: 5\n",
      "Episode: 3610, Total Reward: 8\n",
      "Episode: 3611, Total Reward: 7\n",
      "Episode: 3612, Total Reward: 5\n",
      "Episode: 3613, Total Reward: 9\n",
      "Episode: 3614, Total Reward: 8\n",
      "Episode: 3615, Total Reward: 7\n",
      "Episode: 3616, Total Reward: 8\n",
      "Episode: 3617, Total Reward: 12\n",
      "Episode: 3618, Total Reward: 8\n",
      "Episode: 3619, Total Reward: 8\n",
      "Episode: 3620, Total Reward: 8\n",
      "Episode: 3621, Total Reward: 11\n",
      "Episode: 3622, Total Reward: 9\n",
      "Episode: 3623, Total Reward: 10\n",
      "Episode: 3624, Total Reward: 7\n",
      "Episode: 3625, Total Reward: 11\n",
      "Episode: 3626, Total Reward: 10\n",
      "Episode: 3627, Total Reward: 10\n",
      "Episode: 3628, Total Reward: 11\n",
      "Episode: 3629, Total Reward: 8\n",
      "Episode: 3630, Total Reward: 12\n",
      "Episode: 3631, Total Reward: 10\n",
      "Episode: 3632, Total Reward: 7\n",
      "Episode: 3633, Total Reward: 9\n",
      "Episode: 3634, Total Reward: -4\n",
      "Episode: 3635, Total Reward: 3\n",
      "Episode: 3636, Total Reward: 11\n",
      "Episode: 3637, Total Reward: 13\n",
      "Episode: 3638, Total Reward: 14\n",
      "Episode: 3639, Total Reward: 5\n",
      "Episode: 3640, Total Reward: 4\n",
      "Episode: 3641, Total Reward: 9\n",
      "Episode: 3642, Total Reward: 9\n",
      "Episode: 3643, Total Reward: 6\n",
      "Episode: 3644, Total Reward: 9\n",
      "Episode: 3645, Total Reward: 7\n",
      "Episode: 3646, Total Reward: 14\n",
      "Episode: 3647, Total Reward: 12\n",
      "Episode: 3648, Total Reward: 6\n",
      "Episode: 3649, Total Reward: 8\n",
      "Episode: 3650, Total Reward: 3\n",
      "Episode: 3651, Total Reward: 8\n",
      "Episode: 3652, Total Reward: -4\n",
      "Episode: 3653, Total Reward: -2\n",
      "Episode: 3654, Total Reward: 5\n",
      "Episode: 3655, Total Reward: 7\n",
      "Episode: 3656, Total Reward: 9\n",
      "Episode: 3657, Total Reward: 4\n",
      "Episode: 3658, Total Reward: 9\n",
      "Episode: 3659, Total Reward: 7\n",
      "Episode: 3660, Total Reward: 7\n",
      "Episode: 3661, Total Reward: 10\n",
      "Episode: 3662, Total Reward: 8\n",
      "Episode: 3663, Total Reward: 8\n",
      "Episode: 3664, Total Reward: 8\n",
      "Episode: 3665, Total Reward: 8\n",
      "Episode: 3666, Total Reward: 11\n",
      "Episode: 3667, Total Reward: 4\n",
      "Episode: 3668, Total Reward: 12\n",
      "Episode: 3669, Total Reward: 10\n",
      "Episode: 3670, Total Reward: 8\n",
      "Episode: 3671, Total Reward: 6\n",
      "Episode: 3672, Total Reward: 9\n",
      "Episode: 3673, Total Reward: 4\n",
      "Episode: 3674, Total Reward: 9\n",
      "Episode: 3675, Total Reward: 6\n",
      "Episode: 3676, Total Reward: -4\n",
      "Episode: 3677, Total Reward: 6\n",
      "Episode: 3678, Total Reward: 6\n",
      "Episode: 3679, Total Reward: 4\n",
      "Episode: 3680, Total Reward: 4\n",
      "Episode: 3681, Total Reward: 7\n",
      "Episode: 3682, Total Reward: 9\n",
      "Episode: 3683, Total Reward: 9\n",
      "Episode: 3684, Total Reward: 4\n",
      "Episode: 3685, Total Reward: 8\n",
      "Episode: 3686, Total Reward: 8\n",
      "Episode: 3687, Total Reward: 12\n",
      "Episode: 3688, Total Reward: 5\n",
      "Episode: 3689, Total Reward: 8\n",
      "Episode: 3690, Total Reward: 5\n",
      "Episode: 3691, Total Reward: 5\n",
      "Episode: 3692, Total Reward: -7\n",
      "Episode: 3693, Total Reward: 13\n",
      "Episode: 3694, Total Reward: 5\n",
      "Episode: 3695, Total Reward: 7\n",
      "Episode: 3696, Total Reward: -5\n",
      "Episode: 3697, Total Reward: 9\n",
      "Episode: 3698, Total Reward: 10\n",
      "Episode: 3699, Total Reward: 8\n",
      "Episode: 3700, Total Reward: 5\n",
      "Episode: 3701, Total Reward: 8\n",
      "Episode: 3702, Total Reward: 14\n",
      "Episode: 3703, Total Reward: 9\n",
      "Episode: 3704, Total Reward: 5\n",
      "Episode: 3705, Total Reward: 9\n",
      "Episode: 3706, Total Reward: 7\n",
      "Episode: 3707, Total Reward: 5\n",
      "Episode: 3708, Total Reward: 8\n",
      "Episode: 3709, Total Reward: 11\n",
      "Episode: 3710, Total Reward: 4\n",
      "Episode: 3711, Total Reward: 6\n",
      "Episode: 3712, Total Reward: 8\n",
      "Episode: 3713, Total Reward: 7\n",
      "Episode: 3714, Total Reward: 7\n",
      "Episode: 3715, Total Reward: 0\n",
      "Episode: 3716, Total Reward: 6\n",
      "Episode: 3717, Total Reward: 7\n",
      "Episode: 3718, Total Reward: 9\n",
      "Episode: 3719, Total Reward: 7\n",
      "Episode: 3720, Total Reward: -4\n",
      "Episode: 3721, Total Reward: 7\n",
      "Episode: 3722, Total Reward: 3\n",
      "Episode: 3723, Total Reward: 11\n",
      "Episode: 3724, Total Reward: 9\n",
      "Episode: 3725, Total Reward: 6\n",
      "Episode: 3726, Total Reward: 10\n",
      "Episode: 3727, Total Reward: 14\n",
      "Episode: 3728, Total Reward: 4\n",
      "Episode: 3729, Total Reward: 7\n",
      "Episode: 3730, Total Reward: 14\n",
      "Episode: 3731, Total Reward: 10\n",
      "Episode: 3732, Total Reward: 9\n",
      "Episode: 3733, Total Reward: 5\n",
      "Episode: 3734, Total Reward: 7\n",
      "Episode: 3735, Total Reward: 5\n",
      "Episode: 3736, Total Reward: 9\n",
      "Episode: 3737, Total Reward: 14\n",
      "Episode: 3738, Total Reward: 10\n",
      "Episode: 3739, Total Reward: 8\n",
      "Episode: 3740, Total Reward: 6\n",
      "Episode: 3741, Total Reward: 6\n",
      "Episode: 3742, Total Reward: 10\n",
      "Episode: 3743, Total Reward: -4\n",
      "Episode: 3744, Total Reward: 9\n",
      "Episode: 3745, Total Reward: 6\n",
      "Episode: 3746, Total Reward: 7\n",
      "Episode: 3747, Total Reward: 6\n",
      "Episode: 3748, Total Reward: 8\n",
      "Episode: 3749, Total Reward: 5\n",
      "Episode: 3750, Total Reward: 7\n",
      "Episode: 3751, Total Reward: 7\n",
      "Episode: 3752, Total Reward: 4\n",
      "Episode: 3753, Total Reward: 2\n",
      "Episode: 3754, Total Reward: 5\n",
      "Episode: 3755, Total Reward: 10\n",
      "Episode: 3756, Total Reward: 9\n",
      "Episode: 3757, Total Reward: 7\n",
      "Episode: 3758, Total Reward: 5\n",
      "Episode: 3759, Total Reward: -1\n",
      "Episode: 3760, Total Reward: 13\n",
      "Episode: 3761, Total Reward: 11\n",
      "Episode: 3762, Total Reward: 8\n",
      "Episode: 3763, Total Reward: 5\n",
      "Episode: 3764, Total Reward: 9\n",
      "Episode: 3765, Total Reward: 6\n",
      "Episode: 3766, Total Reward: 6\n",
      "Episode: 3767, Total Reward: 8\n",
      "Episode: 3768, Total Reward: 10\n",
      "Episode: 3769, Total Reward: 8\n",
      "Episode: 3770, Total Reward: 6\n",
      "Episode: 3771, Total Reward: 10\n",
      "Episode: 3772, Total Reward: 10\n",
      "Episode: 3773, Total Reward: 6\n",
      "Episode: 3774, Total Reward: 14\n",
      "Episode: 3775, Total Reward: 14\n",
      "Episode: 3776, Total Reward: 4\n",
      "Episode: 3777, Total Reward: 15\n",
      "Episode: 3778, Total Reward: 10\n",
      "Episode: 3779, Total Reward: 5\n",
      "Episode: 3780, Total Reward: 12\n",
      "Episode: 3781, Total Reward: 7\n",
      "Episode: 3782, Total Reward: 4\n",
      "Episode: 3783, Total Reward: 10\n",
      "Episode: 3784, Total Reward: 7\n",
      "Episode: 3785, Total Reward: 4\n",
      "Episode: 3786, Total Reward: 9\n",
      "Episode: 3787, Total Reward: 4\n",
      "Episode: 3788, Total Reward: 15\n",
      "Episode: 3789, Total Reward: 9\n",
      "Episode: 3790, Total Reward: 11\n",
      "Episode: 3791, Total Reward: 6\n",
      "Episode: 3792, Total Reward: 9\n",
      "Episode: 3793, Total Reward: 6\n",
      "Episode: 3794, Total Reward: 2\n",
      "Episode: 3795, Total Reward: 5\n",
      "Episode: 3796, Total Reward: 10\n",
      "Episode: 3797, Total Reward: 4\n",
      "Episode: 3798, Total Reward: 8\n",
      "Episode: 3799, Total Reward: 8\n",
      "Episode: 3800, Total Reward: 5\n",
      "Episode: 3801, Total Reward: 7\n",
      "Episode: 3802, Total Reward: 6\n",
      "Episode: 3803, Total Reward: 11\n",
      "Episode: 3804, Total Reward: 8\n",
      "Episode: 3805, Total Reward: 4\n",
      "Episode: 3806, Total Reward: 4\n",
      "Episode: 3807, Total Reward: 5\n",
      "Episode: 3808, Total Reward: 5\n",
      "Episode: 3809, Total Reward: 12\n",
      "Episode: 3810, Total Reward: -6\n",
      "Episode: 3811, Total Reward: 9\n",
      "Episode: 3812, Total Reward: 7\n",
      "Episode: 3813, Total Reward: 10\n",
      "Episode: 3814, Total Reward: 5\n",
      "Episode: 3815, Total Reward: 5\n",
      "Episode: 3816, Total Reward: 10\n",
      "Episode: 3817, Total Reward: 8\n",
      "Episode: 3818, Total Reward: 7\n",
      "Episode: 3819, Total Reward: 11\n",
      "Episode: 3820, Total Reward: 8\n",
      "Episode: 3821, Total Reward: 9\n",
      "Episode: 3822, Total Reward: 10\n",
      "Episode: 3823, Total Reward: 6\n",
      "Episode: 3824, Total Reward: 10\n",
      "Episode: 3825, Total Reward: 7\n",
      "Episode: 3826, Total Reward: 15\n",
      "Episode: 3827, Total Reward: 11\n",
      "Episode: 3828, Total Reward: 5\n",
      "Episode: 3829, Total Reward: 11\n",
      "Episode: 3830, Total Reward: 10\n",
      "Episode: 3831, Total Reward: 5\n",
      "Episode: 3832, Total Reward: 9\n",
      "Episode: 3833, Total Reward: 2\n",
      "Episode: 3834, Total Reward: 1\n",
      "Episode: 3835, Total Reward: 5\n",
      "Episode: 3836, Total Reward: 6\n",
      "Episode: 3837, Total Reward: 10\n",
      "Episode: 3838, Total Reward: 6\n",
      "Episode: 3839, Total Reward: 8\n",
      "Episode: 3840, Total Reward: 5\n",
      "Episode: 3841, Total Reward: 4\n",
      "Episode: 3842, Total Reward: 8\n",
      "Episode: 3843, Total Reward: 4\n",
      "Episode: 3844, Total Reward: 8\n",
      "Episode: 3845, Total Reward: 8\n",
      "Episode: 3846, Total Reward: 9\n",
      "Episode: 3847, Total Reward: 11\n",
      "Episode: 3848, Total Reward: 6\n",
      "Episode: 3849, Total Reward: 6\n",
      "Episode: 3850, Total Reward: 12\n",
      "Episode: 3851, Total Reward: 8\n",
      "Episode: 3852, Total Reward: 9\n",
      "Episode: 3853, Total Reward: 5\n",
      "Episode: 3854, Total Reward: 8\n",
      "Episode: 3855, Total Reward: 4\n",
      "Episode: 3856, Total Reward: 8\n",
      "Episode: 3857, Total Reward: 8\n",
      "Episode: 3858, Total Reward: 8\n",
      "Episode: 3859, Total Reward: -6\n",
      "Episode: 3860, Total Reward: 6\n",
      "Episode: 3861, Total Reward: 4\n",
      "Episode: 3862, Total Reward: 5\n",
      "Episode: 3863, Total Reward: 6\n",
      "Episode: 3864, Total Reward: 10\n",
      "Episode: 3865, Total Reward: 8\n",
      "Episode: 3866, Total Reward: 13\n",
      "Episode: 3867, Total Reward: 11\n",
      "Episode: 3868, Total Reward: 4\n",
      "Episode: 3869, Total Reward: 7\n",
      "Episode: 3870, Total Reward: 6\n",
      "Episode: 3871, Total Reward: 4\n",
      "Episode: 3872, Total Reward: 10\n",
      "Episode: 3873, Total Reward: 8\n",
      "Episode: 3874, Total Reward: 12\n",
      "Episode: 3875, Total Reward: 7\n",
      "Episode: 3876, Total Reward: 8\n",
      "Episode: 3877, Total Reward: 3\n",
      "Episode: 3878, Total Reward: 4\n",
      "Episode: 3879, Total Reward: 9\n",
      "Episode: 3880, Total Reward: 9\n",
      "Episode: 3881, Total Reward: 9\n",
      "Episode: 3882, Total Reward: 9\n",
      "Episode: 3883, Total Reward: 9\n",
      "Episode: 3884, Total Reward: -5\n",
      "Episode: 3885, Total Reward: 12\n",
      "Episode: 3886, Total Reward: 11\n",
      "Episode: 3887, Total Reward: 8\n",
      "Episode: 3888, Total Reward: 9\n",
      "Episode: 3889, Total Reward: 5\n",
      "Episode: 3890, Total Reward: 9\n",
      "Episode: 3891, Total Reward: -3\n",
      "Episode: 3892, Total Reward: 9\n",
      "Episode: 3893, Total Reward: 6\n",
      "Episode: 3894, Total Reward: 9\n",
      "Episode: 3895, Total Reward: 9\n",
      "Episode: 3896, Total Reward: 5\n",
      "Episode: 3897, Total Reward: 6\n",
      "Episode: 3898, Total Reward: 6\n",
      "Episode: 3899, Total Reward: 7\n",
      "Episode: 3900, Total Reward: 7\n",
      "Episode: 3901, Total Reward: 9\n",
      "Episode: 3902, Total Reward: 11\n",
      "Episode: 3903, Total Reward: 5\n",
      "Episode: 3904, Total Reward: 10\n",
      "Episode: 3905, Total Reward: 3\n",
      "Episode: 3906, Total Reward: 9\n",
      "Episode: 3907, Total Reward: 9\n",
      "Episode: 3908, Total Reward: 5\n",
      "Episode: 3909, Total Reward: 3\n",
      "Episode: 3910, Total Reward: 5\n",
      "Episode: 3911, Total Reward: 9\n",
      "Episode: 3912, Total Reward: 9\n",
      "Episode: 3913, Total Reward: 14\n",
      "Episode: 3914, Total Reward: 7\n",
      "Episode: 3915, Total Reward: 9\n",
      "Episode: 3916, Total Reward: 10\n",
      "Episode: 3917, Total Reward: 5\n",
      "Episode: 3918, Total Reward: 9\n",
      "Episode: 3919, Total Reward: 7\n",
      "Episode: 3920, Total Reward: 6\n",
      "Episode: 3921, Total Reward: 11\n",
      "Episode: 3922, Total Reward: -3\n",
      "Episode: 3923, Total Reward: 8\n",
      "Episode: 3924, Total Reward: 8\n",
      "Episode: 3925, Total Reward: -4\n",
      "Episode: 3926, Total Reward: 4\n",
      "Episode: 3927, Total Reward: 5\n",
      "Episode: 3928, Total Reward: 6\n",
      "Episode: 3929, Total Reward: 8\n",
      "Episode: 3930, Total Reward: 12\n",
      "Episode: 3931, Total Reward: 10\n",
      "Episode: 3932, Total Reward: 3\n",
      "Episode: 3933, Total Reward: 7\n",
      "Episode: 3934, Total Reward: 7\n",
      "Episode: 3935, Total Reward: 6\n",
      "Episode: 3936, Total Reward: 11\n",
      "Episode: 3937, Total Reward: 6\n",
      "Episode: 3938, Total Reward: 3\n",
      "Episode: 3939, Total Reward: 9\n",
      "Episode: 3940, Total Reward: 8\n",
      "Episode: 3941, Total Reward: 5\n",
      "Episode: 3942, Total Reward: 9\n",
      "Episode: 3943, Total Reward: 7\n",
      "Episode: 3944, Total Reward: 7\n",
      "Episode: 3945, Total Reward: 7\n",
      "Episode: 3946, Total Reward: 10\n",
      "Episode: 3947, Total Reward: 4\n",
      "Episode: 3948, Total Reward: 5\n",
      "Episode: 3949, Total Reward: 11\n",
      "Episode: 3950, Total Reward: 10\n",
      "Episode: 3951, Total Reward: 8\n",
      "Episode: 3952, Total Reward: 9\n",
      "Episode: 3953, Total Reward: 6\n",
      "Episode: 3954, Total Reward: 6\n",
      "Episode: 3955, Total Reward: 7\n",
      "Episode: 3956, Total Reward: 4\n",
      "Episode: 3957, Total Reward: 6\n",
      "Episode: 3958, Total Reward: 12\n",
      "Episode: 3959, Total Reward: 10\n",
      "Episode: 3960, Total Reward: 6\n",
      "Episode: 3961, Total Reward: 5\n",
      "Episode: 3962, Total Reward: 3\n",
      "Episode: 3963, Total Reward: 8\n",
      "Episode: 3964, Total Reward: 8\n",
      "Episode: 3965, Total Reward: 4\n",
      "Episode: 3966, Total Reward: 8\n",
      "Episode: 3967, Total Reward: 8\n",
      "Episode: 3968, Total Reward: 11\n",
      "Episode: 3969, Total Reward: 10\n",
      "Episode: 3970, Total Reward: 4\n",
      "Episode: 3971, Total Reward: 7\n",
      "Episode: 3972, Total Reward: 9\n",
      "Episode: 3973, Total Reward: 8\n",
      "Episode: 3974, Total Reward: 10\n",
      "Episode: 3975, Total Reward: 0\n",
      "Episode: 3976, Total Reward: 9\n",
      "Episode: 3977, Total Reward: 8\n",
      "Episode: 3978, Total Reward: 8\n",
      "Episode: 3979, Total Reward: 8\n",
      "Episode: 3980, Total Reward: 11\n",
      "Episode: 3981, Total Reward: 6\n",
      "Episode: 3982, Total Reward: 12\n",
      "Episode: 3983, Total Reward: 10\n",
      "Episode: 3984, Total Reward: 10\n",
      "Episode: 3985, Total Reward: 9\n",
      "Episode: 3986, Total Reward: 8\n",
      "Episode: 3987, Total Reward: 14\n",
      "Episode: 3988, Total Reward: 14\n",
      "Episode: 3989, Total Reward: 4\n",
      "Episode: 3990, Total Reward: 7\n",
      "Episode: 3991, Total Reward: 9\n",
      "Episode: 3992, Total Reward: 5\n",
      "Episode: 3993, Total Reward: 10\n",
      "Episode: 3994, Total Reward: 5\n",
      "Episode: 3995, Total Reward: 8\n",
      "Episode: 3996, Total Reward: 9\n",
      "Episode: 3997, Total Reward: 8\n",
      "Episode: 3998, Total Reward: 5\n",
      "Episode: 3999, Total Reward: 9\n",
      "Episode: 4000, Total Reward: 9\n",
      "Episode: 4001, Total Reward: 6\n",
      "Episode: 4002, Total Reward: 5\n",
      "Episode: 4003, Total Reward: 4\n",
      "Episode: 4004, Total Reward: 8\n",
      "Episode: 4005, Total Reward: 9\n",
      "Episode: 4006, Total Reward: -4\n",
      "Episode: 4007, Total Reward: 9\n",
      "Episode: 4008, Total Reward: 6\n",
      "Episode: 4009, Total Reward: 10\n",
      "Episode: 4010, Total Reward: 7\n",
      "Episode: 4011, Total Reward: 10\n",
      "Episode: 4012, Total Reward: 10\n",
      "Episode: 4013, Total Reward: 4\n",
      "Episode: 4014, Total Reward: 8\n",
      "Episode: 4015, Total Reward: 10\n",
      "Episode: 4016, Total Reward: 13\n",
      "Episode: 4017, Total Reward: 11\n",
      "Episode: 4018, Total Reward: 9\n",
      "Episode: 4019, Total Reward: -3\n",
      "Episode: 4020, Total Reward: 6\n",
      "Episode: 4021, Total Reward: 12\n",
      "Episode: 4022, Total Reward: 12\n",
      "Episode: 4023, Total Reward: 9\n",
      "Episode: 4024, Total Reward: 7\n",
      "Episode: 4025, Total Reward: 8\n",
      "Episode: 4026, Total Reward: 7\n",
      "Episode: 4027, Total Reward: 11\n",
      "Episode: 4028, Total Reward: 10\n",
      "Episode: 4029, Total Reward: 8\n",
      "Episode: 4030, Total Reward: 8\n",
      "Episode: 4031, Total Reward: 5\n",
      "Episode: 4032, Total Reward: 7\n",
      "Episode: 4033, Total Reward: 5\n",
      "Episode: 4034, Total Reward: 7\n",
      "Episode: 4035, Total Reward: 7\n",
      "Episode: 4036, Total Reward: 11\n",
      "Episode: 4037, Total Reward: 8\n",
      "Episode: 4038, Total Reward: 9\n",
      "Episode: 4039, Total Reward: 7\n",
      "Episode: 4040, Total Reward: 10\n",
      "Episode: 4041, Total Reward: 6\n",
      "Episode: 4042, Total Reward: 6\n",
      "Episode: 4043, Total Reward: 7\n",
      "Episode: 4044, Total Reward: 5\n",
      "Episode: 4045, Total Reward: 6\n",
      "Episode: 4046, Total Reward: 10\n",
      "Episode: 4047, Total Reward: 3\n",
      "Episode: 4048, Total Reward: 7\n",
      "Episode: 4049, Total Reward: 5\n",
      "Episode: 4050, Total Reward: 4\n",
      "Episode: 4051, Total Reward: 9\n",
      "Episode: 4052, Total Reward: 7\n",
      "Episode: 4053, Total Reward: 8\n",
      "Episode: 4054, Total Reward: 7\n",
      "Episode: 4055, Total Reward: 11\n",
      "Episode: 4056, Total Reward: 12\n",
      "Episode: 4057, Total Reward: 7\n",
      "Episode: 4058, Total Reward: 9\n",
      "Episode: 4059, Total Reward: 10\n",
      "Episode: 4060, Total Reward: 6\n",
      "Episode: 4061, Total Reward: 10\n",
      "Episode: 4062, Total Reward: 14\n",
      "Episode: 4063, Total Reward: 9\n",
      "Episode: 4064, Total Reward: 7\n",
      "Episode: 4065, Total Reward: 8\n",
      "Episode: 4066, Total Reward: 3\n",
      "Episode: 4067, Total Reward: 10\n",
      "Episode: 4068, Total Reward: 6\n",
      "Episode: 4069, Total Reward: 6\n",
      "Episode: 4070, Total Reward: 10\n",
      "Episode: 4071, Total Reward: 9\n",
      "Episode: 4072, Total Reward: 7\n",
      "Episode: 4073, Total Reward: 7\n",
      "Episode: 4074, Total Reward: 8\n",
      "Episode: 4075, Total Reward: 9\n",
      "Episode: 4076, Total Reward: 11\n",
      "Episode: 4077, Total Reward: 3\n",
      "Episode: 4078, Total Reward: 6\n",
      "Episode: 4079, Total Reward: 11\n",
      "Episode: 4080, Total Reward: 5\n",
      "Episode: 4081, Total Reward: 10\n",
      "Episode: 4082, Total Reward: 4\n",
      "Episode: 4083, Total Reward: 5\n",
      "Episode: 4084, Total Reward: 10\n",
      "Episode: 4085, Total Reward: 9\n",
      "Episode: 4086, Total Reward: 7\n",
      "Episode: 4087, Total Reward: 14\n",
      "Episode: 4088, Total Reward: 6\n",
      "Episode: 4089, Total Reward: 7\n",
      "Episode: 4090, Total Reward: 8\n",
      "Episode: 4091, Total Reward: 8\n",
      "Episode: 4092, Total Reward: 9\n",
      "Episode: 4093, Total Reward: 11\n",
      "Episode: 4094, Total Reward: 6\n",
      "Episode: 4095, Total Reward: 9\n",
      "Episode: 4096, Total Reward: 10\n",
      "Episode: 4097, Total Reward: 11\n",
      "Episode: 4098, Total Reward: 7\n",
      "Episode: 4099, Total Reward: 9\n",
      "Episode: 4100, Total Reward: 7\n",
      "Episode: 4101, Total Reward: 7\n",
      "Episode: 4102, Total Reward: 7\n",
      "Episode: 4103, Total Reward: -2\n",
      "Episode: 4104, Total Reward: 10\n",
      "Episode: 4105, Total Reward: 5\n",
      "Episode: 4106, Total Reward: 9\n",
      "Episode: 4107, Total Reward: 7\n",
      "Episode: 4108, Total Reward: 10\n",
      "Episode: 4109, Total Reward: 10\n",
      "Episode: 4110, Total Reward: 5\n",
      "Episode: 4111, Total Reward: 10\n",
      "Episode: 4112, Total Reward: 6\n",
      "Episode: 4113, Total Reward: 6\n",
      "Episode: 4114, Total Reward: 8\n",
      "Episode: 4115, Total Reward: 9\n",
      "Episode: 4116, Total Reward: 6\n",
      "Episode: 4117, Total Reward: 3\n",
      "Episode: 4118, Total Reward: 8\n",
      "Episode: 4119, Total Reward: 10\n",
      "Episode: 4120, Total Reward: 12\n",
      "Episode: 4121, Total Reward: 5\n",
      "Episode: 4122, Total Reward: 6\n",
      "Episode: 4123, Total Reward: 11\n",
      "Episode: 4124, Total Reward: 9\n",
      "Episode: 4125, Total Reward: 13\n",
      "Episode: 4126, Total Reward: 6\n",
      "Episode: 4127, Total Reward: 8\n",
      "Episode: 4128, Total Reward: 4\n",
      "Episode: 4129, Total Reward: 8\n",
      "Episode: 4130, Total Reward: 8\n",
      "Episode: 4131, Total Reward: 6\n",
      "Episode: 4132, Total Reward: 5\n",
      "Episode: 4133, Total Reward: 9\n",
      "Episode: 4134, Total Reward: 11\n",
      "Episode: 4135, Total Reward: 5\n",
      "Episode: 4136, Total Reward: 10\n",
      "Episode: 4137, Total Reward: 5\n",
      "Episode: 4138, Total Reward: 10\n",
      "Episode: 4139, Total Reward: 10\n",
      "Episode: 4140, Total Reward: -7\n",
      "Episode: 4141, Total Reward: 11\n",
      "Episode: 4142, Total Reward: 13\n",
      "Episode: 4143, Total Reward: 7\n",
      "Episode: 4144, Total Reward: 7\n",
      "Episode: 4145, Total Reward: 12\n",
      "Episode: 4146, Total Reward: 1\n",
      "Episode: 4147, Total Reward: 8\n",
      "Episode: 4148, Total Reward: 7\n",
      "Episode: 4149, Total Reward: 4\n",
      "Episode: 4150, Total Reward: 8\n",
      "Episode: 4151, Total Reward: 10\n",
      "Episode: 4152, Total Reward: 7\n",
      "Episode: 4153, Total Reward: 7\n",
      "Episode: 4154, Total Reward: 11\n",
      "Episode: 4155, Total Reward: 7\n",
      "Episode: 4156, Total Reward: 7\n",
      "Episode: 4157, Total Reward: 8\n",
      "Episode: 4158, Total Reward: 5\n",
      "Episode: 4159, Total Reward: 14\n",
      "Episode: 4160, Total Reward: -2\n",
      "Episode: 4161, Total Reward: 10\n",
      "Episode: 4162, Total Reward: 7\n",
      "Episode: 4163, Total Reward: 5\n",
      "Episode: 4164, Total Reward: 9\n",
      "Episode: 4165, Total Reward: 9\n",
      "Episode: 4166, Total Reward: 7\n",
      "Episode: 4167, Total Reward: 4\n",
      "Episode: 4168, Total Reward: 8\n",
      "Episode: 4169, Total Reward: 7\n",
      "Episode: 4170, Total Reward: 9\n",
      "Episode: 4171, Total Reward: 6\n",
      "Episode: 4172, Total Reward: 7\n",
      "Episode: 4173, Total Reward: 6\n",
      "Episode: 4174, Total Reward: 13\n",
      "Episode: 4175, Total Reward: 7\n",
      "Episode: 4176, Total Reward: -3\n",
      "Episode: 4177, Total Reward: 11\n",
      "Episode: 4178, Total Reward: 12\n",
      "Episode: 4179, Total Reward: 5\n",
      "Episode: 4180, Total Reward: 8\n",
      "Episode: 4181, Total Reward: 8\n",
      "Episode: 4182, Total Reward: 9\n",
      "Episode: 4183, Total Reward: 6\n",
      "Episode: 4184, Total Reward: 5\n",
      "Episode: 4185, Total Reward: 8\n",
      "Episode: 4186, Total Reward: 2\n",
      "Episode: 4187, Total Reward: 10\n",
      "Episode: 4188, Total Reward: 11\n",
      "Episode: 4189, Total Reward: 7\n",
      "Episode: 4190, Total Reward: 9\n",
      "Episode: 4191, Total Reward: 9\n",
      "Episode: 4192, Total Reward: 7\n",
      "Episode: 4193, Total Reward: 7\n",
      "Episode: 4194, Total Reward: 7\n",
      "Episode: 4195, Total Reward: 11\n",
      "Episode: 4196, Total Reward: 13\n",
      "Episode: 4197, Total Reward: 6\n",
      "Episode: 4198, Total Reward: 6\n",
      "Episode: 4199, Total Reward: 5\n",
      "Episode: 4200, Total Reward: 4\n",
      "Episode: 4201, Total Reward: 8\n",
      "Episode: 4202, Total Reward: 5\n",
      "Episode: 4203, Total Reward: 4\n",
      "Episode: 4204, Total Reward: 6\n",
      "Episode: 4205, Total Reward: 8\n",
      "Episode: 4206, Total Reward: 13\n",
      "Episode: 4207, Total Reward: 5\n",
      "Episode: 4208, Total Reward: 8\n",
      "Episode: 4209, Total Reward: 4\n",
      "Episode: 4210, Total Reward: 8\n",
      "Episode: 4211, Total Reward: 5\n",
      "Episode: 4212, Total Reward: 10\n",
      "Episode: 4213, Total Reward: 14\n",
      "Episode: 4214, Total Reward: 5\n",
      "Episode: 4215, Total Reward: 11\n",
      "Episode: 4216, Total Reward: 7\n",
      "Episode: 4217, Total Reward: 9\n",
      "Episode: 4218, Total Reward: 12\n",
      "Episode: 4219, Total Reward: 4\n",
      "Episode: 4220, Total Reward: 4\n",
      "Episode: 4221, Total Reward: 7\n",
      "Episode: 4222, Total Reward: 3\n",
      "Episode: 4223, Total Reward: 10\n",
      "Episode: 4224, Total Reward: 6\n",
      "Episode: 4225, Total Reward: 8\n",
      "Episode: 4226, Total Reward: 7\n",
      "Episode: 4227, Total Reward: 3\n",
      "Episode: 4228, Total Reward: 6\n",
      "Episode: 4229, Total Reward: 7\n",
      "Episode: 4230, Total Reward: 6\n",
      "Episode: 4231, Total Reward: 7\n",
      "Episode: 4232, Total Reward: 4\n",
      "Episode: 4233, Total Reward: 5\n",
      "Episode: 4234, Total Reward: 4\n",
      "Episode: 4235, Total Reward: 3\n",
      "Episode: 4236, Total Reward: 6\n",
      "Episode: 4237, Total Reward: 8\n",
      "Episode: 4238, Total Reward: 9\n",
      "Episode: 4239, Total Reward: 7\n",
      "Episode: 4240, Total Reward: 5\n",
      "Episode: 4241, Total Reward: 13\n",
      "Episode: 4242, Total Reward: 8\n",
      "Episode: 4243, Total Reward: 7\n",
      "Episode: 4244, Total Reward: 11\n",
      "Episode: 4245, Total Reward: 8\n",
      "Episode: 4246, Total Reward: 11\n",
      "Episode: 4247, Total Reward: 5\n",
      "Episode: 4248, Total Reward: 12\n",
      "Episode: 4249, Total Reward: 11\n",
      "Episode: 4250, Total Reward: 5\n",
      "Episode: 4251, Total Reward: 12\n",
      "Episode: 4252, Total Reward: 6\n",
      "Episode: 4253, Total Reward: 12\n",
      "Episode: 4254, Total Reward: 6\n",
      "Episode: 4255, Total Reward: 8\n",
      "Episode: 4256, Total Reward: 6\n",
      "Episode: 4257, Total Reward: 11\n",
      "Episode: 4258, Total Reward: 10\n",
      "Episode: 4259, Total Reward: 8\n",
      "Episode: 4260, Total Reward: 6\n",
      "Episode: 4261, Total Reward: 8\n",
      "Episode: 4262, Total Reward: 5\n",
      "Episode: 4263, Total Reward: 4\n",
      "Episode: 4264, Total Reward: 5\n",
      "Episode: 4265, Total Reward: 2\n",
      "Episode: 4266, Total Reward: 8\n",
      "Episode: 4267, Total Reward: 8\n",
      "Episode: 4268, Total Reward: 8\n",
      "Episode: 4269, Total Reward: 10\n",
      "Episode: 4270, Total Reward: 11\n",
      "Episode: 4271, Total Reward: 10\n",
      "Episode: 4272, Total Reward: 5\n",
      "Episode: 4273, Total Reward: 10\n",
      "Episode: 4274, Total Reward: 8\n",
      "Episode: 4275, Total Reward: 7\n",
      "Episode: 4276, Total Reward: 6\n",
      "Episode: 4277, Total Reward: 11\n",
      "Episode: 4278, Total Reward: 7\n",
      "Episode: 4279, Total Reward: 7\n",
      "Episode: 4280, Total Reward: 5\n",
      "Episode: 4281, Total Reward: 11\n",
      "Episode: 4282, Total Reward: 9\n",
      "Episode: 4283, Total Reward: 11\n",
      "Episode: 4284, Total Reward: 8\n",
      "Episode: 4285, Total Reward: 5\n",
      "Episode: 4286, Total Reward: 7\n",
      "Episode: 4287, Total Reward: -7\n",
      "Episode: 4288, Total Reward: 13\n",
      "Episode: 4289, Total Reward: 9\n",
      "Episode: 4290, Total Reward: 4\n",
      "Episode: 4291, Total Reward: 10\n",
      "Episode: 4292, Total Reward: 8\n",
      "Episode: 4293, Total Reward: 3\n",
      "Episode: 4294, Total Reward: 3\n",
      "Episode: 4295, Total Reward: 9\n",
      "Episode: 4296, Total Reward: 10\n",
      "Episode: 4297, Total Reward: 11\n",
      "Episode: 4298, Total Reward: 12\n",
      "Episode: 4299, Total Reward: 5\n",
      "Episode: 4300, Total Reward: 11\n",
      "Episode: 4301, Total Reward: 14\n",
      "Episode: 4302, Total Reward: 5\n",
      "Episode: 4303, Total Reward: 7\n",
      "Episode: 4304, Total Reward: 12\n",
      "Episode: 4305, Total Reward: 9\n",
      "Episode: 4306, Total Reward: 4\n",
      "Episode: 4307, Total Reward: 7\n",
      "Episode: 4308, Total Reward: 7\n",
      "Episode: 4309, Total Reward: 7\n",
      "Episode: 4310, Total Reward: 4\n",
      "Episode: 4311, Total Reward: 5\n",
      "Episode: 4312, Total Reward: 8\n",
      "Episode: 4313, Total Reward: 6\n",
      "Episode: 4314, Total Reward: 6\n",
      "Episode: 4315, Total Reward: 6\n",
      "Episode: 4316, Total Reward: 4\n",
      "Episode: 4317, Total Reward: 10\n",
      "Episode: 4318, Total Reward: 10\n",
      "Episode: 4319, Total Reward: 9\n",
      "Episode: 4320, Total Reward: 8\n",
      "Episode: 4321, Total Reward: 4\n",
      "Episode: 4322, Total Reward: 6\n",
      "Episode: 4323, Total Reward: 4\n",
      "Episode: 4324, Total Reward: 8\n",
      "Episode: 4325, Total Reward: 8\n",
      "Episode: 4326, Total Reward: 10\n",
      "Episode: 4327, Total Reward: 3\n",
      "Episode: 4328, Total Reward: 8\n",
      "Episode: 4329, Total Reward: 8\n",
      "Episode: 4330, Total Reward: 6\n",
      "Episode: 4331, Total Reward: 10\n",
      "Episode: 4332, Total Reward: 12\n",
      "Episode: 4333, Total Reward: 9\n",
      "Episode: 4334, Total Reward: 10\n",
      "Episode: 4335, Total Reward: 7\n",
      "Episode: 4336, Total Reward: 6\n",
      "Episode: 4337, Total Reward: 9\n",
      "Episode: 4338, Total Reward: 10\n",
      "Episode: 4339, Total Reward: 4\n",
      "Episode: 4340, Total Reward: 13\n",
      "Episode: 4341, Total Reward: 8\n",
      "Episode: 4342, Total Reward: 5\n",
      "Episode: 4343, Total Reward: 11\n",
      "Episode: 4344, Total Reward: 9\n",
      "Episode: 4345, Total Reward: 7\n",
      "Episode: 4346, Total Reward: 5\n",
      "Episode: 4347, Total Reward: 10\n",
      "Episode: 4348, Total Reward: 8\n",
      "Episode: 4349, Total Reward: 8\n",
      "Episode: 4350, Total Reward: 9\n",
      "Episode: 4351, Total Reward: 9\n",
      "Episode: 4352, Total Reward: 3\n",
      "Episode: 4353, Total Reward: 4\n",
      "Episode: 4354, Total Reward: 11\n",
      "Episode: 4355, Total Reward: 6\n",
      "Episode: 4356, Total Reward: 5\n",
      "Episode: 4357, Total Reward: 7\n",
      "Episode: 4358, Total Reward: 11\n",
      "Episode: 4359, Total Reward: 4\n",
      "Episode: 4360, Total Reward: 6\n",
      "Episode: 4361, Total Reward: 8\n",
      "Episode: 4362, Total Reward: 6\n",
      "Episode: 4363, Total Reward: 8\n",
      "Episode: 4364, Total Reward: 10\n",
      "Episode: 4365, Total Reward: 7\n",
      "Episode: 4366, Total Reward: 9\n",
      "Episode: 4367, Total Reward: 11\n",
      "Episode: 4368, Total Reward: 11\n",
      "Episode: 4369, Total Reward: 7\n",
      "Episode: 4370, Total Reward: 12\n",
      "Episode: 4371, Total Reward: 6\n",
      "Episode: 4372, Total Reward: 8\n",
      "Episode: 4373, Total Reward: 6\n",
      "Episode: 4374, Total Reward: 12\n",
      "Episode: 4375, Total Reward: 9\n",
      "Episode: 4376, Total Reward: 6\n",
      "Episode: 4377, Total Reward: 10\n",
      "Episode: 4378, Total Reward: 7\n",
      "Episode: 4379, Total Reward: 4\n",
      "Episode: 4380, Total Reward: 6\n",
      "Episode: 4381, Total Reward: 11\n",
      "Episode: 4382, Total Reward: 14\n",
      "Episode: 4383, Total Reward: 6\n",
      "Episode: 4384, Total Reward: 11\n",
      "Episode: 4385, Total Reward: 5\n",
      "Episode: 4386, Total Reward: 6\n",
      "Episode: 4387, Total Reward: 7\n",
      "Episode: 4388, Total Reward: 13\n",
      "Episode: 4389, Total Reward: 5\n",
      "Episode: 4390, Total Reward: 6\n",
      "Episode: 4391, Total Reward: 9\n",
      "Episode: 4392, Total Reward: 8\n",
      "Episode: 4393, Total Reward: 8\n",
      "Episode: 4394, Total Reward: 10\n",
      "Episode: 4395, Total Reward: 7\n",
      "Episode: 4396, Total Reward: 9\n",
      "Episode: 4397, Total Reward: 8\n",
      "Episode: 4398, Total Reward: 6\n",
      "Episode: 4399, Total Reward: 10\n",
      "Episode: 4400, Total Reward: 10\n",
      "Episode: 4401, Total Reward: 9\n",
      "Episode: 4402, Total Reward: 3\n",
      "Episode: 4403, Total Reward: 6\n",
      "Episode: 4404, Total Reward: 8\n",
      "Episode: 4405, Total Reward: 6\n",
      "Episode: 4406, Total Reward: 9\n",
      "Episode: 4407, Total Reward: 9\n",
      "Episode: 4408, Total Reward: 4\n",
      "Episode: 4409, Total Reward: 7\n",
      "Episode: 4410, Total Reward: 8\n",
      "Episode: 4411, Total Reward: 7\n",
      "Episode: 4412, Total Reward: 3\n",
      "Episode: 4413, Total Reward: 3\n",
      "Episode: 4414, Total Reward: 9\n",
      "Episode: 4415, Total Reward: 5\n",
      "Episode: 4416, Total Reward: 8\n",
      "Episode: 4417, Total Reward: 8\n",
      "Episode: 4418, Total Reward: 6\n",
      "Episode: 4419, Total Reward: 13\n",
      "Episode: 4420, Total Reward: 11\n",
      "Episode: 4421, Total Reward: 5\n",
      "Episode: 4422, Total Reward: 9\n",
      "Episode: 4423, Total Reward: 6\n",
      "Episode: 4424, Total Reward: 9\n",
      "Episode: 4425, Total Reward: 8\n",
      "Episode: 4426, Total Reward: -6\n",
      "Episode: 4427, Total Reward: 9\n",
      "Episode: 4428, Total Reward: 11\n",
      "Episode: 4429, Total Reward: 6\n",
      "Episode: 4430, Total Reward: 5\n",
      "Episode: 4431, Total Reward: 9\n",
      "Episode: 4432, Total Reward: 7\n",
      "Episode: 4433, Total Reward: 6\n",
      "Episode: 4434, Total Reward: 3\n",
      "Episode: 4435, Total Reward: 8\n",
      "Episode: 4436, Total Reward: 5\n",
      "Episode: 4437, Total Reward: 13\n",
      "Episode: 4438, Total Reward: 10\n",
      "Episode: 4439, Total Reward: 5\n",
      "Episode: 4440, Total Reward: 7\n",
      "Episode: 4441, Total Reward: 13\n",
      "Episode: 4442, Total Reward: 6\n",
      "Episode: 4443, Total Reward: 7\n",
      "Episode: 4444, Total Reward: 10\n",
      "Episode: 4445, Total Reward: 3\n",
      "Episode: 4446, Total Reward: 7\n",
      "Episode: 4447, Total Reward: 5\n",
      "Episode: 4448, Total Reward: 8\n",
      "Episode: 4449, Total Reward: 6\n",
      "Episode: 4450, Total Reward: 6\n",
      "Episode: 4451, Total Reward: 14\n",
      "Episode: 4452, Total Reward: 2\n",
      "Episode: 4453, Total Reward: 8\n",
      "Episode: 4454, Total Reward: 10\n",
      "Episode: 4455, Total Reward: 12\n",
      "Episode: 4456, Total Reward: 8\n",
      "Episode: 4457, Total Reward: 6\n",
      "Episode: 4458, Total Reward: 8\n",
      "Episode: 4459, Total Reward: 4\n",
      "Episode: 4460, Total Reward: 6\n",
      "Episode: 4461, Total Reward: 8\n",
      "Episode: 4462, Total Reward: 10\n",
      "Episode: 4463, Total Reward: 11\n",
      "Episode: 4464, Total Reward: 8\n",
      "Episode: 4465, Total Reward: 11\n",
      "Episode: 4466, Total Reward: 2\n",
      "Episode: 4467, Total Reward: 5\n",
      "Episode: 4468, Total Reward: 11\n",
      "Episode: 4469, Total Reward: 9\n",
      "Episode: 4470, Total Reward: 8\n",
      "Episode: 4471, Total Reward: 8\n",
      "Episode: 4472, Total Reward: 4\n",
      "Episode: 4473, Total Reward: -4\n",
      "Episode: 4474, Total Reward: 10\n",
      "Episode: 4475, Total Reward: 8\n",
      "Episode: 4476, Total Reward: 5\n",
      "Episode: 4477, Total Reward: 10\n",
      "Episode: 4478, Total Reward: 3\n",
      "Episode: 4479, Total Reward: 9\n",
      "Episode: 4480, Total Reward: 5\n",
      "Episode: 4481, Total Reward: 8\n",
      "Episode: 4482, Total Reward: 8\n",
      "Episode: 4483, Total Reward: 7\n",
      "Episode: 4484, Total Reward: 5\n",
      "Episode: 4485, Total Reward: 6\n",
      "Episode: 4486, Total Reward: 7\n",
      "Episode: 4487, Total Reward: 4\n",
      "Episode: 4488, Total Reward: 9\n",
      "Episode: 4489, Total Reward: 13\n",
      "Episode: 4490, Total Reward: 8\n",
      "Episode: 4491, Total Reward: 11\n",
      "Episode: 4492, Total Reward: 7\n",
      "Episode: 4493, Total Reward: 8\n",
      "Episode: 4494, Total Reward: 7\n",
      "Episode: 4495, Total Reward: 10\n",
      "Episode: 4496, Total Reward: 6\n",
      "Episode: 4497, Total Reward: 7\n",
      "Episode: 4498, Total Reward: 8\n",
      "Episode: 4499, Total Reward: 4\n",
      "Episode: 4500, Total Reward: 7\n",
      "Episode: 4501, Total Reward: 11\n",
      "Episode: 4502, Total Reward: 13\n",
      "Episode: 4503, Total Reward: 8\n",
      "Episode: 4504, Total Reward: 9\n",
      "Episode: 4505, Total Reward: 11\n",
      "Episode: 4506, Total Reward: 14\n",
      "Episode: 4507, Total Reward: 9\n",
      "Episode: 4508, Total Reward: 8\n",
      "Episode: 4509, Total Reward: 5\n",
      "Episode: 4510, Total Reward: 7\n",
      "Episode: 4511, Total Reward: 8\n",
      "Episode: 4512, Total Reward: 7\n",
      "Episode: 4513, Total Reward: 4\n",
      "Episode: 4514, Total Reward: 6\n",
      "Episode: 4515, Total Reward: 5\n",
      "Episode: 4516, Total Reward: 9\n",
      "Episode: 4517, Total Reward: 11\n",
      "Episode: 4518, Total Reward: 4\n",
      "Episode: 4519, Total Reward: 8\n",
      "Episode: 4520, Total Reward: 10\n",
      "Episode: 4521, Total Reward: 5\n",
      "Episode: 4522, Total Reward: 6\n",
      "Episode: 4523, Total Reward: 15\n",
      "Episode: 4524, Total Reward: 12\n",
      "Episode: 4525, Total Reward: 5\n",
      "Episode: 4526, Total Reward: 8\n",
      "Episode: 4527, Total Reward: 11\n",
      "Episode: 4528, Total Reward: 7\n",
      "Episode: 4529, Total Reward: 0\n",
      "Episode: 4530, Total Reward: 10\n",
      "Episode: 4531, Total Reward: 8\n",
      "Episode: 4532, Total Reward: 7\n",
      "Episode: 4533, Total Reward: 2\n",
      "Episode: 4534, Total Reward: 10\n",
      "Episode: 4535, Total Reward: 11\n",
      "Episode: 4536, Total Reward: 8\n",
      "Episode: 4537, Total Reward: 9\n",
      "Episode: 4538, Total Reward: 11\n",
      "Episode: 4539, Total Reward: 3\n",
      "Episode: 4540, Total Reward: 7\n",
      "Episode: 4541, Total Reward: 4\n",
      "Episode: 4542, Total Reward: 10\n",
      "Episode: 4543, Total Reward: 5\n",
      "Episode: 4544, Total Reward: 12\n",
      "Episode: 4545, Total Reward: 4\n",
      "Episode: 4546, Total Reward: 9\n",
      "Episode: 4547, Total Reward: 2\n",
      "Episode: 4548, Total Reward: 6\n",
      "Episode: 4549, Total Reward: 10\n",
      "Episode: 4550, Total Reward: 3\n",
      "Episode: 4551, Total Reward: 9\n",
      "Episode: 4552, Total Reward: 13\n",
      "Episode: 4553, Total Reward: 7\n",
      "Episode: 4554, Total Reward: 7\n",
      "Episode: 4555, Total Reward: 9\n",
      "Episode: 4556, Total Reward: 9\n",
      "Episode: 4557, Total Reward: 8\n",
      "Episode: 4558, Total Reward: 7\n",
      "Episode: 4559, Total Reward: 6\n",
      "Episode: 4560, Total Reward: 6\n",
      "Episode: 4561, Total Reward: 9\n",
      "Episode: 4562, Total Reward: 6\n",
      "Episode: 4563, Total Reward: 7\n",
      "Episode: 4564, Total Reward: 5\n",
      "Episode: 4565, Total Reward: 11\n",
      "Episode: 4566, Total Reward: 5\n",
      "Episode: 4567, Total Reward: 9\n",
      "Episode: 4568, Total Reward: 10\n",
      "Episode: 4569, Total Reward: 10\n",
      "Episode: 4570, Total Reward: 8\n",
      "Episode: 4571, Total Reward: 8\n",
      "Episode: 4572, Total Reward: 5\n",
      "Episode: 4573, Total Reward: 9\n",
      "Episode: 4574, Total Reward: 10\n",
      "Episode: 4575, Total Reward: 10\n",
      "Episode: 4576, Total Reward: 8\n",
      "Episode: 4577, Total Reward: 7\n",
      "Episode: 4578, Total Reward: 11\n",
      "Episode: 4579, Total Reward: 8\n",
      "Episode: 4580, Total Reward: 7\n",
      "Episode: 4581, Total Reward: 3\n",
      "Episode: 4582, Total Reward: 14\n",
      "Episode: 4583, Total Reward: 5\n",
      "Episode: 4584, Total Reward: 8\n",
      "Episode: 4585, Total Reward: 10\n",
      "Episode: 4586, Total Reward: 5\n",
      "Episode: 4587, Total Reward: 8\n",
      "Episode: 4588, Total Reward: 9\n",
      "Episode: 4589, Total Reward: 7\n",
      "Episode: 4590, Total Reward: 5\n",
      "Episode: 4591, Total Reward: 13\n",
      "Episode: 4592, Total Reward: 8\n",
      "Episode: 4593, Total Reward: 8\n",
      "Episode: 4594, Total Reward: 7\n",
      "Episode: 4595, Total Reward: 12\n",
      "Episode: 4596, Total Reward: 9\n",
      "Episode: 4597, Total Reward: 5\n",
      "Episode: 4598, Total Reward: 6\n",
      "Episode: 4599, Total Reward: 8\n",
      "Episode: 4600, Total Reward: 10\n",
      "Episode: 4601, Total Reward: 12\n",
      "Episode: 4602, Total Reward: 14\n",
      "Episode: 4603, Total Reward: 10\n",
      "Episode: 4604, Total Reward: 6\n",
      "Episode: 4605, Total Reward: 9\n",
      "Episode: 4606, Total Reward: 11\n",
      "Episode: 4607, Total Reward: 10\n",
      "Episode: 4608, Total Reward: 7\n",
      "Episode: 4609, Total Reward: -2\n",
      "Episode: 4610, Total Reward: 9\n",
      "Episode: 4611, Total Reward: 10\n",
      "Episode: 4612, Total Reward: 10\n",
      "Episode: 4613, Total Reward: 7\n",
      "Episode: 4614, Total Reward: 6\n",
      "Episode: 4615, Total Reward: 9\n",
      "Episode: 4616, Total Reward: 12\n",
      "Episode: 4617, Total Reward: 9\n",
      "Episode: 4618, Total Reward: 9\n",
      "Episode: 4619, Total Reward: 7\n",
      "Episode: 4620, Total Reward: 5\n",
      "Episode: 4621, Total Reward: 11\n",
      "Episode: 4622, Total Reward: 5\n",
      "Episode: 4623, Total Reward: 11\n",
      "Episode: 4624, Total Reward: 8\n",
      "Episode: 4625, Total Reward: 7\n",
      "Episode: 4626, Total Reward: 5\n",
      "Episode: 4627, Total Reward: 10\n",
      "Episode: 4628, Total Reward: 5\n",
      "Episode: 4629, Total Reward: 3\n",
      "Episode: 4630, Total Reward: 3\n",
      "Episode: 4631, Total Reward: 10\n",
      "Episode: 4632, Total Reward: 7\n",
      "Episode: 4633, Total Reward: 9\n",
      "Episode: 4634, Total Reward: 6\n",
      "Episode: 4635, Total Reward: 10\n",
      "Episode: 4636, Total Reward: 12\n",
      "Episode: 4637, Total Reward: 9\n",
      "Episode: 4638, Total Reward: 12\n",
      "Episode: 4639, Total Reward: 8\n",
      "Episode: 4640, Total Reward: 11\n",
      "Episode: 4641, Total Reward: 12\n",
      "Episode: 4642, Total Reward: 12\n",
      "Episode: 4643, Total Reward: 7\n",
      "Episode: 4644, Total Reward: 14\n",
      "Episode: 4645, Total Reward: 9\n",
      "Episode: 4646, Total Reward: 9\n",
      "Episode: 4647, Total Reward: 8\n",
      "Episode: 4648, Total Reward: 5\n",
      "Episode: 4649, Total Reward: 7\n",
      "Episode: 4650, Total Reward: 8\n",
      "Episode: 4651, Total Reward: 8\n",
      "Episode: 4652, Total Reward: 9\n",
      "Episode: 4653, Total Reward: 6\n",
      "Episode: 4654, Total Reward: 9\n",
      "Episode: 4655, Total Reward: 9\n",
      "Episode: 4656, Total Reward: 8\n",
      "Episode: 4657, Total Reward: 10\n",
      "Episode: 4658, Total Reward: 9\n",
      "Episode: 4659, Total Reward: 11\n",
      "Episode: 4660, Total Reward: 5\n",
      "Episode: 4661, Total Reward: 12\n",
      "Episode: 4662, Total Reward: 10\n",
      "Episode: 4663, Total Reward: 11\n",
      "Episode: 4664, Total Reward: 9\n",
      "Episode: 4665, Total Reward: 12\n",
      "Episode: 4666, Total Reward: 11\n",
      "Episode: 4667, Total Reward: 8\n",
      "Episode: 4668, Total Reward: 8\n",
      "Episode: 4669, Total Reward: 7\n",
      "Episode: 4670, Total Reward: 8\n",
      "Episode: 4671, Total Reward: 8\n",
      "Episode: 4672, Total Reward: 4\n",
      "Episode: 4673, Total Reward: 12\n",
      "Episode: 4674, Total Reward: 2\n",
      "Episode: 4675, Total Reward: 11\n",
      "Episode: 4676, Total Reward: 6\n",
      "Episode: 4677, Total Reward: 15\n",
      "Episode: 4678, Total Reward: 6\n",
      "Episode: 4679, Total Reward: 7\n",
      "Episode: 4680, Total Reward: 9\n",
      "Episode: 4681, Total Reward: 12\n",
      "Episode: 4682, Total Reward: 8\n",
      "Episode: 4683, Total Reward: 6\n",
      "Episode: 4684, Total Reward: 8\n",
      "Episode: 4685, Total Reward: 12\n",
      "Episode: 4686, Total Reward: 10\n",
      "Episode: 4687, Total Reward: 7\n",
      "Episode: 4688, Total Reward: 6\n",
      "Episode: 4689, Total Reward: 8\n",
      "Episode: 4690, Total Reward: 9\n",
      "Episode: 4691, Total Reward: 9\n",
      "Episode: 4692, Total Reward: 3\n",
      "Episode: 4693, Total Reward: 6\n",
      "Episode: 4694, Total Reward: 5\n",
      "Episode: 4695, Total Reward: 10\n",
      "Episode: 4696, Total Reward: 8\n",
      "Episode: 4697, Total Reward: 8\n",
      "Episode: 4698, Total Reward: 10\n",
      "Episode: 4699, Total Reward: 9\n",
      "Episode: 4700, Total Reward: 9\n",
      "Episode: 4701, Total Reward: 8\n",
      "Episode: 4702, Total Reward: 10\n",
      "Episode: 4703, Total Reward: 8\n",
      "Episode: 4704, Total Reward: 14\n",
      "Episode: 4705, Total Reward: 9\n",
      "Episode: 4706, Total Reward: 7\n",
      "Episode: 4707, Total Reward: 10\n",
      "Episode: 4708, Total Reward: 10\n",
      "Episode: 4709, Total Reward: 5\n",
      "Episode: 4710, Total Reward: 5\n",
      "Episode: 4711, Total Reward: 9\n",
      "Episode: 4712, Total Reward: 3\n",
      "Episode: 4713, Total Reward: 14\n",
      "Episode: 4714, Total Reward: 6\n",
      "Episode: 4715, Total Reward: -7\n",
      "Episode: 4716, Total Reward: 6\n",
      "Episode: 4717, Total Reward: 13\n",
      "Episode: 4718, Total Reward: 9\n",
      "Episode: 4719, Total Reward: 11\n",
      "Episode: 4720, Total Reward: 14\n",
      "Episode: 4721, Total Reward: 10\n",
      "Episode: 4722, Total Reward: 8\n",
      "Episode: 4723, Total Reward: 11\n",
      "Episode: 4724, Total Reward: 10\n",
      "Episode: 4725, Total Reward: 9\n",
      "Episode: 4726, Total Reward: 8\n",
      "Episode: 4727, Total Reward: 11\n",
      "Episode: 4728, Total Reward: 11\n",
      "Episode: 4729, Total Reward: 8\n",
      "Episode: 4730, Total Reward: 7\n",
      "Episode: 4731, Total Reward: 9\n",
      "Episode: 4732, Total Reward: 10\n",
      "Episode: 4733, Total Reward: 8\n",
      "Episode: 4734, Total Reward: 4\n",
      "Episode: 4735, Total Reward: 10\n",
      "Episode: 4736, Total Reward: -2\n",
      "Episode: 4737, Total Reward: 4\n",
      "Episode: 4738, Total Reward: 7\n",
      "Episode: 4739, Total Reward: 9\n",
      "Episode: 4740, Total Reward: 7\n",
      "Episode: 4741, Total Reward: 7\n",
      "Episode: 4742, Total Reward: 8\n",
      "Episode: 4743, Total Reward: 7\n",
      "Episode: 4744, Total Reward: 9\n",
      "Episode: 4745, Total Reward: 8\n",
      "Episode: 4746, Total Reward: 6\n",
      "Episode: 4747, Total Reward: 4\n",
      "Episode: 4748, Total Reward: 9\n",
      "Episode: 4749, Total Reward: 7\n",
      "Episode: 4750, Total Reward: 6\n",
      "Episode: 4751, Total Reward: 7\n",
      "Episode: 4752, Total Reward: 10\n",
      "Episode: 4753, Total Reward: 8\n",
      "Episode: 4754, Total Reward: 8\n",
      "Episode: 4755, Total Reward: 8\n",
      "Episode: 4756, Total Reward: 11\n",
      "Episode: 4757, Total Reward: 9\n",
      "Episode: 4758, Total Reward: 7\n",
      "Episode: 4759, Total Reward: 6\n",
      "Episode: 4760, Total Reward: 10\n",
      "Episode: 4761, Total Reward: 9\n",
      "Episode: 4762, Total Reward: 4\n",
      "Episode: 4763, Total Reward: 10\n",
      "Episode: 4764, Total Reward: 8\n",
      "Episode: 4765, Total Reward: 8\n",
      "Episode: 4766, Total Reward: 11\n",
      "Episode: 4767, Total Reward: 10\n",
      "Episode: 4768, Total Reward: 6\n",
      "Episode: 4769, Total Reward: 10\n",
      "Episode: 4770, Total Reward: 10\n",
      "Episode: 4771, Total Reward: 6\n",
      "Episode: 4772, Total Reward: 6\n",
      "Episode: 4773, Total Reward: 9\n",
      "Episode: 4774, Total Reward: 4\n",
      "Episode: 4775, Total Reward: 0\n",
      "Episode: 4776, Total Reward: 6\n",
      "Episode: 4777, Total Reward: 3\n",
      "Episode: 4778, Total Reward: 6\n",
      "Episode: 4779, Total Reward: 8\n",
      "Episode: 4780, Total Reward: 10\n",
      "Episode: 4781, Total Reward: 9\n",
      "Episode: 4782, Total Reward: 3\n",
      "Episode: 4783, Total Reward: -6\n",
      "Episode: 4784, Total Reward: 11\n",
      "Episode: 4785, Total Reward: 5\n",
      "Episode: 4786, Total Reward: 4\n",
      "Episode: 4787, Total Reward: 8\n",
      "Episode: 4788, Total Reward: 9\n",
      "Episode: 4789, Total Reward: 4\n",
      "Episode: 4790, Total Reward: 4\n",
      "Episode: 4791, Total Reward: 7\n",
      "Episode: 4792, Total Reward: 4\n",
      "Episode: 4793, Total Reward: 1\n",
      "Episode: 4794, Total Reward: 9\n",
      "Episode: 4795, Total Reward: 15\n",
      "Episode: 4796, Total Reward: 7\n",
      "Episode: 4797, Total Reward: 8\n",
      "Episode: 4798, Total Reward: 7\n",
      "Episode: 4799, Total Reward: 10\n",
      "Episode: 4800, Total Reward: 8\n",
      "Episode: 4801, Total Reward: 3\n",
      "Episode: 4802, Total Reward: 5\n",
      "Episode: 4803, Total Reward: 13\n",
      "Episode: 4804, Total Reward: 10\n",
      "Episode: 4805, Total Reward: 9\n",
      "Episode: 4806, Total Reward: 10\n",
      "Episode: 4807, Total Reward: 7\n",
      "Episode: 4808, Total Reward: 10\n",
      "Episode: 4809, Total Reward: 13\n",
      "Episode: 4810, Total Reward: 5\n",
      "Episode: 4811, Total Reward: 8\n",
      "Episode: 4812, Total Reward: 7\n",
      "Episode: 4813, Total Reward: 9\n",
      "Episode: 4814, Total Reward: 11\n",
      "Episode: 4815, Total Reward: 11\n",
      "Episode: 4816, Total Reward: 9\n",
      "Episode: 4817, Total Reward: 6\n",
      "Episode: 4818, Total Reward: 10\n",
      "Episode: 4819, Total Reward: 8\n",
      "Episode: 4820, Total Reward: 5\n",
      "Episode: 4821, Total Reward: 8\n",
      "Episode: 4822, Total Reward: 9\n",
      "Episode: 4823, Total Reward: 8\n",
      "Episode: 4824, Total Reward: 9\n",
      "Episode: 4825, Total Reward: 6\n",
      "Episode: 4826, Total Reward: 5\n",
      "Episode: 4827, Total Reward: 10\n",
      "Episode: 4828, Total Reward: 8\n",
      "Episode: 4829, Total Reward: 3\n",
      "Episode: 4830, Total Reward: 3\n",
      "Episode: 4831, Total Reward: 5\n",
      "Episode: 4832, Total Reward: -6\n",
      "Episode: 4833, Total Reward: 8\n",
      "Episode: 4834, Total Reward: 7\n",
      "Episode: 4835, Total Reward: 10\n",
      "Episode: 4836, Total Reward: 9\n",
      "Episode: 4837, Total Reward: 8\n",
      "Episode: 4838, Total Reward: 3\n",
      "Episode: 4839, Total Reward: 9\n",
      "Episode: 4840, Total Reward: 10\n",
      "Episode: 4841, Total Reward: 6\n",
      "Episode: 4842, Total Reward: 9\n",
      "Episode: 4843, Total Reward: 13\n",
      "Episode: 4844, Total Reward: -1\n",
      "Episode: 4845, Total Reward: 11\n",
      "Episode: 4846, Total Reward: 8\n",
      "Episode: 4847, Total Reward: 9\n",
      "Episode: 4848, Total Reward: 10\n",
      "Episode: 4849, Total Reward: -2\n",
      "Episode: 4850, Total Reward: 10\n",
      "Episode: 4851, Total Reward: 5\n",
      "Episode: 4852, Total Reward: 10\n",
      "Episode: 4853, Total Reward: 12\n",
      "Episode: 4854, Total Reward: 5\n",
      "Episode: 4855, Total Reward: 12\n",
      "Episode: 4856, Total Reward: -2\n",
      "Episode: 4857, Total Reward: 6\n",
      "Episode: 4858, Total Reward: 8\n",
      "Episode: 4859, Total Reward: 7\n",
      "Episode: 4860, Total Reward: 7\n",
      "Episode: 4861, Total Reward: 8\n",
      "Episode: 4862, Total Reward: 9\n",
      "Episode: 4863, Total Reward: 9\n",
      "Episode: 4864, Total Reward: 8\n",
      "Episode: 4865, Total Reward: 4\n",
      "Episode: 4866, Total Reward: 5\n",
      "Episode: 4867, Total Reward: 3\n",
      "Episode: 4868, Total Reward: 10\n",
      "Episode: 4869, Total Reward: 14\n",
      "Episode: 4870, Total Reward: 8\n",
      "Episode: 4871, Total Reward: 9\n",
      "Episode: 4872, Total Reward: 9\n",
      "Episode: 4873, Total Reward: 5\n",
      "Episode: 4874, Total Reward: 10\n",
      "Episode: 4875, Total Reward: 4\n",
      "Episode: 4876, Total Reward: 13\n",
      "Episode: 4877, Total Reward: 11\n",
      "Episode: 4878, Total Reward: 5\n",
      "Episode: 4879, Total Reward: 6\n",
      "Episode: 4880, Total Reward: 9\n",
      "Episode: 4881, Total Reward: -6\n",
      "Episode: 4882, Total Reward: 10\n",
      "Episode: 4883, Total Reward: 6\n",
      "Episode: 4884, Total Reward: 13\n",
      "Episode: 4885, Total Reward: 5\n",
      "Episode: 4886, Total Reward: 11\n",
      "Episode: 4887, Total Reward: 7\n",
      "Episode: 4888, Total Reward: 6\n",
      "Episode: 4889, Total Reward: 10\n",
      "Episode: 4890, Total Reward: 7\n",
      "Episode: 4891, Total Reward: 5\n",
      "Episode: 4892, Total Reward: 8\n",
      "Episode: 4893, Total Reward: 9\n",
      "Episode: 4894, Total Reward: 4\n",
      "Episode: 4895, Total Reward: 14\n",
      "Episode: 4896, Total Reward: 6\n",
      "Episode: 4897, Total Reward: 8\n",
      "Episode: 4898, Total Reward: 4\n",
      "Episode: 4899, Total Reward: 8\n",
      "Episode: 4900, Total Reward: 10\n",
      "Episode: 4901, Total Reward: 9\n",
      "Episode: 4902, Total Reward: 11\n",
      "Episode: 4903, Total Reward: 9\n",
      "Episode: 4904, Total Reward: 8\n",
      "Episode: 4905, Total Reward: 8\n",
      "Episode: 4906, Total Reward: 5\n",
      "Episode: 4907, Total Reward: -2\n",
      "Episode: 4908, Total Reward: 11\n",
      "Episode: 4909, Total Reward: 5\n",
      "Episode: 4910, Total Reward: 4\n",
      "Episode: 4911, Total Reward: 6\n",
      "Episode: 4912, Total Reward: 6\n",
      "Episode: 4913, Total Reward: 10\n",
      "Episode: 4914, Total Reward: 11\n",
      "Episode: 4915, Total Reward: 3\n",
      "Episode: 4916, Total Reward: 5\n",
      "Episode: 4917, Total Reward: 11\n",
      "Episode: 4918, Total Reward: 9\n",
      "Episode: 4919, Total Reward: 3\n",
      "Episode: 4920, Total Reward: 13\n",
      "Episode: 4921, Total Reward: 6\n",
      "Episode: 4922, Total Reward: 4\n",
      "Episode: 4923, Total Reward: 12\n",
      "Episode: 4924, Total Reward: 9\n",
      "Episode: 4925, Total Reward: 10\n",
      "Episode: 4926, Total Reward: 9\n",
      "Episode: 4927, Total Reward: 9\n",
      "Episode: 4928, Total Reward: 7\n",
      "Episode: 4929, Total Reward: 9\n",
      "Episode: 4930, Total Reward: 10\n",
      "Episode: 4931, Total Reward: 9\n",
      "Episode: 4932, Total Reward: 10\n",
      "Episode: 4933, Total Reward: 10\n",
      "Episode: 4934, Total Reward: 8\n",
      "Episode: 4935, Total Reward: 10\n",
      "Episode: 4936, Total Reward: 6\n",
      "Episode: 4937, Total Reward: 10\n",
      "Episode: 4938, Total Reward: 10\n",
      "Episode: 4939, Total Reward: 8\n",
      "Episode: 4940, Total Reward: 6\n",
      "Episode: 4941, Total Reward: 6\n",
      "Episode: 4942, Total Reward: 11\n",
      "Episode: 4943, Total Reward: 7\n",
      "Episode: 4944, Total Reward: 7\n",
      "Episode: 4945, Total Reward: 8\n",
      "Episode: 4946, Total Reward: 5\n",
      "Episode: 4947, Total Reward: 9\n",
      "Episode: 4948, Total Reward: -15\n",
      "Episode: 4949, Total Reward: 9\n",
      "Episode: 4950, Total Reward: 6\n",
      "Episode: 4951, Total Reward: 9\n",
      "Episode: 4952, Total Reward: 7\n",
      "Episode: 4953, Total Reward: 10\n",
      "Episode: 4954, Total Reward: 8\n",
      "Episode: 4955, Total Reward: 12\n",
      "Episode: 4956, Total Reward: 7\n",
      "Episode: 4957, Total Reward: 9\n",
      "Episode: 4958, Total Reward: 10\n",
      "Episode: 4959, Total Reward: 8\n",
      "Episode: 4960, Total Reward: 6\n",
      "Episode: 4961, Total Reward: 6\n",
      "Episode: 4962, Total Reward: 9\n",
      "Episode: 4963, Total Reward: 8\n",
      "Episode: 4964, Total Reward: 8\n",
      "Episode: 4965, Total Reward: 3\n",
      "Episode: 4966, Total Reward: 8\n",
      "Episode: 4967, Total Reward: 11\n",
      "Episode: 4968, Total Reward: 10\n",
      "Episode: 4969, Total Reward: 12\n",
      "Episode: 4970, Total Reward: 8\n",
      "Episode: 4971, Total Reward: 10\n",
      "Episode: 4972, Total Reward: 12\n",
      "Episode: 4973, Total Reward: 13\n",
      "Episode: 4974, Total Reward: 11\n",
      "Episode: 4975, Total Reward: 6\n",
      "Episode: 4976, Total Reward: 4\n",
      "Episode: 4977, Total Reward: 8\n",
      "Episode: 4978, Total Reward: 10\n",
      "Episode: 4979, Total Reward: 8\n",
      "Episode: 4980, Total Reward: 9\n",
      "Episode: 4981, Total Reward: 11\n",
      "Episode: 4982, Total Reward: 11\n",
      "Episode: 4983, Total Reward: 8\n",
      "Episode: 4984, Total Reward: 10\n",
      "Episode: 4985, Total Reward: 9\n",
      "Episode: 4986, Total Reward: 10\n",
      "Episode: 4987, Total Reward: 4\n",
      "Episode: 4988, Total Reward: 4\n",
      "Episode: 4989, Total Reward: 6\n",
      "Episode: 4990, Total Reward: -4\n",
      "Episode: 4991, Total Reward: 7\n",
      "Episode: 4992, Total Reward: 7\n",
      "Episode: 4993, Total Reward: 8\n",
      "Episode: 4994, Total Reward: 13\n",
      "Episode: 4995, Total Reward: 6\n",
      "Episode: 4996, Total Reward: 5\n",
      "Episode: 4997, Total Reward: 8\n",
      "Episode: 4998, Total Reward: 9\n",
      "Episode: 4999, Total Reward: 6\n",
      "Episode: 5000, Total Reward: 10\n"
     ]
    }
   ],
   "source": [
    "# Initiate q-table\n",
    "np.random.seed(123)\n",
    "q_table = np.zeros((num_states, num_actions)) #500x6 matrix\n",
    "\n",
    "\n",
    "# Q-learning algorithm\n",
    "for episode in range(num_episodes):\n",
    "    state, info = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    while not done:\n",
    "        # Calculate action with exploration-exploitation trade-off\n",
    "        if np.random.rand() < epsilon:\n",
    "            action = np.random.randint(0,6) #Take random action\n",
    "        else:\n",
    "            action = np.argmax(q_table[state]) #Take \"best\" route, highest reward\n",
    "    \n",
    "        \n",
    "        # step \n",
    "        new_state, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        \n",
    "        # Q-value update, from function\n",
    "        q_table[state,action] = (1-learning_rate)*q_table[state,action] + learning_rate*(reward + discount_factor*np.max(q_table[new_state]))\n",
    "        total_reward += reward\n",
    "        state = new_state\n",
    "    \n",
    "    epsilon = epsilon_min + (epsilon_max - epsilon_min)*np.exp(-epsilon_lambda*episode) #From epsilon function\n",
    "    print(f\"Episode: {episode+1}, Total Reward: {total_reward}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fdf225",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6d7ae88e0a68128cf258b2e24a0d248a",
     "grade": false,
     "grade_id": "intro_ex_1_2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exersice 1.2: Evaluate Q-learning \n",
    "\n",
    "Here implement greedy actions only with the learned Q-table. It is also possible to visualize the results. A coorectly implemented q-learning algorithm should get average reward of higher than 7.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "331b4952",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "976a35458ed027a03623d60c836f8a23",
     "grade": true,
     "grade_id": "test_q_learning",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward over 100 evaluation episodes: 7.78\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the trained policy\n",
    "env_render = gym.make(\"Taxi-v3\", render_mode='human') # env with renderig, if you want to visualize, but it is slow. \n",
    "\n",
    "total_rewards = []\n",
    "num_evaluation_episodes = 100\n",
    "\n",
    "for _ in range(num_evaluation_episodes):\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    while not done:\n",
    "       \n",
    "        # Choose greedy action \n",
    "        \n",
    "        action = np.argmax(q_table[state]) \n",
    "        new_state, reward, terminated, truncated, _ = env.step(action)\n",
    "        #new_state, reward, terminated, truncated, _ = env_render.step(action) # uncomment for visualization\n",
    "\n",
    "        done = terminated or truncated\n",
    "        total_reward += reward\n",
    "        state = new_state\n",
    "    \n",
    "    total_rewards.append(total_reward)\n",
    "\n",
    "average_reward = np.mean(total_rewards)\n",
    "print(f\"Average Reward over {num_evaluation_episodes} evaluation episodes: {average_reward}\")\n",
    "env_render.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da7579c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "55f00d503598087056fa0ba55af905ae",
     "grade": false,
     "grade_id": "Q_learning_ex_1_3_text",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exersice 1.3: Q-learning question\n",
    "\n",
    "Are there any limitations with Q-learning, what type of problems can it solve and what type of problems is it less suitable for?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9736e3af",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "02eae55556f1aca2a5ad2bc313f1af22",
     "grade": true,
     "grade_id": "Q_learning_ex_1_3_ans",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "If we choose a Greedy algorithm it might miss the best path, since it just checks the next actions from that point, we could have a better path with more reward, but if the first action is giving less reward we might choose the other one. If we have many dimensions we will get a big Q_table since we need to store Q_values for each state-actions. It takes up a lot of memory and computer power."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a88d69",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c53f8558b5868bbfc34d33a2c63fbc37",
     "grade": false,
     "grade_id": "Deep_q_intro",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Deep Q learning\n",
    "\n",
    "In this task, we'll tackle the challenge of balancing an inverted pendulum. What makes this problem intriguing is that it involves continuous input variables, making the traditional Q-learning approach with a finite table impractical. Instead, we'll use a neural network to approximate the Q-table, enabling us to efficiently handle continuous input while still producing discrete outputs.\n",
    "\n",
    "First we will construct our neural network, this will be done in three steps. First we will define our activation function, then we will define a what a layer is and lastly we will construct the network.  \n",
    "\n",
    "First let us go over the math of a neural network. They should be seen as general function approximator. A segment of neural network can be represented with a graph representation, see image below. \n",
    "\n",
    "<img src=\"imgs/NN_ps3.png\" width=\"800\"/>\n",
    "\n",
    "\n",
    "\n",
    "### Naming\n",
    "* $a^i_j$ is the output of neuron j in layer i.\n",
    "* $b^i_j$ is the sum of the input to neuron j in layer i.\n",
    "* $g()$ is the activation function of a neuron (the last layer does not have a activation funciton in this case)\n",
    "* $w^i_{jk}$ is the weights of layer i going from neron k in layer i-1 to neuron j in layer i. \n",
    "\n",
    "### Forward propagation\n",
    "\n",
    "A neural network can be seen as a function $y = f(x)$ where $x$ is an input vector and $y$ is an output vector. Forward propagation describes how we go from the input $x$ to the output $y$. Each layer can be caluculated in a sequence, where we start from the input. \n",
    "\n",
    "First each neuron $j$ in layer 1 calculated the sum of the input to that neuron:\n",
    "\n",
    "$b^1_j = \\sum_{k=1}^{len(x)}( w^1_{j,k}x_k) + w^1_{j,0}$ \n",
    "\n",
    "The output of the first layer is caluclated but using the activation funciton. \n",
    "\n",
    "$a^1_j = g(b^1_j)$\n",
    "\n",
    "More generally for layer $i$ and with matrix multiplication we can write this as.\n",
    "\n",
    "$b^i = w^i \\begin{bmatrix} 1 \\\\ a^{i-1}\\end{bmatrix}$\n",
    "\n",
    "where $b^i$ is a vector that has the same dimension as number of neurons in layer $i$ and the 1 added to the input is for calculating the bias. \n",
    "\n",
    "$a^i = g(b^i)$\n",
    "\n",
    "This is then caluculated sequentially until the last layer has been reashed. For the last layer without activation function we would have\n",
    "\n",
    "$\\hat{y} = a^i = b^i$\n",
    " \n",
    "### Backward propagation\n",
    "\n",
    "The way we train a network is by updating the weights $w$, they are the parameters we want to estimate to solve the problem. The way we are going to update the weights is through gradient descent. The gradients are calculated sequentially from the last layer to the first. The reason for this is that this allows us to leverage the chain rule, this saves us a lot of computational complexity. \n",
    "\n",
    "Calculating gradients:\n",
    "\n",
    "For each parameter (weight) in the neural network we will calculate a gradient:\n",
    "$\\frac{\\partial \\mathcal{L}}{\\partial w^i_{jk}}$ \n",
    "where $\\mathcal{L(\\mathbf{y}, \\hat{\\mathbf{y}})}$ is the loss function, which we want to minimize. A normal loss function could for example be the mean square error $\\mathcal{L} = \\frac{1}{n}\\sum_{i=1}^n(y-\\hat{y})^2$. The gradients can be caluclated with \n",
    "\n",
    "$\\frac{\\partial \\mathcal{L}}{\\partial w^i_{jk}} = \\Delta^i_{j} a^{i-1}_k$\n",
    "\n",
    "where $\\Delta^i_j$ can be seen as the \"precived\" error for the input to neuron $j$ in layer $i$. It can be calculated with the chain rule. Let $n(i)$ be a function that returns the number of neuron of layer $i$.\n",
    "\n",
    "$\\Delta^i_j = \\left( \\sum_{r=1}^{n(i+1)} \\Delta^{i+1}_r w^{i+1}_{rj} \\right) \\frac{\\partial g(b^i_j)}{\\partial b^i_j}$\n",
    "\n",
    "For the first itteration there where is no $\\Delta^{i+1}_r$ then they are calculated as:\n",
    "\n",
    "$\\Delta^i_j = \\frac{\\partial \\mathcal{L(\\mathbf{y}, \\hat{\\mathbf{y}})}}{\\partial \\hat{y}_j}$\n",
    "\n",
    "This is under the assumption that there is no activation on the last layer. The nice thing is that the calculation of the vector $\\Delta^i$ can be done as a matrix multiplication:\n",
    "\n",
    "$\\Delta^i = (\\bar{w}^{i+1})^T \\Delta^{i+1} \\odot \\nabla_{b^i} g(b^i)$\n",
    "\n",
    "where $\\odot$ is elementwise multiplication, $\\bar{w}$ is the weight without bias and $\\nabla_{b^i} g(b^i) = \\begin{bmatrix} \\frac{\\partial g(b^i_1)}{\\partial b^i_1} &...&\\frac{\\partial g(b^i_n)}{\\partial b^i_n} \\end{bmatrix}^T$.\n",
    "\n",
    "We can then calculate the gradients for a layer with:\n",
    "\n",
    "$\\nabla_{w^i} \\mathcal{L} = \\Delta^i  (a^{i-1})^T$\n",
    "\n",
    "We are then going to update the weights with:\n",
    "\n",
    "$w^i \\leftarrow w^i - \\alpha(\\nabla_{w^i} \\mathcal{L} + \\lambda w^i)$\n",
    "\n",
    "where $\\alpha$ is the learning rate and $\\lambda$ is a regularization term (L2 regularization), we don't want the weight to become too large. The regularization also combats overfitting to some extent. We will come back to $\\nabla_{w^i}$ later. \n",
    "\n",
    "For more on the chain rule see the exersice \"NN_exersice\" on canvas under the Exercises folder.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66120cf7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c730103a194f266df1be32674e9ba3f4",
     "grade": false,
     "grade_id": "intro_ex_2_1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exersice 2.1: ReLu\n",
    "\n",
    "Here we will implement a class for the ReLu activation function. The activation function is what allows deep neural networks to express non-linearities. The class will only have two functions, forward(x) and diff(x). The forward function takes a vector or matrix and outputs the same shape where for every element we have applied the ReLu function. The diff function returns the partial derivative of the ReLu function. This will later be used in our neural network. \n",
    "\n",
    "Hint: np.where() is useful function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "53a37fbd",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f35eaa602fefa4e6297bcd504abfb7f",
     "grade": false,
     "grade_id": "ReLu",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class ReLu():\n",
    "    def forward(self, x):\n",
    "        # x is a numpy array and can have any shape. \n",
    "        # calculates the output of the ReLU function\n",
    "        return np.maximum(0,x) #If x is lower than 0, then return 0, else return input.\n",
    "        \n",
    "        \n",
    "    def diff(self, x):\n",
    "        # x is a numpy array and can have any shape.\n",
    "        # calculates the partial differential of the ReLU function\n",
    "        return np.where(x <= 0, 0, 1) # For x lower than 0, return 0, else return 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b473050f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e7ae97291c36dea27bb0214ce4a430be",
     "grade": true,
     "grade_id": "ReLU_test",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward test:  True\n",
      "diff test:  True\n"
     ]
    }
   ],
   "source": [
    "relu = ReLu()\n",
    "\n",
    "input = np.array([[1.2],[-1.1], [0.0], [10.3]])\n",
    "out = relu.forward(input)\n",
    "ref = np.array([[1.2],[0.0], [0.0], [10.3]])\n",
    "print('forward test: ', np.array_equal(out, ref))\n",
    "\n",
    "diff_out = relu.diff(input)\n",
    "diff_ref = np.array([[1.],[0.0], [0.0], [1]])\n",
    "print('diff test: ', np.array_equal(diff_out, diff_ref))\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceb8933",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "feca8b4e21fb40ef49d69a6e665223a9",
     "grade": false,
     "grade_id": "intor_ex_2_2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exersice 2.2: Layer\n",
    "\n",
    "A dense neural network is constructed by layers of neurons, here we will define a class to represent our layers. It will contain the weights and activation function for the layer. The layer class will contain two functions, forward and backward.\n",
    "\n",
    "Hint: it is a good practice to return a copy of np arrays or matrices as otherwise modifying the output can modify the internally saved matrix as it is the same object, these problems are not easy to debug. For a matrix A, then return A.copy(). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "48b5b7d0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b63bce90e62ae9d46fca75f8b887e988",
     "grade": false,
     "grade_id": "Layer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    def __init__(self, num_in, num_out, activation_func=None):\n",
    "        self.weights = np.random.rand(num_out, num_in+1)-0.5 # (to layer, from layer) \n",
    "        self.gradients = np.zeros((num_out, num_in+1))\n",
    "        self.a_input = None  # placeholder for saving the input to the forward function\n",
    "        self.b = None  # placeholder for saving the value right before the activation function\n",
    "        self.activation_func = activation_func  # class instance of activation function \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x is a standing vector\n",
    "        # Add a 1 for the bias term on the input, and save this in the self.a_input, this will be used later in backward()\n",
    "        bias = 1.0\n",
    "        self.a_input=np.insert(x, 0 ,bias,axis=0).copy() #Axis = 0, otherwise I had tiny errors in the test below\n",
    "        # Calculate b, the summation in each neuron. Can be done as a matrix multiplication, save in self.b. \n",
    "        self.b = np.dot(self.weights,self.a_input).copy() #Dot product\n",
    "        # Check if the activation function is None, otherwise run the forward of the activation function. \n",
    "        if self.activation_func is None:\n",
    "            return self.b\n",
    "        else:\n",
    "            return self.activation_func.forward(self.b)\n",
    "        # return the output of the layer\n",
    "        \n",
    "        \n",
    "    \n",
    "    def backward(self, pre_delta, pre_w=None):\n",
    "    \n",
    "        # pre_delta is from layer i+1, pre_w is the weights from layer i+1.\n",
    "        # First check it pre_w is None, it is none for the last layer (output layer).\n",
    "        # # Calculate this layers delta \n",
    "        if pre_w is None:\n",
    "            delta = pre_delta #This is L/delta y^hat, L is loss function\n",
    "        else:\n",
    "            #Hidden layer: Calc delta by using backpropgating through pre_w, use weights from next layer (pre_w), with bias term removed\n",
    "            delta = np.dot(pre_w.T,pre_delta)[1:].copy() \n",
    "    \n",
    "        # Caluclate this layers gradients and save to self.gradients (do not use the gradients to update the weights yet)\n",
    "        if self.activation_func:\n",
    "            delta *= self.activation_func.diff(self.b)\n",
    "            \n",
    "        self.gradients = np.outer(delta, self.a_input).copy()\n",
    "        # return delta from this layer \n",
    "        return delta, self.gradients\n",
    "        # Hint: see calculations above under Deep Q Learning\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d87bfea",
   "metadata": {},
   "source": [
    "### Test your layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "25cdadc1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5ed3cb821b39631c1ce9f6830c89d6a9",
     "grade": true,
     "grade_id": "Layer_test",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward function matches reference\n",
      "delta is correct for no activation function\n",
      "gradients are correct for when no activation function\n",
      "delta correct with activation function\n",
      "gradients are correct with activation function\n"
     ]
    }
   ],
   "source": [
    "### ------------ Test forward -------------------\n",
    "\n",
    "layer = Layer(3, 3, ReLu())\n",
    "x = np.array([[1.2], [-0.3], [4.1]])\n",
    "weights = np.array([[ 0.27611978, -0.34896471, -0.33349842,  0.33546291],\n",
    "          [-0.17959862, -0.36556547,  0.26716984,  0.31734925],\n",
    "          [-0.11004516,  0.28841945, -0.36654527, -0.10927562]])\n",
    "layer.weights = weights\n",
    "ref = np.array([[1.33280959],\n",
    "             [0.60270379],\n",
    "             [0.        ]])\n",
    "out = layer.forward(x)\n",
    "\n",
    "if np.allclose(ref, out):\n",
    "    print('Forward function matches reference')\n",
    "else:\n",
    "    print('Forward is not same as reference', out)\n",
    "\n",
    "### ------------ Test Backward with no activation function -------------------\n",
    "layer = Layer(3, 3)\n",
    "layer.weights = weights\n",
    "\n",
    "out = layer.forward(x)\n",
    "\n",
    "pre_delta = np.array([[0.0],[0.3],[-1.7]])\n",
    "delta, _ = layer.backward(pre_delta)\n",
    "\n",
    "if np.allclose(pre_delta, delta):\n",
    "    print('delta is correct for no activation function')\n",
    "else:\n",
    "    print('delta is incorrect for no activation function', delta)\n",
    "\n",
    "    \n",
    "grad_ref = np.array([[ 0.,    0.,   -0.,    0.  ],\n",
    "                     [ 0.3,   0.36, -0.09,  1.23],\n",
    "                     [-1.7, -2.04, 0.51,-6.97]])\n",
    "\n",
    "if np.allclose(grad_ref, layer.gradients):\n",
    "    print('gradients are correct for when no activation function')\n",
    "else:\n",
    "    print('gradients are incorrect for when no activation function', layer.gradients)\n",
    "    \n",
    "### ------------ Test Backward with activation function -------------------\n",
    "    \n",
    "layer = Layer(3, 3, ReLu())\n",
    "layer.weights = weights\n",
    "\n",
    "out = layer.forward(x)\n",
    "\n",
    "pre_w  = np.array([[-0.04031945,  0.36892667, -0.47157759, -0.19271963],\n",
    "                   [ 0.25223295,  0.38480469,  0.42154434,  0.13994889],\n",
    "                   [ 0.07775184, -0.43675348,  0.36158881,  0.25008313]])\n",
    "\n",
    "delta, _ = layer.backward(pre_delta, pre_w)\n",
    "\n",
    "ref_delta = np.array([[ 0.85792232],\n",
    "                      [-0.48823767],\n",
    "                      [-0.        ]])\n",
    "\n",
    "ref_grad = np.array([[ 0.85792232,  1.02950679, -0.2573767, 3.51748152],\n",
    "                     [-0.48823767, -0.58588521,  0.1464713,  -2.00177447],\n",
    "                     [-0.,         -0.,          0.,         -0.       ]])\n",
    "\n",
    "if np.allclose(ref_delta, delta):\n",
    "    print('delta correct with activation function')\n",
    "else:\n",
    "    print('delta incorrect with activation function', delta)\n",
    "    \n",
    "if np.allclose(ref_grad, layer.gradients):\n",
    "    print('gradients are correct with activation function')\n",
    "else:\n",
    "    print('gradients are incorrect with activation function', layer.gradients)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e711df",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "920a556408026ecfb4d90de73a9813e3",
     "grade": false,
     "grade_id": "intro_ex_2_3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 2.3: Define the neural network\n",
    "We will create a neural network that has two hidden layers with 64 neurons each with ReLU activation function and the output layer has the same size as the number of outputs but with no activation function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8898221a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71f4d59fc27df15463f87eae45b9caf1",
     "grade": true,
     "grade_id": "NN_define",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class NeuralNetwork():\n",
    "    def __init__(self, lr=1e-3, input_size=4, output_size=6, regularization=1e-4):\n",
    "        # Here we create a list of the layers that we defined above\n",
    "        # This is where we define the structure of our network\n",
    "        self.layers = [Layer(input_size, 64, ReLu()),\n",
    "                       Layer(64, 64,ReLu()),\n",
    "                       Layer(64, output_size)]\n",
    "        self.num_layers = len(self.layers)\n",
    "        self.lr = lr\n",
    "        self.regularization = regularization\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Calculate the output of the neural network by itterating over the layers and return the output. \n",
    "        for i in self.layers:\n",
    "            x = i.forward(x)\n",
    "        return x.copy() \n",
    "    \n",
    "    def backward(self, loss_diff):\n",
    "        # Here we caluclate the gradients for the network.\n",
    "        # The input is the partial differential of the loss function. \n",
    "        # Go backwards throught the layers and call the backwards function from the last layer and itterate \n",
    "        # towards the first layer. \n",
    "        # Hint: for i, layer in reversed(list(enumerate(self.layers))): could be useful\n",
    "        # For the output layer in the network: delta = loss_diff and w_1 = None.  \n",
    "        # return a python list that contains the graidients from each layer. i.e. [grad_layer_1, grad_layer_2, etc]\n",
    "        gradients = [None]*self.num_layers # initialize a python list to hold the gradients \n",
    "        delta = loss_diff #\n",
    "        \n",
    "        for i, layer in reversed(list(enumerate(self.layers))):\n",
    "            if i == (self.num_layers -1): #If we are at first position in backpropgation (last pos in forward prop)\n",
    "                pre_w = None \n",
    "            else:\n",
    "                pre_w = self.layers[i+1].weights #Gather weights from next layer (i+1)\n",
    "                \n",
    "            delta, gradient = layer.backward(delta,pre_w) #We use older backward function which we created before\n",
    "        \n",
    "            gradients[i] = gradient #Store the calculated gradient for this current layer onto gradients list.\n",
    "        return gradients\n",
    "    \n",
    "\n",
    "    def update_weights(self, gradients):\n",
    "        # Here we update the weights of the network, input is a list of gradients. We then want to update the weights\n",
    "        # as described above with regularization. \n",
    "        # the second thing we are going to do is to clip the weights, this just ensures that we wont get any \n",
    "        # numerical problems from exploding gradients. \n",
    "        for i, grad in enumerate(gradients): \n",
    "            # UPDATE the weights here\n",
    "            #new weights = old weights - learning_rate*(gradient+regulzation*old weights)\n",
    "            self.layers[i].weights -= self.lr * (grad+ self.regularization*self.layers[i].weights)\n",
    "            \n",
    "            \n",
    "            self.layers[i].weights = np.clip(self.layers[i].weights, -1e4, 1e4)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8f1388",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "43db34785f0b137c3676b30c6d8e8ebb",
     "grade": false,
     "grade_id": "intro_test_supervized",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Test supervised learning to see if the network performes as expeced. \n",
    "Here we want to test the neural network on a simple supervised problem, it should learn the output of two functions. Does the y_est follow the true y? You should see that they follow each other fairly well, usually within 0.1 difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "69bd0fcb",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c29d8dbb2663bf10fdaabebb9dab9ef0",
     "grade": true,
     "grade_id": "NN_supervised_test",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: [2.34237553 0.4487831 ] y_est: [2.32590508 0.47461817]\n",
      "y: [2.86254388 1.34771369] y_est: [2.91954005 1.35153213]\n",
      "y: [2.27743254 0.19050826] y_est: [2.29166043 0.18420022]\n",
      "y: [3.20728993 0.1825447 ] y_est: [3.21254485 0.15176325]\n",
      "y: [2.57050154 0.58792381] y_est: [2.62737785 0.56093488]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "nn = NeuralNetwork(lr=1e-3, input_size=3, output_size=2)\n",
    "# Train \n",
    "for i in range(10000):\n",
    "    x = np.random.rand(3,1)\n",
    "    y1 = 2*x[0,0] + x[0,0]*x[1,0] +1\n",
    "    y2= -1*x[2,0] + 3*x[0,0]*x[2,0] \n",
    "    \n",
    "    y = np.array([[y1],[y2]])\n",
    "    y_est = nn.forward(x)\n",
    "    \n",
    "    diff_loss = -2*(y-y_est)\n",
    "    loss = (y-y_est)**2\n",
    "    grad = nn.backward(diff_loss)\n",
    "    nn.update_weights(grad)\n",
    "\n",
    "# Test\n",
    "for i in range(5):\n",
    "    x = np.random.rand(3,1)\n",
    "    y1 = 2*x[0,0] + x[0,0]*x[1,0] +1\n",
    "    y2= -1*x[2,0] + 3*x[0,0]*x[2,0] \n",
    "    \n",
    "    y = np.array([[y1],[y2]])\n",
    "    y_est = nn.forward(x)\n",
    "    \n",
    "    print('y:', y[:,0], 'y_est:', y_est[:,0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ddac8d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e7fa1d9f6c48b2664a612b83e35de017",
     "grade": false,
     "grade_id": "intro_deep_q_lr",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Training Deep Q-learning\n",
    "\n",
    "The idea for this section is that we will walk you through the code and the process and then you will answer some theoretical questions.\n",
    "\n",
    "Now, we have a neural network, and we aim to employ it to balance an inverted pendulum on a cart. This problem involves continuous input space, with four inputs, and a discrete output space, consisting of two possible actions (left or right). The reward function for this task is straightforward - we receive a reward for every step taken, with the objective being to maintain balance. The task is considered unsuccessful if the pendulum leans too far or the cart moves excessively to the side. You can find more details about this problem at https://gymnasium.farama.org/environments/classic_control/cart_pole/.\n",
    "\n",
    "The challenge with this problem is that the continuous input space makes it impractical to use standard Q-learning, as the Q-table would become excessively large. To address this, we'll replace the Q-table with a neural network. However, as we will demonstrate, this transition is not without its challenges. \n",
    "\n",
    "The primary challenge in deep Q-learning lies in training stability, as the training process tends to be noisy, and many issues can arise. To enhance stability, we introduce three key components: target networks, experience replay, and batch gradient descent. However, before delving into those specifics, let's discuss the fundamental principle of replacing the Q-table with a neural network.\n",
    "\n",
    "In Q-learning, we maintain a table of future expected rewards, and for a given state and action, we can obtain the value, denoted as $Q(s, a)$. Our objective is to approximate this Q-value using a neural network, denoted as $f$, which takes the state as input and produces a value for each possible action, i.e., $\\hat{q} = f(s)$, where $\\hat{q}$ is a vector. The training loop remains similar to traditional Q-learning, but in this case, we formulate a loss function. \n",
    "\n",
    "$\\mathcal{L}(s_t, a) = (q(s_t)_a -\\hat{q}(s_t)_a)^2$\n",
    "\n",
    "were \n",
    "\n",
    "$q(s_t)_a = r + \\gamma \\underbrace{\\max}_{a} \\hat{q}(s_{t+1})$ \n",
    "\n",
    "and $\\hat{q}(s_t)_a$ is the output of the network for action $a$ and state $s$, and $\\hat{q}(s_{t+1})$ is for the next state. This will make the network converge towarde the Q-table, atleast theoretically. The problem is that this is prone to instabilities. We can no longer initiate the network to predict zeros initially, so the initial predictions of the future reward will be completely wrong. Every time we update the weights we will also change $\\underbrace{\\max}_{a} \\hat{q}(s_{t+1})$, which means that the value the network tries to converge to is allways changing, and if it varies to fast instabilities will arrise. One other of the downsides of using gradient decent is that it can easily forget thing that it trained on a long time ago. The methods below attempts to minimize these issues.     \n",
    "\n",
    "\n",
    "### Target network \n",
    "The idea here is to make $\\underbrace{\\max}_{a} \\hat{q}(s_{t+1})$ a slow varying target to increase stability. We introdue a second network called the target network. So we have two netorks $\\hat{q} = f(s)$ and $\\hat{q}_T = f_T(s)$, where the second is the target network. We use the second network to estimate the future estimated reward.  \n",
    "\n",
    "$q(s_t, a) = r + \\gamma \\underbrace{\\max}_{a} \\hat{q}_T(s_{t+1}, a)$ \n",
    "\n",
    "The idea is then to update the target network slowly towards the first network, the weights of the target network $w_T$ can then be updated with \n",
    "\n",
    "$w_T = w_T + \\alpha_T (w - w_T)$\n",
    "\n",
    "where $\\alpha_T$ is the target update rate. This adds stability to the traning as the future expected reward is more steady and slow changing. \n",
    "\n",
    "### Experiance replay\n",
    "\n",
    "Next up is experience replay, because of gradient descent we don't want to train on samples that are too close to each other as there is a risk that the network will forget things it has learned. The idea is then in the training loop to not directly train on the observed data but instead save it in a buffer/queue. For training we sample for the queue, this means that the network might train on old data or new data. This minimizes that it forgets or that a lot of samples in sequence are too similar. \n",
    "\n",
    "### Batch gradient decent \n",
    "\n",
    "To furter imporove stability we sample multiple timesteps from our memory buffer, then we caluclate the gradients for each of them and take the average of the gradients. It is then those average graidentes we use as $\\nabla_{w^i}$ to update the weights, this minimize noise as each update of the weights is based on multiple data samples. \n",
    "\n",
    "We will now show how these things can be implemented in code. \n",
    "\n",
    "## Hyper parameters\n",
    "\n",
    "Neural networks can have quite a few hyper parameters and it can be quite tricky to tune them. I have provided some hypter parameters that work, but feel free to tune them if desiered.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d88bc5c4",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0339d6bd13db65a30e9890d17b1af0bd",
     "grade": true,
     "grade_id": "Hyper_parameters",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import random\n",
    "import copy\n",
    "from collections import deque # will be used to create a memory buffer\n",
    "\n",
    "n_observation = 4 # input size, inverted pendelum (Cart Pole) \n",
    "n_actions = 2 # output size, inverted pendelum (Cart Pole)\n",
    "\n",
    "# Hyperparameters\n",
    "learn_rate = 2e-4 # learning rate, alpha\n",
    "discount_factor = 0.98 # discount factor, gamma \n",
    "epsilon = 1.0 # epsilon\n",
    "epsilon_max = 1.0 # epsilon max\n",
    "epsilon_min = 0.05 # epsilon min\n",
    "epsilon_lambda = 0.01 # epsilon decay rate\n",
    "target_rate = 5e-3 # learning rate of target network\n",
    "num_episodes = 500 # number of episodes the learning is \n",
    "batch_size = 128 # How many samples are used to calculate the gradients. \n",
    "regularization = 1e-4 # amount of regularization \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934c2d25",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bb03be0a51b48ea2d81562815144a44b",
     "grade": false,
     "grade_id": "intro_train_function",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Training function\n",
    "\n",
    "Here we define our training function, this is what will be called for every step in our trianing loop. This part is responsible for sampling a batch from the memory buffer and calculating the gradients for the batch, it is also here we have our reward function and update our network. Lastly we will update the weights of the target network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5d5cff63",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "79e6a20aa389d86df877576ccc8ba332",
     "grade": true,
     "grade_id": "tranning_function",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def unpack_state(state): #this is for reshaping the state from gym to a standing vector. \n",
    "    return  np.reshape(state, (len(state),1))\n",
    "\n",
    "# This is the training function that will be called from the traning loop\n",
    "def train_network(nn, nn_target, memory):\n",
    "    # nn - is the neural network, nn_target - is the target network, memory - is the memory buffer\n",
    "    if len(memory) > batch_size: #check if there is enought data in the memory buffer\n",
    "        grad_list = [[] for x in range(nn.num_layers)] # create a list to temporay store all the gradients\n",
    "        sample = random.sample(memory, batch_size) # We sample batch_size number of samples from our memory buffer\n",
    "\n",
    "        # we calculate the gradients for each sample that we sampled\n",
    "        for i in range(batch_size): \n",
    "            state = sample[i][0]\n",
    "            action = sample[i][1]\n",
    "            reward = sample[i][2]\n",
    "            next_state = sample[i][3]\n",
    "            done = sample[i][4]\n",
    "            \n",
    "            # first we run a forward pass on both networks \n",
    "            pred = nn.forward(unpack_state(state))\n",
    "            pred_target = nn_target.forward(unpack_state(next_state))\n",
    "            \n",
    "            # we create a loss vector that is zeros. We directly express it as the partial deriviative \n",
    "            diff_loss = np.zeros((n_actions,1))\n",
    "            \n",
    "            # we calcualte out q using the reward and the best expected reward from the target network\n",
    "            q = reward + discount_factor * np.max(pred_target)*(1-done)\n",
    "            # we caluclate the partial derivative loss for the action \n",
    "            diff_loss[action, 0] =  -2*(q - pred[action, 0])\n",
    "        \n",
    "            grad = nn.backward(diff_loss) # we calculate the gradients in the network\n",
    "            \n",
    "            # we append the gradients to our list for the batch \n",
    "            for k in range(nn.num_layers):\n",
    "                    grad_list[k].append(grad[k])\n",
    "\n",
    "        # After all gradients are calcultated we take the average over the batch. \n",
    "        avg_grad = []            \n",
    "        for k in range(nn.num_layers):\n",
    "            avg_grad.append(np.mean(grad_list[k], axis=0))\n",
    "        \n",
    "        # we update the weigths of the networḱ\n",
    "        nn.update_weights(avg_grad)\n",
    "    # Lastly we update the target network to be closer to the network, the idea is that the target updates slower\n",
    "    # and therefore is less noisy. \n",
    "    for k in range(nn.num_layers):\n",
    "            nn_target.layers[k].weights += target_rate*(nn.layers[k].weights - nn_target.layers[k].weights)\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5640e56",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "04be1614b924470e3fe908540536f664",
     "grade": false,
     "grade_id": "intro_train_loop",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "##  Training loop\n",
    "\n",
    "Here is the actual training loop that runs the simulation. This part should look similar to the q-learning training loop at the beginning of the assignment. The difference is the call of the training function and appending to the memory buffer. Because of the unstable nature of deep Q-learning, you typically save the network that performed the best during training. It can sometimes take more than 100 episodes before you see any noticeable learning.\n",
    "\n",
    "Even with all the additions of the target network, batch gradient decent and experience replay, the training can still be unstable. It is therefore common in reinforcement learning to always save the best-performing network. \n",
    "\n",
    "## Exercise 2.4: Epsilon greedy - deep learning\n",
    "Fill code for action and update of epsilon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4928b835",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf97cb1604e6aaf3722d9546c55e4aff",
     "grade": true,
     "grade_id": "tranning_loop",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_model 19.0\n",
      "Episode: 1, Total Reward: 19.0 prob  1.0\n",
      "save_model 25.0\n",
      "Episode: 2, Total Reward: 25.0 prob  0.9905473420617097\n",
      "Episode: 3, Total Reward: 18.0 prob  0.9811887396414175\n",
      "Episode: 4, Total Reward: 15.0 prob  0.9719232568710827\n",
      "Episode: 5, Total Reward: 17.0 prob  0.9627499671947071\n",
      "save_model 33.0\n",
      "Episode: 6, Total Reward: 33.0 prob  0.9536679532756783\n",
      "Episode: 7, Total Reward: 25.0 prob  0.9446763069050362\n",
      "save_model 37.0\n",
      "Episode: 8, Total Reward: 37.0 prob  0.9357741289106508\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 44\u001b[0m\n\u001b[0;32m     41\u001b[0m memory\u001b[38;5;241m.\u001b[39mappend((state, action, reward, new_state, done))\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# call the training function\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m \u001b[43mtrain_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnn_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# update total reward and state\u001b[39;00m\n\u001b[0;32m     47\u001b[0m total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward \n",
      "Cell \u001b[1;32mIn[45], line 31\u001b[0m, in \u001b[0;36mtrain_network\u001b[1;34m(nn, nn_target, memory)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# we caluclate the partial derivative loss for the action \u001b[39;00m\n\u001b[0;32m     29\u001b[0m diff_loss[action, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m  \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m(q \u001b[38;5;241m-\u001b[39m pred[action, \u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m---> 31\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiff_loss\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# we calculate the gradients in the network\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# we append the gradients to our list for the batch \u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nn\u001b[38;5;241m.\u001b[39mnum_layers):\n",
      "Cell \u001b[1;32mIn[42], line 36\u001b[0m, in \u001b[0;36mNeuralNetwork.backward\u001b[1;34m(self, loss_diff)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m         pre_w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;66;03m#Gather weights from next layer (i+1)\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m     delta, gradient \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpre_w\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#We use older backward function which we created before\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     gradients[i] \u001b[38;5;241m=\u001b[39m gradient \u001b[38;5;66;03m#Store the calculated gradient for this current layer onto gradients list.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gradients\n",
      "Cell \u001b[1;32mIn[40], line 40\u001b[0m, in \u001b[0;36mLayer.backward\u001b[1;34m(self, pre_delta, pre_w)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_func:\n\u001b[0;32m     38\u001b[0m     delta \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_func\u001b[38;5;241m.\u001b[39mdiff(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb)\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradients \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mouter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ma_input\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# return delta from this layer \u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m delta, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradients\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\core\\numeric.py:925\u001b[0m, in \u001b[0;36mouter\u001b[1;34m(a, b, out)\u001b[0m\n\u001b[0;32m    923\u001b[0m a \u001b[38;5;241m=\u001b[39m asarray(a)\n\u001b[0;32m    924\u001b[0m b \u001b[38;5;241m=\u001b[39m asarray(b)\n\u001b[1;32m--> 925\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmultiply\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewaxis\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnewaxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train Deep Q-learning algorithm\n",
    "\n",
    "# We create the environment \n",
    "env = gym.make(\"CartPole-v1\")\n",
    "#env = gym.make('LunarLander-v2')\n",
    "# we create our neural network and target network, both are identical to start with. \n",
    "nn = NeuralNetwork(lr=learn_rate, input_size=n_observation, output_size=n_actions, regularization=regularization)\n",
    "nn_target = NeuralNetwork(lr=learn_rate, input_size=n_observation, output_size=n_actions, regularization=regularization)\n",
    "nn_target.layers = nn.layers.copy()\n",
    "\n",
    "# A placeholder network to save the best solution. \n",
    "nn_save = NeuralNetwork(lr=learn_rate, input_size=n_observation, output_size=n_actions, regularization=regularization)\n",
    "\n",
    "# our memory buffer, it can hold 10000 samples \n",
    "memory = deque(maxlen=10000)\n",
    "\n",
    "# To track rewards\n",
    "rewards_list = []\n",
    "highest_score = 0\n",
    "\n",
    "# train over a number of episodes\n",
    "for episode in range(num_episodes):\n",
    "    state, info = env.reset() # reset the environment in the beging of every episode\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        # Get prediciton\n",
    "        pred = nn.forward(unpack_state(state))\n",
    "        \n",
    "        # Calculate action with exploration-exploitation trade-off\n",
    "        if np.random.rand() <= epsilon:\n",
    "            action = env.action_space.sample() #Generates random action from the action space of the enviroment env\n",
    "        else:\n",
    "            action = np.argmax(pred) \n",
    "        \n",
    "\n",
    "        new_state, reward, terminated, truncated, _ = env.step(action) # take a step in the environment\n",
    "        done = terminated or truncated # check if done\n",
    "        # append to the memory buffer\n",
    "        memory.append((state, action, reward, new_state, done))\n",
    "        \n",
    "        # call the training function\n",
    "        train_network(nn, nn_target, memory)\n",
    "\n",
    "        # update total reward and state\n",
    "        total_reward += reward \n",
    "        state = new_state\n",
    "            \n",
    "    rewards_list.append(total_reward)\n",
    "    # save best performing network\n",
    "    if total_reward >= np.max(rewards_list):\n",
    "        nn_save = copy.deepcopy(nn)\n",
    "        print('save_model', total_reward)\n",
    "        \n",
    "    # Decay exploration probability (epsilon)\n",
    "    \n",
    "    epsilon = epsilon_min + (epsilon_max - epsilon_min)*np.exp(-epsilon_lambda*episode)\n",
    "    print(f\"Episode: {episode+1}, Total Reward: {total_reward}\", 'prob ', epsilon)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7077e413",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b0e1fd35486a4811743b16a28bb47542",
     "grade": false,
     "grade_id": "title_learnng_curve",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Plot the learning curve\n",
    "Below we plot the total reward againt the episodes, you can see that the learning is noisy and quite often it completly forgets everything after 300-400 episodes. The highest score is 500 and it is usually posible to reach it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "20943e42",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d6fae63369ebdf24db45bd5d102af692",
     "grade": true,
     "grade_id": "plot_learning_curve",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.plot(rewards_list)\n",
    "plt.xlabel('episode')\n",
    "plt.ylabel('total reward')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f11611",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2a8b7bed97956ea11cbbe7104071d4db",
     "grade": false,
     "grade_id": "title_learned_policy",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Test the learned policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2da732cb",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d3ff92c7efff9c8a83afe28b2523c114",
     "grade": true,
     "grade_id": "test_learnd_policy",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "#env = gym.make(\"LunarLander-v2\", render_mode=\"human\")\n",
    "\n",
    "state, info = env.reset()\n",
    "done = False\n",
    "total_reward = 0\n",
    "\n",
    "while not done:\n",
    "    pred = nn_save.forward(unpack_state(state))\n",
    "    action = np.argmax(pred)  # greedy\n",
    "    new_state, reward, terminated, truncated, _ = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    total_reward += reward\n",
    "    state = new_state\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044dca8c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "019c66ab67b3a12e2e6a0db85860b6f4",
     "grade": false,
     "grade_id": "ex_2_4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exersice 2.5: \n",
    "\n",
    "1. What are the similarities between Q-learning and deep Q-learning?\n",
    "\n",
    "They both use Q-values and aim to maximize cumulative rewards.\n",
    "\n",
    "2. What are the differences and what implications does these difference have? Are Q-learning and deep Q-learning equally good at the same tasks or are they suited for different problems? \n",
    "\n",
    "Q-learning uses a tabular approach. Deep Q-learning uses a neural network approach.\n",
    "Neural networks can diverge or oscillate during value updates.\n",
    "\n",
    "3. Are there any difficulties with deep Q-learning?\n",
    "\n",
    "Balancing the exploration-exploitation trade-off is challenging, and issues like overfitting and other problems can occur.\n",
    "\n",
    "4. What conclusion can you draw from the the learning curve?\n",
    "\n",
    "4 The graph initially shows an exponential increase. This suggests that the learning algorithm is quickly gathering knowledge or finding an effective strategy. After reaching a peak the performance declines rapidly which may indicate overfitting or instability as the model starts to over-prioritize certain actions. Finally, the curve converges to a specific y-value, likely reflecting the model settling into a stable policy where it consistently achieves a certain level of reward "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1709af2",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fa7545a2aff704dcb7afea13f2288849",
     "grade": true,
     "grade_id": "answer_2_4",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "732320bc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "283b1e53de966ca8b05df62817159256",
     "grade": false,
     "grade_id": "Intro-CNN_pytorch",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# CNN and pytorch\n",
    "\n",
    "## Exersice 3.1\n",
    "\n",
    "Now that we've gained a solid understanding of how neural networks function and how they are trained, we'll shift our focus to tackling an image classification problem. In this instance, we will utilize ready-made packages and libraries to streamline the process.\n",
    "\n",
    "Debugging neural networks is not an easy task! If you're looking for a helpful resource, the University of Amsterdam's course on debugging neural networks might provide valuable insights and techniques to address common challenges. https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/guide3/Debugging_PyTorch.html\n",
    "\n",
    "The starting initial code is based on https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
    "\n",
    "We are going to use the MNIST data set, which containts images of handwritten numbers and your task is to classify the written numbers from the images. \n",
    "\n",
    "Your task is to modify the code below to increase the accuracy to atleast 98%. There will hints written throughout below. Then in task 3.2 you will describe the changes you made and try to motivate why you made them.    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "71891f6b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e16ece813ff7e8be7579f03d5549528f",
     "grade": true,
     "grade_id": "CNN_imports",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "94ef6cbf",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6952f2383930e2fbacffa8d51413946d",
     "grade": true,
     "grade_id": "Get_mnist_data",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Download training data from open datasets.\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# visualize the data\n",
    "num_images_to_plot = 9\n",
    "fig, axes = plt.subplots(3, 3, figsize=(8, 8))\n",
    "\n",
    "for i in range(num_images_to_plot):\n",
    "    image, label = training_data[i]\n",
    "    ax = axes[i // 3, i % 3]\n",
    "    ax.imshow(image.squeeze(), cmap='gray')\n",
    "    ax.set_title(f\"Label: {label}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "eb266a78",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b5e6463b9fd0ad8c7d337ba33cfda21e",
     "grade": true,
     "grade_id": "CNN_data_loaders",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Batch size, this is something you can tune, but the current value is decent.  \n",
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83db25ff",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d7bc5151d90e0559a8e741a39fdb23e7",
     "grade": false,
     "grade_id": "intro_define_network",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Define the neural network\n",
    "\n",
    "Here there is alot of things that can be tuned, I do encurage to add convolutional layers. While it is not neccessary to achive the accuracy, the convolutional layers are very good at images. For example a convolution layer can be defnined as following\n",
    "\n",
    "self.conv1 = nn.Conv2d(1, 3, 5)\n",
    "\n",
    "where the first input is the number of in channels. For a grey image there is only one channel, for an rgb image there is 3 channels. The second input is the number of out channels, you can see it as parrallel filters. The last input is the filter size. More infromation exists at https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html. The thing to keep in mind is the dimensions out of convolution. In this case the inpout is 1x28x28 and the output 3x24x24.\n",
    "\n",
    "In the forward funciton it can be used as\n",
    "\n",
    "x =  F.relu(self.conv1(x))\n",
    "\n",
    "And lets say you have defined a linear (dense) layer \n",
    "\n",
    "self.fd1 = nn.Linear(3 * 24 * 24, 120)\n",
    "\n",
    "They can be combined in the forward function as:\n",
    "\n",
    "x =  F.relu(self.conv1(x))\n",
    "\n",
    "x = torch.flatten(x, 1) # this flattens the output to a vector\n",
    "\n",
    "x =  F.relu(self.fd1(x))\n",
    "\n",
    "\n",
    "A lot of things can be modified here, such as number of layers, the size of the layers, the type of layers. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "83e6f984",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7408262fd7e4d7f66589a8d873fc4081",
     "grade": true,
     "grade_id": "cnn_define_network",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define the neural network model\n",
    "class NeuralNetwork_pytorch(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=4) #This layer takes and input image with 1 channel (grayscale) and applies 16 filters (outputs 16 featurs maps) and uses a 4x4 kerner. \n",
    "        self.conv2 = nn.Conv2d(16,32, kernel_size=4) #This layer takes the 16 feature maps from the prev lavyer, applies 32 further filters and uses a 4x4 kernel.\n",
    "        \n",
    "        self.fd1 = nn.Linear(32*22*22, 512) # Takes the 512 featurs (after flattning the 32 channels of 4x4 features) and maps them to 512 neurons\n",
    "        self.fd2 = nn.Linear(512, 512) # A second fully connected layer with 512 neurons\n",
    "        self.fd3 = nn.Linear(512, 10) # Maps the 512 neurons to 10 output neurons, correpsonding to the 10 possible classes (0-9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = (F.relu(self.conv1(x)))  # Input x passes through conv1, then through a ReLu function and then by a pool. \n",
    "        x = (F.relu(self.conv2(x)))  # Input x passes through conv2, then through a ReLu function and then by a pool. \n",
    "        \n",
    "        x = torch.flatten(x, 1) #Flattens the 2d feature map into a vector.\n",
    "        \n",
    "        #The flattened vector goes through two ReLu-activated layers (fd1 and fd2), then through fd3 which outputs the predictions (logits) for each of the 10 classes\n",
    "        x = F.relu(self.fd1(x)) \n",
    "        x = F.relu(self.fd2(x))\n",
    "        x = self.fd3(x) # Final layer with no activation (logits)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "22193a02",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10998906721c2c93d54bfa413d8a0f22",
     "grade": false,
     "grade_id": "train_function_cnn",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Our traning function, nothing to modify here\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % (100*int(64/batch_size)) == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "36a59e70",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec1aaa765533f8acf154c2f063c84e51",
     "grade": false,
     "grade_id": "cnn_test_function",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# our test function, nothing to modify here.\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "897fff6b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f0afd422e93f815692478b30e4555d87",
     "grade": true,
     "grade_id": "Training_loop_cnn",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.307724  [   64/60000]\n",
      "loss: 0.464238  [ 6464/60000]\n",
      "loss: 0.359718  [12864/60000]\n",
      "loss: 0.368388  [19264/60000]\n",
      "loss: 0.118982  [25664/60000]\n",
      "loss: 0.258456  [32064/60000]\n",
      "loss: 0.155885  [38464/60000]\n",
      "loss: 0.176451  [44864/60000]\n",
      "loss: 0.165082  [51264/60000]\n",
      "loss: 0.192400  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.2%, Avg loss: 0.118777 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.062292  [   64/60000]\n",
      "loss: 0.049327  [ 6464/60000]\n",
      "loss: 0.166091  [12864/60000]\n",
      "loss: 0.128372  [19264/60000]\n",
      "loss: 0.054547  [25664/60000]\n",
      "loss: 0.044728  [32064/60000]\n",
      "loss: 0.066340  [38464/60000]\n",
      "loss: 0.062965  [44864/60000]\n",
      "loss: 0.119650  [51264/60000]\n",
      "loss: 0.141898  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.066925 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.016948  [   64/60000]\n",
      "loss: 0.066714  [ 6464/60000]\n",
      "loss: 0.081307  [12864/60000]\n",
      "loss: 0.079567  [19264/60000]\n",
      "loss: 0.048480  [25664/60000]\n",
      "loss: 0.016901  [32064/60000]\n",
      "loss: 0.051743  [38464/60000]\n",
      "loss: 0.027004  [44864/60000]\n",
      "loss: 0.146437  [51264/60000]\n",
      "loss: 0.080422  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.063129 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.029677  [   64/60000]\n",
      "loss: 0.017851  [ 6464/60000]\n",
      "loss: 0.026959  [12864/60000]\n",
      "loss: 0.044385  [19264/60000]\n",
      "loss: 0.006709  [25664/60000]\n",
      "loss: 0.005313  [32064/60000]\n",
      "loss: 0.057949  [38464/60000]\n",
      "loss: 0.016246  [44864/60000]\n",
      "loss: 0.098855  [51264/60000]\n",
      "loss: 0.020749  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Avg loss: 0.062506 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.056672  [   64/60000]\n",
      "loss: 0.002406  [ 6464/60000]\n",
      "loss: 0.025913  [12864/60000]\n",
      "loss: 0.009922  [19264/60000]\n",
      "loss: 0.002782  [25664/60000]\n",
      "loss: 0.012152  [32064/60000]\n",
      "loss: 0.018819  [38464/60000]\n",
      "loss: 0.013998  [44864/60000]\n",
      "loss: 0.094221  [51264/60000]\n",
      "loss: 0.002038  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.058125 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# The training loop, here you can change the optimizer, the opimizer is how you update the weights. SGD does \n",
    "# gradient decent. Adam optimizer adds some extra steps and regularization. \n",
    "\n",
    "epochs = 5 # try to not change the number of epochs, we want something that learns fast. \n",
    "           # One epoch trains through all the data. \n",
    "    \n",
    "model = NeuralNetwork_pytorch().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss() # you can change the loss function \n",
    "\n",
    "# you can change the optimizer. The optimizer is how you updates the weights and there are differnet ways to do that.\n",
    "# For more info see https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial4/Optimization_and_Initialization.html#Optimization\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-3) #Weight added for reglurazation\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a6d5da",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "108d76a3aad36c29ce5dbcda5c0af526",
     "grade": false,
     "grade_id": "cell-c4a405f59c1f4998",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exersice 3.2: modifications\n",
    "\n",
    "What modifications did you do and what improvments did you see from them. Can you reason to why they worked?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe273f73",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "53f3838a7ac06254a76374891bea3a16",
     "grade": true,
     "grade_id": "cell-c08fcb694697cec5",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Text answer: \n",
    "\n",
    "Firstly we increased the learning-rate in the SGD model to 1e-1 which saw a nice improvment. From 92percent to 97 percent\n",
    "\n",
    "Then we started tinkering a bit with the definition of the neural network. We added to two convulutions layers because convulation layers are better for images as they retain spatial information and help the model learn patterns like edges, shapes and textures. This is benifical as seen in the  Origninally we only had fully connected layers for the image data.\n",
    "\n",
    "We hanged the input size of the first fully connected layder (fd1) to match the ouput form the final convulution layer. This ensured we did not achive any shape mismatch errors.\n",
    "\n",
    "We also moved the flattening and retained its 2D structure thoughout the convulution layers and flattening afterwards. By not flattening as early our convulutional layers could captue the spacial hierachies in the data, allowing them to detech complex patterns more effectievly.\n",
    "\n",
    "Using the three modifications above went from a 97 to 98.5 percent accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
